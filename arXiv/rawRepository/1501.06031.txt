FROM DYNAMICS TO LINKS: A SPARSE RECONSTRUCTION OF THE
TOPOLOGY OF A NEURAL NETWORK

arXiv:1501.06031v1 [stat.AP] 24 Jan 2015

GIACOMO ALETTI, DAVIDE LONARDONI, GIOVANNI NALDI, AND THIERRY NIEUS

A BSTRACT. One major challenge in neuroscience is the identification of interrelations between signals reflecting neural activity and how information processing occurs in the neural
circuits. At the cellular and molecular level, mechanisms of signal transduction have been
studied intensively and a better knowledge and understanding of some basic processes of
information handling by neurons has been achieved. In contrast, little is known about the
organization and function of complex neuronal networks. Experimental methods are now
available to simultaneously monitor electrical activity of a large number of neurons in real
time. Then, the qualitative and quantitative analysis of the spiking activity of individual
neurons is a very valuable tool for the study of the dynamics and architecture of the neural
networks. Such activity is not due to the sole intrinsic properties of the individual neural
cells but it is mostly consequence of the direct influence of other neurons. The deduction of the effective connectivity between neurons, whose experimental spike trains are
observed, is of crucial importance in neuroscience: first for the correct interpretation of the
electro-physiological activity of the involved neurons and neural networks, and, for correctly relating the electrophysiological activity to the functional tasks accomplished by the
network. In this work we propose a novel method for the identification of connectivity of
neural networks using recorded voltages. Our approach is based on the assumptions that
the network has a topology with sparse connection. After a brief description of our method
we will show some numerical results with some data obtained from numerical simulations.

1. I NTRODUCTION
Along the latests years there have been enormous progresses in the Neuroscience field
that have revolutionized the way we envisage the brain functions. In this regard, the technological advancements have been fundamental to improve the recording capability from
brain areas and neural populations [1]. Nowadays, multi-site recordings can be achieved
from thousands of channels (sites) with a good spatial (at the cellular level) and temporal
resolution (less than one millisecond for the action potential) yielding a good description of
the underlying network dynamics. Given that the brain operates on a single trial basis such
recordings are instrumental to understand the neural code [2]. As a first step, multi-site
recordings allow to quantify the information flow in the network. The anatomical wiring
(i.e. Structural Connectivity, SC) clearly plays a fundamental role to understand how cells
comunicate among them but it is often not well known neither it can by itself explain the
overall network activity. Multi-site recordings can be used to infer statistical dependencies
(i.e. Functional Connections, FC) among the recorded units and to track the information
flow in the network [3]. On the other hand the Effective Connectivity (EC) denotes the
directed causal relationship between the recorded sites. The EC is typically estimated by
stimulating one cell and studying the effects on the connected elements. Alternatively the
2000 Mathematics Subject Classification. 92B20; 65K05; 37F99.
Key words and phrases. Neural Networks; Sparse reconstruction; LASSO method.
1

2

GIACOMO ALETTI, DAVIDE LONARDONI, GIOVANNI NALDI, AND THIERRY NIEUS

EC can also be studied establishing a causal mathematical model between the recorded
units data.
Importantly, multi-site recordings raise some limitations that need to be evaluated carefully before any further analysis. First, the experimental sessions are often severly limited
in time. Second, the high dimensional data sets involve a set of numerical and mathematical problems that would be hard to face even with long enough recording sessions. These
issues are common to different fields and have been coined as ’curse of dimensionality’.
To overcome these issues, two approaches are typically foreseen. A first solution consists
into a reductionist approach that projects the data on a lower dimenstional space that can
better elucidate the underlying processing. Another possibility consists into fitting the observed data to a low-dimensional model that captures the salient properties of the dynamics
[1]. Here we introduce a model of effective connectivity that gets rid of the dimensionality
problem by introducing a natural constrain of almost all biological networks: the sparseness among the connected units (see e.g. [4]). Other approaches, such as the multivariate
autoregressive model [5], allow for the possibility of a fully connected network in which
every node may influence all the other nodes. However this is somewhat unrealistic for
biological networks (i.e. each neuron is directly influenced by only a small subset of neurons) and it also leads to practical challenges. In fact, most of the connectivity tools used
to understand the communication among neuronal populations are based on linear models although it is widely recognized that the interactions (i.e. synaptic currents) among
neural cells are nonlinear. Then, fully connected networks involve models that can easily
be over-parameterized and hard to solve. Therefore current methods are not well suited
to robustly infer on the network connectivity from the time series in different contexts.
Among these approaches, the Granger causality [6, 7] is probably the most prominent and
most widely used concept. This concept of causality does not rely on the specification of a
scientific model and thus is particularly suited for empirical investigations of cause-effect
relationships. On the other hand, it is commonly known that Granger causality basically
is a measure of association between the variables and thus can lead to so-called spurious causalities if important relevant variables are not included in the analysis. In order to
capture nonlinear interactions between even short and noisy time series, we consider an
event-based model. Then, we involve the physiological basis of the signal, which is likely
to be mainly nonlinear.
In Section 2 we introduce a general setting for the problem. In the Section 3 we describe
our experimental settings and data preprocessing. The results are reported in the Section 4,
while final remarks are postponed in the last section.
2. P ROBLEM F ORMULATION
2.1. Network representation of the problem. Let us consider a graph G = (V, E),
where V corresponds to a set of N neurons connected with a directed graph given by
the edges contained in E of ordered pairs of vertices contained in ⊆ V × V . On each node
i ∈ V , two stochastic processes are observed:
• an external process {Xi (t), 0 ≤ t ≤ T } (spike processes);
• an internal process {Yi (t), 0 ≤ t ≤ T }.
We assume a Local Markov Property (LMP): the relevant information on each process
Yi (t), i = 1, . . . , N is “contained” on the external activity of the neurons j connected to
it, and in a time interval δ. For example, in the network given in Figure 1, the law of the
4th neuron depends on the external activity of the 1st, 2nd, and 5th neuron together with
its own internal activity.

FD2L: SPARSE RECONSTRUCTION OF THE TOPOLOGY

3

We explain now the LMP in terms of the σ-algebras of events observable by the processes. We denote by Ft− the observable events of the “past” of the external processes
until time t, and it will be defined as the σ-algebra of events generated by the processes
W
(i)
{Xi (s), s < t, i ∈ V }: Ft− = i∈V σ(Xi (s), s < t). The σ-algebra Ft− contains
the observable events of the “close past” of the in-neighborhoods of the i-th neuron:
W
(i)
Fδ,t− = j : (j,i)∈E σ(Xj (s), t − δ ≤ s < t). Moreover, we will denote by Gt+ the
(i)

observable events of the “future” of the internal processes: Gt+ = σ(Yi (u), t ≤ u).
With this notation, LMP says that the future of the i-th internal process and past of all
the external processes are conditional independent given the close past of the i-th neuron:
(i)

P (G|Ft− ) = P (G|Fδ,t− ),

(LMP)

(i)

∀G ∈ Gt+ , ∀i.

(i)

In other words, Fδ,t− gives all the relevant information on the future of the internal activity
of the i-th neuron.
2

1

4

5


0
0

CE = 
1
0
1

1
0
0
0
0

0
0
0
1
0

1
1
0
0
1


0
0

1

0
0

3
F IGURE 1. Example of a nework of 5 neurons and its adjacency matrix.

2.2. Event-based discrete time model. We use a particular model of the class of processes satisfying (LMP). We sample the processes at discrete times tm = mδ, and we
assume an event-based model: both the internal and external processes are simple point
processes, and we assume that at most one event may occur for each process in any time
interval. We note that the definition of event depends on the knowledge of the investigator
and on the available data. For the purpose of this paper, the definition of events will be
introduced in the Section 3.2. Given an event-based model, for any m = 1, . . . , M , we
observe
(
+1 if there has been an event for Yi (s) duting (tm−1 , tm ];
m
yi =
0
otherwise;
and
xm
i

(
+1
=
0

if there has been an event for Xi (s) duting (tm−1 , tm ];
otherwise;

The model can be completely characterized by defining the family of conditional probabilities
π(i, m) = P (yim+1 = 1|xlj , l ≤ m, j ∈ V ) = P (yim+1 = 1|xm
j , (j, i) ∈ E),
the last equality being a consequence of (LMP).

∀i, m,

4

GIACOMO ALETTI, DAVIDE LONARDONI, GIOVANNI NALDI, AND THIERRY NIEUS

To model the association among the nodes, we assume in this paper a time-homogeneous
linear logit model:
X
−1
(1)
π(i, m) = (1 + exp(−β0 −
βj,i xm
.
j ))
(j,i)∈E

Given a set {ωi,m } of positive real numbers, the negative weighted log-likelihood function
for our processes reads:
(2)

`M (β) = −

M
−1 X
X



ωi,m yim+1 log π(i, m) + (1 − yim+1 ) log(1 − π(i, m)) .

m=1 i∈V

Note that the significant parameters {βj,i , (j, i) ∈ E} of our model depend on the topology
of the network. The choice of the weights is done
to balance the numberPof yim = 0
P here
m
l
and yi = 1. A simple choice might be ωi,m = j,l yj if yim = 0 and ωi,m = j,l (1−yjl )
if yim = 1.
3. E XPERIMENTIMENTAL SETTINGS
3.1. Simulations . We simulate the potential of the j-th neuron Vj (t) by the Hodgkin&Huxley
equations of the cerebellar granule cell (GrC, [8]). Heterogeinity among the GrCs is introduced by randomizing the resting potentials with a current of 2 ± 0.2 pA. The network
consists of 20 neurons with a connectivity probability of 0.3 and all connections are directional (i.e. chemical synapses). Since self-connections (i.e. ’autapses’) are not so frequent
in the brain, they were not included in our networks. Based on these numbers, the simulated networks comprises, in average, of 114 connections (i.e. 20 · 19 · 0.3). The chemical
synapses are modeled by the fast AMPA excitatory currents [9]. In addition, to mimic a biologically realistic noisy regime, Poisson distributed AMPA currents (of frequency 0.2 Hz)
are injected to all GrCs. The cellular and synaptic models are described in the literature
[8, 9] and the parameter settings and its changes respect to the literature are reported in the
Table 1. Since here we are interested in highlighting the potential impact of our approach
synaptic input
AMPA

NMDA

parameter unit
gmax
pS
r1
ms−1 mM −1
r2
ms−1
r6
ms−1 mM −1
absent

value
800
5.4
0.84
0

value in literature [9]
1200

1.12

synaptic noise

gmax
pS
500
r1
ms−1 mM −1 5.4
r2
ms−1
0.1
r6
ms−1 mM −1 0
TABLE 1. Values for the parameter settings for the dynamics of AMPA,
NMDA and synaptic currents

we discarded the contribution of other synaptic conductances that will be included in a next
work.

FD2L: SPARSE RECONSTRUCTION OF THE TOPOLOGY

5

We simulate five seconds of activity of such a network. A snapshot of the activity of a
neuron in the network is shown in figure 2. The upswings of the potential are mainly determined by the inputs from the other cells, which time occurence is highlighted by the red,
blue and green dashed lines. Interestingly, the spiking activity is not strictly determined by
the input itself. In fact, the spike doublet (D1,D2), the isolated spikes (IS) and the spike
from excitation (EXC) are not apparently determined by the input. Spike D1 arises from
a depolarization that is not directly caused by the input and spike D2 can either by determined by high membrane excitation as well as by noise. The spike IS is most probably
caused only by noise and spike EXC is again due to membrane excitation or simply by
synaptic noise.
20

D1

D2

IS

EXC

voltage (mV)

0

20

40

60

80

3400

3600

3800
time (ms)

4000

4200

F IGURE 2. Voltage trace of a neuron in the network. The voltage (black
trace) is overlayed with the time stamps of the inputs (colored dash lines)
to the cell. The voltage changes are clearly correlated with the input.
However spikes D1, D2, IS, EXC are not apparently determined solely
by the input. Note that the blue, red and green colors correspond to three
different cells.

3.2. Data preprocessing. The process {xm
j , m = 1, . . . , M } is the discretization (in
time) of the spike activity of the j-th neuron, so that xm
j = 1 if there has been a spike
during the time interval (tm−1 , tm ].
The process {yjm , m = 1, . . . , M } is a reaction process, nonlinear filter of the potential
activity Vj (t). Here, yjm = 1 if there has been an event for Vj (t) during the time interval
(tm−1 , tm ], where an event at time t depends on three factors (see Figure 3):
(i) the right derivative Vj0 (t+ ) must be greater than a positive threshold (increasing of
potential after excitation);
(ii) the increasing of derivatives Vj0 (t+ ) − Vj0 (t− ) must be greater than a positive
threshold (convex effect of potential due to excitation);
(iii) the left derivative Vj0 (t− ) must be greater than a negative threshold (in connection
with other conditions, this avoid an event caused by the recover of the resting
potential during the hyperpolarization phase; alone, this identifies those events).

6

GIACOMO ALETTI, DAVIDE LONARDONI, GIOVANNI NALDI, AND THIERRY NIEUS

F IGURE 3. Example of identification of events based on the voltage activity. Events that are determined by the links of the network are marked
with ∗ (i.e. true positive), while ◦ shows false identification (i.e. false
positive) (due, for example, to external noise). Top left: identification of
events with all the three factors of data preprocessing. Top right: identification of events with only (i) factor. Bottom left: identification of events
with only (ii) factor. Bottom right: identification of events with only (iii)
factor.

More precisely, when a sequence of times of length n ≥ 1 satisfies the requested conditions, an event is detected. The first time of this sequence is the time of the event.
3.3. Topology estimator. Given the data of our processes, we are interested in reconstructing the topology of our network. We want to give an estimator V̂ of the set V of the
edges. In our contest, the edge (j, i) exists when the process yim is directly caused by xm
j ,
in the sense of (LMP). In other words, when βj,i is different from zero in (1). Therefore,
we adopt the following strategy:
• with a penalization technique, we find a sparse estimator β̂ of β;
• we say that (j, i) ∈ V̂ if β̂j,i is different from zero.
In this paper, we adopt a `1 -penalization on the regression coefficients {βj,i , i, j ∈ E}.
Given a positive penalization parameter λ, let
L(β, λ) = `M (β) + λ

X
i,j∈E

|βj,i |,

FD2L: SPARSE RECONSTRUCTION OF THE TOPOLOGY

7

and define the Lasso estimator β̂(λ) = arg minβ L(β, λ). As stated above, we define
V̂ (λ) as
(3)

(j, i) ∈ V̂ ⇐⇒ β̂j,i (λ) > 0.

Here we also compare the performances of the novel methodology with the standard
cross-correlation that is widely used in the multi electrode array field [10, 11, 12]. The
cross-correlation functions among the discrete spike trains are defined as:
(4)

CCi,j (τ ) =

hSTi · STj (τ )i
p
Ni · Nj

where STi , STj are the binned spike trains (bin size 1 ms) and Ni ,Nj the corresponding
number of spikes. The strength of a connection, between the nodes i and j, is then given
by the peak of the quantity CCi,j given in (4). The network topology can then be inferred
by retaining the strongest and most significants cross-correlation peaks that are overcome
a selected threshold.

4. E XPERIMENTAL R ESULTS
The validation of the proposed methodology is afforded on simulations presented in the
Section 3.1. The performances of the methodologies are quantified with the well known
receiver operating characteristic (ROC) curves and with the recently introduced positive
precision curve (PPC, [10]). The graphs reported in Figure 4 are obtained by varying the
penalization parameter λ, for the Lasso methodology, and the cross-correlation threshold
for the respective correlation methodology.
Let us remind that PPC is defined as:
(5)

PPC =

TP − FP
TP + FP

and represents the proportion of the correctly (true positive, TP) versus the incorrectly
(false positive, FP) inferred links. The plot on the right in the Figure 4 reports the PPC
index with respect to the number of links included in the analysis. Interestingly, the PPC
curve of the Lasso stays at its maximum up to 30% of the links, that correspond to the real
links of the network (the connectivity probability is 0.3).
Clearly, beyond 30% of the included links, the PPC has a negative power decay. We
point out that the cross-correlation does not achieve to infer the topology at any level of the
cross-correlation threshold. Interestingly, when the Lasso events are based only on spiking
information (condition (iii) alone) it performs as bad as the cross-correlation.
The Lasso (Figure 4) performs very well and reaches the maximum value (=1) in both
the ROC and PPC curves for a large range of the penalization parameter. Moreover, the
worst performances are achieved when no constraint is imposed on the sparsity (e.g. λ = 0)
on the inferred network. Finally, the intuition is preserved: the first connections entered in
the Lasso estimate, are almost all true (PPC ∼ 1).
Another interesting feature of the newly introduced Lasso methodology consists into
its capability of inferring on the birectional links. The results of Figure 4 are based on
a network with 121 connections out of which 38 were bidirectional (31.4% out of the
total). This an another advantage over the cross-correlation method, that only determines
unidirectional connections.

8

GIACOMO ALETTI, DAVIDE LONARDONI, GIOVANNI NALDI, AND THIERRY NIEUS

F IGURE 4. Roc (on the left) and PPC (on the right) curves for the topology estimator (3), with the complete data preprocessing and with each
of the filtering conditions (i), (ii) and (iii) given in Section 3.2. The first
conditions (i) and (ii) of data preprocessing may be used alone without
affecting the main result, while spiking activity alone is not predictive

5. C ONCLUSIONS AND F UTURE W ORKS
Understanding how interactions between brain structures support the performance of
specific cognitive tasks or perceptual processes is a prominent goal in neuroscience. The
effects that one part of the nervous system has on another are typically examined by stimulating or lesioning the first part and investigating the outcome in the second. For example,
in peripheral and spinal pathways, the interventional techniques of stimulation and ablation have proven to be powerful methods for inferring causal influences from one neuron
or neuronal population to another. For the study of causal relations within the brain (functional and effective connectivity ), the utility of the interventional techniques is diminished
by the high levels of convergence and divergence in brain pathways.
In this work we have developed an event based approach for inferring networks of causal
relationships in a neuronal populations. Specifically, we suppose that we are able to observe the dynamical behaviors of individual components of a neuronal networks and that
few of the components may be causally influencing each other. The variables could be
invasive electrode recordings, intracranial EEG, or non-invasive EEG, MEG or fMRI time
series from different parts of the brain. In order to introduce our method we have considered a simulated cerebellar granule cell network capturing nonlinear interactions between
even short and noisy time series.
Although at the current stage we present an EC algorithm that cannot be applied straightforwardly to the experimental data, the results we got are quite promising from many point
of views. First, despite the algorithm was applied only a short simulation (5 seconds) it
achieved to filter out noisy from causal responses yielding a reliable estimate of the underlying connections in the network. Second, the approach is quite general and the conditions
(i),(ii),(iii) can be further adapted to different types of electro-physiological signals. Third,
the Lasso is also quite robust respect to bidirectional connections in the network. This is of
fundamental importance since it has been recognized in the latest years that bidirectional
network motifs are quite abundant in the brain [13].
In the future we aim to improve the methodology as well as its applicability to experimental data. From the methodological point of view we will include inhibitory synapses

FD2L: SPARSE RECONSTRUCTION OF THE TOPOLOGY

9

and investigate the robustness of the methodology respect to the size of the simulated networks and the introduced noise level. Regarding the applicability of the proposed methodology we foresee an extension to the calcium imaging signals [14]. This is of high interest
since calcium imaging techniques are quite popular nowadays in the Neuroscience field
and are particularly suited for in-vivo experiments [15].

R EFERENCES
[1] I. H. Stevenson and K. P. Kording, “How advances in neural recording affect data analysis.” Nat Neurosci,
vol. 14, no. 2, pp. 139–142, Feb 2011. [Online]. Available: http://dx.doi.org/10.1038/nn.2731
[2] M. M. Churchland, B. M. Yu, M. Sahani, and K. V. Shenoy, “Techniques for extracting single-trial activity
patterns from large-scale neural recordings.” Curr Opin Neurobiol, vol. 17, no. 5, pp. 609–618, Oct 2007.
[Online]. Available: http://dx.doi.org/10.1016/j.conb.2007.11.001
[3] E. Bullmore and O. Sporns, “Complex brain networks: Graph theoretical analysis of structural and functional systems,” Nature Reviews Neuroscience, vol. 10, no. 3, pp. 186–198, 2009.
[4] A. Bolstad, B. Van Veen, and R. Nowak, “Causal network inference via group sparse regularization,” IEEE
Transactions on Signal Processing, vol. 59, no. 6, pp. 2628–2641, 2011.
[5] M. Winterhalder, B. Schelter, W. Hesse, K. Schwab, L. Leistritz, D. Klan, R. Bauer, J. Timmer, and H. Witte,
“Comparisson of linear signal processing techniques to infer directed interactions in multivariate neural
systems.” Signal Process., vol. 85, no. 11, p. 21372160, 2005.
[6] C. Granger, “Investigating causal relations by econometric models and cross-spectral methods.”
Econometrica, vol. 37, pp. 424–438, 1969.
[7] S. L. Bressler and A. K. Seth, “Wienergranger causality: A well established methodology.” NeuroImage,
vol. 58, no. 2, p. 323329, 2011. [Online]. Available: http://dx.doi.org/10.1016/j.neuroimage.2010.02.059
[8] E. D’Angelo, T. Nieus, A. Maffei, S. Armano, P. Rossi, V. Taglietti, A. Fontana, and G. Naldi, “Thetafrequency bursting and resonance in cerebellar granule cells: Experimental evidence and modeling of a
slow k+-dependent mechanism,” Journal of Neuroscience, vol. 21, no. 3, pp. 759–770, 2001.
[9] T. Nieus, E. Sola, J. Mapelli, E. Saftenku, P. Rossi, and E. D’Angelo, “Ltp regulates burst initiation
and frequency at mossy fiber-granule cell synapses of rat cerebellum: experimental observations and
theoretical predictions.” J Neurophysiol, vol. 95, no. 2, pp. 686–699, Feb 2006. [Online]. Available:
http://dx.doi.org/10.1152/jn.00696.2005
[10] M. Garofalo, T. Nieus, P. Massobrio, and S. Martinoia, “Evaluation of the performance of
information theory-based methods and cross-correlation to estimate the functional connectivity
in cortical networks.” PLoS One, vol. 4, no. 8, p. e6482, 2009. [Online]. Available: http:
//dx.doi.org/10.1371/journal.pone.0006482
[11] A. Maccione, M. Garofalo, T. Nieus, M. Tedesco, L. Berdondini, and S. Martinoia, “Multiscale
functional connectivity estimation on low-density neuronal cultures recorded by high-density cmos micro
electrode arrays.” J Neurosci Methods, vol. 207, no. 2, pp. 161–171, Jun 2012. [Online]. Available:
http://dx.doi.org/10.1016/j.jneumeth.2012.04.002
[12] S. Ullo, T. R. Nieus, D. Sona, A. Maccione, L. Berdondini, and V. Murino, “Functional
connectivity estimation over large networks at cellular resolution based on electrophysiological
recordings and structural prior.” Front Neuroanat, vol. 8, p. 137, 2014. [Online]. Available:
http://dx.doi.org/10.3389/fnana.2014.00137
[13] S. Song, P. J. Sjostrom, M. Reigl, S. Nelson, and D. B. Chklovskii, “Highly nonrandom features of synaptic
connectivity in local cortical circuits.” PLoS Biol, vol. 3, no. 3, p. e68, Mar 2005. [Online]. Available:
http://dx.doi.org/10.1371/journal.pbio.0030068
[14] H. Ltcke, F. Gerhard, F. Zenke, W. Gerstner, and F. Helmchen, “Inference of neuronal network spike
dynamics and topology from calcium imaging data.” Front Neural Circuits, vol. 7, p. 201, 2013. [Online].
Available: http://dx.doi.org/10.3389/fncir.2013.00201
[15] S. Bovetti and T. Fellin, “Optical dissection of brain circuits with patterned illumination through the
phase modulation of light.” J Neurosci Methods, Dec 2014. [Online]. Available: http://dx.doi.org/10.1016/
j.jneumeth.2014.12.002

10

GIACOMO ALETTI, DAVIDE LONARDONI, GIOVANNI NALDI, AND THIERRY NIEUS

ADAMSS C ENTER & D EPARTMENT OF M ATHEMATICS , U NIVERSIT À DEGLI S TUDI DI M ILANO , 20131
M ILANO , I TALY
E-mail address: giacomo.aletti@unimi.it
N EUROSCIENCE B RAIN T ECHNOLOGY, I STITUTO I TALIANO DI T ECNOLOGIA , VIA M OREGO 30, 16163
G ENOVA , I TALY
ADAMSS C ENTER & D EPARTMENT OF M ATHEMATICS , U NIVERSIT À DEGLI S TUDI DI M ILANO , 20131
M ILANO , I TALY
N EUROSCIENCE B RAIN T ECHNOLOGY, I STITUTO I TALIANO DI T ECNOLOGIA , VIA M OREGO 30, 16163
G ENOVA , I TALY

