arXiv:1501.04010v1 [cs.NE] 16 Jan 2015

Coevolutionary intransitivity in games:
A landscape analysis
Hendrik Richter
HTWK Leipzig University of Applied Sciences
Faculty of Electrical Engineering & Information Technology
Postfach 301166, D–04251 Leipzig, Germany
Email: richter@eit.htwk-leipzig.de
January 19, 2015

Abstract
Intransitivity is supposed to be a main reason for deficits in coevolutionary progress and inheritable superiority. Besides, coevolutionary dynamics is characterized by interactions yielding subjective fitness, but
aiming at solutions that are superior with respect to an objective measurement. Such an approximation
of objective fitness may be, for instance, generalization performance. In the paper a link between rating–
and ranking–based measures of intransitivity and fitness landscapes that can address the dichotomy between subjective and objective fitness is explored. The approach is illustrated by numerical experiments
involving a simple random game with continuously tunable degree of randomness.

1

Introduction

Despite earlier promises and optimism, using coevolutionary algorithms (CEAs) for evolving candidate
solutions towards an optimum remains a complicated and almost arcane matter with generally unclear
prospects of success [13, 15, 20]. This is prominently caused by a defining feature of coevolution. CEAs
are driven by fitness that originates from interaction of candidate solutions with other candidate solutions.
In other words, the fitness obtained from these interactions is subjective as it depends on which candidate
solutions are actually interacting and when in coevolutionary run–time the interactions take place. The
interactions can be understood as to constitute tests, which leads to labeling such kinds of coevolutionary
problems as test–based problems [15, 17]. Test–based problems particularly occur in game playing or
game–like contexts, for instance in situations where the players’ strategies are subject to (competitive)
coevolutionary optimum finding [15, 19]. It has been argued that in games with players and strategies the
player space can be understood a phenotypic according to the framework of fitness landscapes [10, 16], while
the strategy space is genotypic [1, 14]. This view is adopted in the following discussion.
Notwithstanding that coevolutionary dynamics is induced by subjective fitness, the aim of using a CEA
is identifying candidate solutions that are superior in a more general sense. Hence, in coevolution next to
the fitness resulting from (a limited number of) tests, a second notion of fitness is helpful. Such a fitness
generalizing subjective fitness occurs in test–based problems in different forms. For games with players and
strategies, there is usually no absolute quality measurement, or an absolute quality measurement would
require to evaluate all possible test cases, which is computationally infeasible [4, 5, 19]. To circumvent
this problem and enable experimental studies of the relationships between subjective fitness and absolute
quality measurements, number games have been proposed, for instance minimal substrates [18, 21]. These
artificial problem settings postulate an absolute quality, called objective fitness [7]. In this line of reasoning,
coevolutionary dynamics can be understood as aiming at progress in objective fitness by proxy of subjective
fitness. Consequently, a main difficulty in designing CEAs stems from the question of how well subjective
1

fitness represents objective fitness. In analogy to the (postulated) objective fitness of number games, for
games with players and strategies all general quality measurements of subjective fitness are interpretable as
objective fitness. This implies that for game playing there may only be an approximation of objective fitness
and different approximations are possible, for instance different instances of generalization performance [4, 5].
Put another way, this interpretation suggests that in game playing there are different degrees of objective
fitness.
Application examples of CEAs have frequently reported experiments showing mediocre performance,
mostly attributed to coevolutionary intransitivity [3, 9, 21]. Generally speaking, intransitivity occurs when
superiority relations are cyclic. Such cyclic superiority relations have consequences for coevolutionary dynamics as intransitivity may occurs across subsequent generations. In such a case, it may be that all solutions
at generation k + 1 are better than at k, and that the same applies for k + 2 with respect to k + 1. This,
however, does not imply that the solutions at k + 2 are strictly better than at k. Cyclic superiority relations
that occur across generations are connoted as coevolutionary (dynamic) intransitivity. In this paper, the
problem of coevolutionary intransitivity is linked to the dichotomy between subjective and objective fitness.
This is done by combining a rating– and ranking–based measuring approach of intransitivity proposed by
Samothrakis et al. [19] with a framework of codynamic fitness landscapes recently suggested [18]. Codynamic
fitness landscapes enable to analyse the relationship between objective and subjective fitness for all possible
solutions of the coevolutionary search process. The landscape approach proposed particularly explores how
coevolutionary intransitivity is related to the objective–versus–subjective–fitness issue. The remainder of
the paper is structured as follows. In the next section, the concept of codynamic landscapes composed of
objective and subjective fitness is briefly recalled. In Sec. 3, intransitivity is discussed. For the discussion, a
simple random game is introduced, where the degree of randomness can be continuously tuned. It is shown
that intransitivity can be characterized by different types of intransitivity measures. Numerical experiments
with the simple random game are presented in Sec. 4, and Sec. 5 concludes the paper with a summary.

2

Coevolution, codynamic landscapes and number games

This section focuses attention on an approach recently suggested [18] that is useful for understanding coevolutionary dynamics through codynamic fitness landscapes. Such landscapes allow studying the relationship
between objective and subjective fitness which, in turn, mainly determines coevolutionary dynamics.
We define objective fitness as the triple of search space S with search space points s ∈ S, neighborhood
structure n(s) and fitness function fobj (s). The objective fitness landscape can be considered as to describe
the optimization problem to be solved by the CEA. This problem solving is based on coevolutionary interactions between potential solutions which yields subjective fitness. Hence, subjective fitness can be viewed as
the way the CEA perceives the problem posed by the objective fitness. From this, it appears to be sensible
to assume that the subjective landscape possesses the same search space and neighborhood structure, but
has a fitness function fsub that more or less strongly deviates from the objective fitness fobj . This can be
seen as the subjective fitness usually overestimating or underestimating objective fitness. Moreover, for a
coevolutionary run, the deviation between objective and subjective fitness is dynamic. In other word, the
coevolutionary dynamics dynamically deforms the subjective fitness landscape. In the following, the link between subjective and objective fitness is exemplified for a number game, which is also called a coevolutionary
minimal substrate [18, 21].
In this number game a population P of players is considered that inhabits the search spaces S. The
search space is one–dimensional and real–valued. At each instance of the game k = 0, 1, 2, . . ., the players
of P (k) may have possible values s ∈ S. An objective fitness function is defined over the search space, that
is fobj (s), which consequently casts an objective fitness landscape. The subjective fitness of P (k) is the
result of an interactive number game. Therefore, for each calculation of the subjective fitness fsub (s) for a
player from P , a sample σ(E) of evaluators from E ⊆ P is randomly selected. This sample is statistically
independent from the sample for the next calculation. Denote µ the size of the sample σ(E) out of λ
evaluators, with µ ≤ λ. The number game further defines that the fitness fsub (s) with respect to the sample
2

σ(E) is calculated by counting the (averaged) number of members in σ(E) that have a smaller objective
fitness fobj (σi (E)), i = 1, 2, . . . , µ, than the objective fitness fobj (s) [18]:
µ

1X
eval(s, σi (E))
fsub (s) =
µ


with

eval(s, σi ) =

i=1

1
0

if fobj (s) > fobj (σi )
.
otherwise

(1)

Note that the number game considered postulates objective fitness and defines by Eq. (1) how subjective
fitness is obtained by a coevolutionary interaction. In the next section, this perspective of subjective and
objective fitness is applied to games with players and strategies. A population of players is engaged to
evaluate their subjective fitness by interaction with other players.

3

Static and coevolutionary intransitivity in games

A relation R is called intransitive over a set S if for three elements {s1 , s2 , s3 } ∈ S the relation (s1 Rs2 ) ∧
(s2 Rs3 ) does not always imply s1 Rs3 . An instance of intransitivity is superiority relations that are cyclic,
which in its most obvious and purest form appears in game playing. Cyclic superiority relations here mean
that for three players and three strategies s1 , s2 and s3 , the player using s1 wins against s2 , and s2 wins
against s3 , but s1 loses against s3 . A simple example is a rock–paper–scissor game, where “paper” wins over
“rock”, “scissor” wins over “paper”, but “scissor” loses against “rock”. Thus, “paper”, “rock” and “scissor”
are possible strategies a player can adopt in this game. Note that this kind of intransitivity is a feature of
the preference in a single round of the game. Hence, such an intransitivity is static (and actually game–
induced) and has no immediate link to (co-)evolutionary dynamics. Consequently, the next question is how
these superiority relations resemble situations with coevolutionary intransitivity and can be understood by
the dichotomy between subjective and objective fitness. To obtain (co-)evolutionary dynamics, the players
need to adjust their strategies, and the game needs to be played for more than one round. In other words,
studying iterated games is also interesting as it serves to juxtapose static (game–induced) intransitivity with
coevolutionary (dynamic and search–induced) intransitivity.
One way to build a relationship between game results and fitness is to apply a rating system. Examples
of rating systems are the Elo system to evaluate chess players [8, 11], or the Bradley–Terry–Luce model of
paired comparison [2, 12]. Recently, it has been shown that this methodology is also useful for analyzing
coevolutionary intransitivity [19]. A rating system creates a probabilistic model based on past game results
that can be seen as a predictor of future results. Most significantly, the rating system also imposes a
(temporal) ranking of the players. In the following, these ideas are applied to a simple random game where
the degree of randomness can be tuned. The game consists of players using a strategy to perform against all
other players once, called a round robin tournament. The game outcome, which can be interpreted as payoff,
is subject to the players’ ratings and random. Given that the game has N players, there are N (N2−1) games in
a single round robin. Define a percentage prand of games that have a random result to obtain prand · N (N2−1)
games whose outcome is chance with a predefined distribution. The remaining games end deterministically
according to the rating difference between the players. Thus, such a game falls into the category of perfect
and incomplete information. Viewed over a series of round robin tournaments, this interaction between
rating–based determinism and random chance creates temporal “rating triangles”, where a player scores
high results (and has a high rating) over a certain time, but may also lose against a nominal weaker (low–
rating) player, which over time may or may not show the same characteristics towards a third player. Such
a behavior complies with coevolutionary (dynamic and actually search–induced) intransitivity. In addition,
the game can also reproduce rock–paper–scissor–like intransitivities. For N players the maximal number of
static intransitivities is


(N − 2)(N − 1)N
N
#intra max =
=
,
(2)
3
6
see [6, 19]. Any three players form a triangle of cyclic superiority relations if they each win one game
against the other two. Thus, for N not very large, the (average) number of actual static intransitivities
3

#
1
2
3
4
5

rt(0)
1600
1600
1600
1600
1600

Table 1: Results of the simple random game for three instance
#1 #2 # 3 #4 #5 sc(0) rt(1) #1 #2 # 3 #4
x
1
1
1
1
4
1630
x
0
1
1
0
x
1
0
1
2
1600
1
x
1
1
0
0
x
1
1
2
1600
0
0
x
0
0
1
0
x
1
2
1600
0
0
1
x
0
0
0
0
x
0
1570
0
1
1
0

of the game
#5 sc(1)
1
3
0
3
0
0
1
2
x
2

rt(2)
1642
1615
1570
1600
1573

gp
3.5
2.5
1
2
1

rank
1
2
4.5
3
4.5

can be determined by enumeration and gives a static intransitivity measure called the intransitivity index
(itx) [6, 19]. As an alternative, Samothrakis et al. [19] suggested to use a difference measure based on
Kullback–Leibler divergence (kld) between the prediction made by the rating system and the actual outcome
to measure static intransitivity. Both quantities itx and kld are subjects of the numerical experiments
reported in the next section.
A game in a coevolutionary setting involves finding the strategy a player should adopt to score best
according to a given understanding of performance. This clearly implies that the performance measurement
should generalize a single round robin tournament. Thus, if there are several instances of round robin
tournaments, the overall results can also be accounted for by generalization performance [4, 5]. Each instance
of a round robin can be scaled to a generation of coevolutionary run–time. Generalization performance is
defined as mean score of a solution in all possible test cases. Because considering all possible test cases may
be computationally infeasible, Chong et al. [4, 5] used a statistical approach involving confidence bounds to
estimate the amount of needed test cases for a given error margin. Given this understanding, and assuming
that all strategies are equally likely to be selected as test strategies, the generalization performance of
strategy i is:
K
1 X
gpi =
sci (k),
(3)
K
k=1

where sci (k) is the score the i-th strategy yields in the k–th instance of a round robin tournament. The needed
number of instances K depends on the bounds given by Chong et al. [4, 5]. Generalization performance also
builds a relationship between actual game results and fitness and therefore can be seen as an alternative to
a rating system.
As an example of the simple random game assume that there are five players (N = 5), denoted as #1 to
#5, which each act upon a unknown, but internally adjusting strategy. Further assume that as an a–priori
evaluation all players are considered equal and have the same rating, say rt(0) = 1600. These players are
now engaged in a round robin tournament, where a win scores 1 and a loss counts 0. The results achieved
depend on the pre–game rating and random. Assume that these results were scored, see Tab. 1, column
3–7. While player #1 wins all games and #5 loses all games, the players #2–#4 build a rock–paper–scissor
triangle of cyclic superiority relations. These results somehow violate the expectations established by the
initial (pre–game) rating, which could have been met by all players winning 2 out of 4 games. Furthermore,
the results show clearly that the game cannot be completely deterministic with respect to the a–priori
evaluation. In other words, a rating and ranking approach subsumes the game history and can only be
a predictor of future game results. The quality of prediction depends on the percentage of random game
results. Also, from the results of the round robin, it is not evident whether player #1 was as successful
as it was because its strategy was (objectively) good, or because the strategies of the other players were
(objectively) poor. All, the round robin gives is a comparison.
The a–priori rating were indicating that all players have the same rank (and hence there is no ranking
difference between them), but the results were showing otherwise. Hence, the round robin tournament
updates the rating, producing an after–game rating. According to the Elo system [8, 11], which is adopted

4

sc(
1
4
0
2
3

here, this is done via first calculating the expected outcome
exi (k) =

1

X
j

1+

10(rtj (k)−rti (k))/400

.

(4)

The quantity exi (k) summarizes winning probabilities of player #i with respect to all other players in round
k. For a single game, that is j = 1, the quantity exi is the expected winning probability for the player #i
winning against player #j. For the example with all players having the same rating, the expected outcome
is also the same, namely exi = 2. The rating of the players is updated according to the difference between
expectation and actual score:
rti (k + 1) = rti (k) + K(sci (k) − exi (k)).

(5)

The K is called the K–factor, which tunes the sensitivity between the rating and the results of a single
round robin tournament. Using K = 15, the new rating rt(1) gives differences between the players, see
Tab. 1, column 9. The best player #1 is now ranked highest, the poorest player #5 is ranked lowest.
Also note that the players #2–#4 engaged in the game–induced intransitivity triangle still share the same
rating as before. Now assume the next round of the game. The strategies of the players have been adjusted,
supposedly by a (competitive) coevolutionary search process. See the results in Tab. 1, column 10–14. The
outcome generally confirms the impression of the first round with player #1 still being strong. Violating
the expectations are the good scores of the players #2 and #5, and the poor score of player #3. Note that
in this round the players #1, #2, and #5 as well as the players #2, #4, and #5 form a rock–paper–scissor
triangle of game–induced intransitivity. Contrary to the first round, these players now neither have the same
score, nor the same pre–game or after–game rating. This after–game rating rt(2) is calculated according to
Eq. (5) and given in Tab. 1, column 16.
As there are now two instances of the round robin tournament, an first estimation of the generalized
performance gp can be obtained by averaging the scores according to Eq. (3). The results are given in Tab.
1, column 17. Conforming with this account of quality evaluation, player #1 is best, and can be ranked first,
followed by players #2 and #4. The ranking with respect to generalization performance is given in Tab. 1,
column 18. Note that the ranking gives average ranks for tied ranks as for player #3 and #5 (gp = 1 leads
to rank = 4.5), which preserves the sum over all ranks. Further note that this ranking is almost equal to
the ranking according to ratings, with the exception of players #3 and #5 which have a very similar but
not equal rating.
Now, the simple random game is interpreted according to the landscape view of subjective and objective
fitness. Recall that subjective fitness is associated with fitness gained by individuals through interaction
with others. According to this view, a round robin tournament yields subjective fitness: fsub = sc(k).
Objective fitness, in turn, generalizes subjective fitness in terms of an absolute quality measurement. Possible
candidates are the rating fobj = rt(k) or generalization performance fobj = gp(k). Defining subjective and
objective fitness in such a way also gives raise to reformulating coevolutionary intransitivity. Generally
speaking, coevolutionary intransitivity involves cycling of (objective) solution quality. This cycling may be
caused by subjective fitness not adequately representing objective fitness. Hence, subjective fitness may
drive evolution into search space regions visited before but evaluated differently, or generally into directions
not favorable. Hence, coevolutionary (dynamic) intransitivity can be understood as temporal mismatches
in order between subjective and objective fitness. Consider again the example of the game whose results are
given in Tab. 1. Suppose another instance of the round robin is played, and (omitting the specific results)
the scores are in Tab. 1, column 19. The rating rt(k) is considered to be objective, while sc(k) is subjective.
For player #1, the rating is rt1 = 1600 ≤ 1630 ≤ 1642, while its score is sc1 = 4 > 3 > 1, which is a
temporal mismatch between objective and subjective fitness. If we were to suppose for a moment that the
rating declared as objective fitness is indeed the quantity to achieve in coevolutionary search, and if a CEA
were to use score for guiding this search, then player #1 would likely be misguided. On the other hand,
for player #2, the rating rt2 = 1600 ≤ 1630 ≤ 1642, and the score sc2 = 2 < 3 < 4 show a match between
5

6

2000

6

1900

5

5

1800
4

3

1700

gp(k)

rat(k)

sc(k)

4

3

1600
2

2
1500

1

0
0

1

1400

2

4

6

8

10

12

14

16

18

1300
0

20

2

4

6

8

10

k

12

14

16

18

0
0

20

2

4

6

8

k

(a)

14

16

18

20

12

14

16

18

20

(c)

2000

6

1900

5

12

k

(b)

6

10

5

1800
4

3

1700

gp(k)

rat(k)

sc(k)

4

3

1600
2

2
1500

1

0
0

1

1400

2

4

6

8

10

12

14

16

18

20

1300
0

2

4

6

8

10

k

(d)

12

14

16

k

(e)

18

20

0
0

2

4

6

8

10

k

(f)

Fig. 1. Scores, ratings, and generalization performance for two percentages of random games: (a)–(c),
prand = 0.01; (d)–(f), prand = 0.75.
subjective and objective fitness. These conditions can be reformulated employing a ranking function with
tied ranks and gives a measure of coevolutionary intransitivity. Hence, the player–wise temporal mismatch
(ptm) can be defined as the average number of rank mismatches: rank(fobj (k), fobj (k + 1)), fobj (k + 2)) 6=
rank(fsub (k), fsub (k + 1)), fsub (k + 2)) for each player for a given number of instances of round robins.
An alternative measure of coevolutionary intransitivity that is related to the ptm just discussed stems
from the fact that coevolutionary selection is based on comparing subjective fitness values. Hence, the fitness
ranking within one instance of the game (or one generation) gives indication as to what direction is preferred.
If difficulties in the search process are caused by how well subjective fitness represents objective fitness,
then the difference in the ranking according to subjective fitness and the ranking according to objective
fitness for each instance is also a suitable measure of coevolutionary intransitivity. Therefore, the quantity
|rank(fsub (k)) − rank(fobj (k))| over all players for each instance k is another measure of coevolutionary
intransitivity and is called collective ranking difference (crd). The observations discussed so far suggest
some relationships, namely that game–induced, static intransitivity has ambiguous effect on coevolutionary
progress, and that coevolutionary, dynamic intransitivity can be expressed as ranking differences between
objective and subjective fitness. In other words, the quantities ptm and crd may be useful as measures of
coevolutionary intransitivity. All these relationships can be studied by numerical experiments, which are
the topic of next section.

6

0.018

0.018

0.018

prand

prand

0.016

prand

0.016

0.016

0.85

0.85

0.014

0.85

0.014
0.50

0.012

0.014
0.50

0.012

0.008

itx

0.01

itx

0.01

itx

0.01

0.008
0.20

0.006

0.008
0.20

0.006

0.004

0.004
0.10

0.002

0.002

0.01
4

6

8

10

12

14

0.01
0
0

16

500

1000

1500

2000

sc

2500

3000

0.01
0
0

3500

(b)

0.2

0.2

N = 32

0.1

<itx>

0.2

<itx>

0.25

0.15

0.15

0.2

0.25

0.3

0.35

N = 24
0.15

N = 16

0.05

N=8
0.4

0.45

0.5

0
0

kld

(d)

N = 32

0.1

N = 16

N=8
0.15

1

N = 24
0.05

N = 16

0.1

0.8

N=8

N = 32

0.1

N = 24
0.05

0.6

(c)

0.25

0.05

0.4

gp

0.25

0
0

0.2

rt

(a)

<itx>

0.10

0.002

2

0.20

0.006

0.004
0.10

0
0

0.50

0.012

0.01

0.02

0.03

0.04

0.05

0.06

ptm(sc,rt)

(e)

0.07

0.08

0
0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

ptm(sc,gp)

(f)

Fig. 2. Intransitivity measure itx versus score = sc(k), rating rt(k) and generalization performance gp(k)
(a–c) as scatter plots; relationships between the intransitivity measure itx, kld, and ptm (d–f)

4

Numerical experiments

The report of experimental results starts with the time evolution of the simple random game introduced
in the last section. Fig. 1 shows the scores, ratings and generalization performances for two different
percentages of random results (prand = 0.01 and prand = 0.75) and N = 6 players and 20 instances of
a round robin. The experiments are initialized with ratings rt(0) being slightly spread around the value
rt(0) = 1600. The randomly determined chance to win or to lose is evenly distributed. The figures show
curves for a single instance of the randomly determined part of the game outcomes. Hence, the curves are
not meant to be statistically significant, but for illustrating typical behaviour only. It can be seen that for
a low number of random outcome (Fig. 1a,b,c) the scores each player achieves are mainly defined by the
initial rating. Small differences in the initial rating are amplified and lead to well–sorted long–term rankings
of both the rating and generalization performance. For a large number of random game results (Fig. 1d,e,f)
the scores are almost purely chance which is evenly distributed. Consistently, ratings and generalization
performances tend to approach the expected value implied by the underlying distribution for all players alike.
The next experiments address the relationships between static (game–induced) intransitivity expressed by
the measure itx and quantities representing subjective as well as objective fitness. The scatter plots given in
Fig. 2a,b,c are for N = 16 players and five levels of prand . The experimental setup includes a repetition of
each run for 100 times for 1000 instances of the round robin, where the first 200 instances are discarded to
omit transients. Note that this gives a sufficient number of instance according to the bounds of generalization

7

2
prand

1.6

0.20

0.05

0.10

1.2
0.50
1
0.8
0.20

0.6
0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

0.50
1
0.8
0.20

0.4
0.10

0.10
0.2

0.01

0.01
0.4

1.2

0.6

0.2

0.2

0.85

1.4
crd(sc,gp)

crd(sc,gp)

0.15

0.1

1.6

0.85

1.4

0.50

0.2

0
0

prand

1.8

0.85

0.25

<itx>

2
prand

1.8

0
0.4

2

0.5

0.6

0.7

crd(sc,gp)

0.8

0.9

1

0.01
0
0.4

1.1

0.5

0.6

0.7

max sc

(a)

0.8

0.9

1

1.1

max gp

(b)

(c)

2.5

0.07

0.06

0.25

2
0.05

0.15

1.5

N = 32

1

N = 32

0.1

ptm(sc,rt)

crd(sc,gp)

<itx>

0.2
0.04

0.03

N = 24
N = 32

0.02
N = 16

N = 24

N = 24

0.5

0.05

N=8

N = 16

N = 16

0.01

N=8

N=8
0
0

0.5

1

1.5

2

2.5

0
0

crd(sc,gp)

(d)

0.2

0.4

0.6

0.8

1

1.2

1.4

crd(sc,rt)

(e)

1.6

1.8

0
0

0.2

0.4

0.6

0.8

1

1.2

1.4

1.6

1.8

crd(sc,rt)

(f)

Fig. 3. Intransitivity measure crd versus time average itx, max sc, and max pg (a–c) as scatter plots;
relationships between the intransitivity measure crd, itx, and ptm (d–f)
performance [4, 5]. Hence, the results can be seen as statistically significant. In fact, the 99% confidence
intervals are so small that they are not depicted in the figures. It can be seen that for each level of
randomness in the game, we obtain a distinct level of static intransitiviy measured by itx, where rising prand
also increases itx. What is interesting is that there is almost no variation in score, rating or generalization
performance for a given level of intransitivity itx. This indicates that static intransitivity seems to have little
influence on neither subjective nor objective fitness. This is particularly visible for low levels of prand where
these is a clear sorting according to the range of fitness a given player achieved but this is not connected to
differences in the itx. A next experiment explores the relations between the index based measure itx and the
probabilistically motivated measure kld, see Fig. 2d. Here as well as in the following figure the results are
for four different number of players N (N = 8, 16, 24, 32) and five levels of random results prand ; the time–
average itx, denoted hitxi, is given, the quantities are normalized according to the number of players. It can
be seen that between both quantities there is a proportional relationship, which on the one hand generally
confirms the result in [19], but does not show that itx is more brittle that kld. For the studied game it can be
concluded that both quantities are interchangeable. Next, the relationship between the static intransitivity
and the dynamic intransitivity measure player–wise temporal mismatch (ptm) is studied, Fig. 2e,f. For the
mismatch ptm based on rating as objective fitness (Fig. 2e) there is a linear relationship, at least for small
values of prand , for the mismatch ptm based on generalization performance (Fig. 2f), no sensible conclusions
about relations can be drawn. Finally, we focus on the rank–based dynamic intransitivity measure collective
ranking difference (crd), see Fig. 3. The Fig. 3a,b,c again shows scatter plots, now for the crd based on

8

score as subjective fitness and generalization performance as objective fitness for N = 16 players and five
levels of prand . It can be seen that although different prand give different itx, there is no difference in the
crd, Fig. 3a. However, there is a almost linear relation between the measure crd and max sc and max
gp, at least for lower levels of prand . This can be interpreted as the crd scaling with the time evolution of
the subjective and objective fitness, but not with the time evolution of static intansitivity, compare to Fig.
2a,b,c, which does not show such a characteristics. For the time–averages, there is a scaling for different
number of players and different levels of randomness prand , see Fig. 3d. In Fig. 3e, the relation between
the crd based on rating as objective fitness (crd(sc,rt)) and the crd based on generalization performance as
objective fitness (crd(sc,gp)) is shown. It can be seen that both quantities scale piece-wise linear for prand
not very large, which allows to conclude that both quantities account for the same intransitivity properties.
Finally, the relation between the crd and ptm is shown, Fig. 3f. It can be seen that the ptm scales weaker
than the crd, particularly for a small number of players and high randomness, and it can be conjectured
that the crd is a more meaningful coevolutionary intransitivity measure than the ptm.

5

Conclusions

This paper is a contribution to the ongoing discussion about the effect of intransitivities on coevolutionary
progress. An approach was presented that allowed to link a rating– and ranking–based measuring approach
of intransitivity [19] with a framework of fitness landscapes to enable analyzing the relationship between
objective and subjective fitness. For experimentally illustrating the approach a simple random game with
continuously tunable degree of randomness was proposed. Apart from the random, the game results depend
on the ratings of the players, which reflect the past success of each player. Thus, the game proposed
characterizes many real–world games as their outcome is also a function of chance as well as of predictions
based on game history.
For studying the effect of intransitivity, measures were explored. In extension of existing static intransitivity measures, dynamic measures that can account for coevolutionary intransitivity were proposed. These
measure are based on rankings between subjective and objective fitness and it was shown that coevolutionary intransitivity can be understood as a ranking problem, and hence be accounted for by ranking statistics.
To enlarge the scope of the presented approach, as a next step the intransitivity measures could be studied
for other types of game for instance social games as the iterated prisoner’s dilemma or board game such as
Othello.

References
[1] T. Antal, H. Ohtsuki, J. Wakeley, P. Taylor, M. A. Nowak, Evolutionary game dynamics in phenotype
space. Proc. Nat. Acad. Sci. 106: 8597–8600, 2009.
[2] R. A. Bradley, M. E. Terry, Rank analysis of incomplete block designs, I. the method of paired comparisons. Biometrika 39: 324–345, 1952.
[3] E. D. de Jong, Intransitivity in coevolution. In: X. Yao et al. (eds.), Parallel Problem Solving from
Nature–PPSN VIII, Springer–Verlag, Berlin Heidelberg New York, 843–851, 2004.
[4] S. Y. Chong, P. Tino, X. Yao, Measuring generalization performance in coevolutionary learning. IEEE
Trans. Evolut. Comp. 12: 479–505, 2008.
[5] S. Y. Chong, P. Tino, D. C. Ku, X. Yao, Improving generalization performance in coevolutionary
learning. IEEE Trans. Evolut. Comp. 16: 70–85, 2012.
[6] O. Frank, F. Harary, Cluster inference by using transitivity indices in empirical graphs. Jour. Am.
Statist. Assoc. 77: 835–840, 1982.
9

[7] E. D. de Jong, Objective fitness correlation. In: H. Lipson (ed.), Proc. Genetic and Evolutionary
Computation Conference, GECCO 2007, ACM, New York, 440–447, 2007.
[8] A. E. Elo, The Rating of Chess Players, Past and Present. Batsford, London, 1978.
[9] P. Funes, E. Pujals, Intransitivity revisited coevolutionary dynamics of numbers games. In: H. G.
Beyer, U. M. O’Reilly (eds.), Proc. Genetic and Evolutionary Computation Conference, GECCO 2005,
Morgan Kaufmann, San Francisco, CA, 515–521, 2005.
[10] L. Kallel, B. Naudts, C. R. Reeves, Properties of fitness functions and search landscapes. In: L. Kallel,
B. Naudts, A. Rogers (eds.), Theoretical Aspects of Evolutionary Computing, Springer–Verlag, Berlin,
Heidelberg, New York, 177–208, 2001.
[11] A. N. Langville, C. D. Meyer, Who’s #1? The Science of Rating and Ranking. Princeton University
Press, Princeton, NJ, 2012.
[12] R. D. Luce, Individual Choice Behaviours: A Theoretical Analysis. John Wiley, New York, 1959.
[13] T. Miconi, Why coevolution doesn’t “work”: Superiority and progress in coevolution. In: L. Vanneschi,
et al. (eds.), EuroGP 2009, Springer–Verlag, Berlin Heidelberg New York, 49–60, 2009.
[14] M. A. Nowak, C. E. Tarnita, T. Antal, Evolutionary dynamics in structured populations. Phil. Trans.
R. Soc. B 365: 19–30, 2010.
[15] E. Popovici, A. Bucci, R. P. Wiegand, E. D. de Jong, Coevolutionary principles. In: G. Rozenberg, T.
Bäck, J. N. Kok (eds.), Handbook of Natural Computing, Springer–Verlag, Berlin Heidelberg New York,
987–1033, 2010.
[16] H. Richter, A. P. Engelbrecht, Recent Advances in the Theory and Application of Fitness Landscapes,
Springer–Verlag, Berlin Heidelberg New York, 2014.
[17] H. Richter, Fitness landscapes that depend on time. In: H. Richter, A. P. Engelbrecht (eds.), Recent
Advances in the Theory and Application of Fitness Landscapes, Springer–Verlag, Berlin Heidelberg New
York, 265–299, 2014.
[18] H. Richter, Codynamic fitness landscapes of coevolutionary minimal substrates. In: C. A. Coello Coello
(ed.) Proc. IEEE Congress on Evolutionary Computation, IEEE CEC 2014, IEEE Press, Piscataway,
NJ, 2692–2699, 2014.
[19] S. Samothrakis, S. M. Lucas, T. P. Runarsson, D. Robles, Coevolving game–playing agents: Measuring
performance and intransitivities. IEEE Trans. Evolut. Comp. 17: 213–226, 2013.
[20] R. P. T. van Wijngaarden, E. D. de Jong, Evaluation and diversity in co-evolution. In: G. Rudolph
et al. (eds.), Parallel Problem Solving from Nature–PPSN X, Springer–Verlag, Berlin Heidelberg New
York, 631–640, 2008.
[21] R. A. Watson, J. B. Pollack, Coevolutionary dynamics in a minimal substrate. In: L. Spector et al.
(eds.), Proc. Genetic and Evolutionary Computation Conference, GECCO 2001, Morgan Kaufmann,
San Francisco, CA, 702–709, 2001.

10

