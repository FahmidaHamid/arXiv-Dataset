arXiv:1503.06308v1 [q-bio.PE] 21 Mar 2015

Similarity of general population matrices and
pseudo-Leslie matrices
João F. Alves1 and Henrique M. Oliveira2
Center of Mathematical Analysis, Geometry and Dynamical Sistems, Departamento de
Matemática, Instituto Superior Técnico, Universidade de Lisboa, Av. Rovisco Pais,
1049-001 Lisbon, Portugal

Abstract
A similarity transformation is obtained between general population matrices models of the Usher or Lefkovitch types and a simpler model, the pseudoLeslie model. The pseudo Leslie model is a matrix that can be decomposed
in a row matrix, which is not necessarily non-negative and a subdiagonal
positive matrix. This technique has computational advantages, since the solutions of the iterative problem using Leslie matrices are readily obtained .
In the case of two age structured population models, one Lefkovitch and another Leslie, the Kolmogorov-Sinai entropies are different, despite the same
growth ratio of both models. We prove that Markov matrices associated to
similar population matrices are similar.
Keywords:
Population dynamics, Leslie matrix, Lefkovitch matrix, Kolmogorov Sinai
entropy, Markov matrices.
2012 MSC: 37N25, 15A21, 92D25
1. Introduction
This article deals with classic discrete structured models for linear population dynamics [2, 8] such as Leslie matrices and Lefkovitch or Usher matrices.
Giving A, a non negative n × n matrix and a population vector xk which
1
2

jalves@math.tecnico.ulisboa.pt
corresponding: holiv@math.tecnico.ulisboa.pt

Preprint submitted to ArXiv

March 29, 2015

components are the fractions of the population at each age or stage, the dynamical system that gives the population vector at any positive time k + 1
is given by
xk+1 = Axk , with initial condition x0 .
Obviously the solution is given by the powers of A
xk = Ak x0 .
In this paper we prove that there is a similarity transform that converts
the complicated dynamics of the so called Usher or Lefkovitch matrices to the
simpler study of matrices which are Leslie matrices or pseudo-Leslie matrices,
a concept that we introduce in this paper.
The paper is organized in three sections, in the second we introduce
pseudo-Leslie matrices and prove the main theorem. In the third section
we present some consequences of interest in population dynamics, namely on
the similarity of Markov matrices associated to similar population dynamics matrices and obtain transformation rules for corresponding stationary
distributions.
2. Main theorem
In age structured population dynamics one divides the population in
classes [2, 7]. When we consider size classes or stage classes instead of pure
age classes we have a structured population model with dynamics given by
the linear equation
xn+1 = Lxn ,
(1)
where xn is a non negative structured absolute population vector, or a proportion of individuals in each class and L is a matrix such that


f1 f2 f3 · · · fn−1 fn
 b1 c1 0 · · ·
0
0 


 0 b2 c2 · · ·
0
0 


L =  .. .. .. . .
..  ,
..
 . . .
.
. 
.


 0 0 0 · · · cn−2
0 
0 0 0 · · · bn−1 cn−1
usually called Usher (in the classic reference [2]) or Lefkovitch matrix in [7].
The coefficient fj is called the fertility rate of class j > 1, the coefficient
2

bk > 0, for any k = 1, . . . , n − 1, is the transition rate from class k − 1 to
class k and the cl the rate of individuals that remain in class l. Along this
paper we assume that fn > 0, assuring that L is irreducible [2].
The coefficient f1 can be decomposed in fb1 + c0 , i.e., a fertility rate and a
permanency rate. Since this decomposition has no influence on the similarity
transformation we do not split f1 . One must keep in mind the biological
meaning of this coefficient.
The solution of the problem is given by the powers of L, given the nonnegative initial condition x0
xn = Ln x0 .
A Leslie matrix is a matrix of the type


φ1 φ2 · · · φn−1 φn
 b1 0 · · ·
0
0 


 0 b2 · · ·

0
0
L=
,
 ..
.. . .
..
.. 
 .
.
.
.
. 
0 0 · · · bn−1 0
where all the entries φj are non-negative and all bj are strictly positive. The
Leslie matrix can be decomposed in two matrices
L = R + B,
where





R=



φ1 φ2
0 0
0 0
..
..
.
.
0 0



0 0
· · · φn−1 φn


···
0
0 
 b1 0

···
0
0 
 and B =  0 b2
 .. ..
.. 
..
..
 . .
.
. 
.
0 0
···
0
0

···
···
···
..
.

0
0
0
..
.

0
0
0
..
.

· · · bn−1 0






.



When the entries φn of the first row of R are real numbers, not restricted to
the non-negative case, we say that L is a pseudo-Leslie matrix. Obviously this
class of matrix does not have an immediate biological correspondence when
some of its entries are negative. That poses no problem in the framework of
this article, since L is merely used as a computational instrument.
3

To state the main theorem we define the sums of products of p factors Γpi ,
where i = 1, ..., n denotes the row index of a given n × n Lefkovitch matrix
L
Γpi =

X
p

(−1)
ci1 ci2 · · · cip if 0 < p ≤ n − i


n−1≥ip >···>i2 >i1 ≥i
.
1
if p = 0



0
if n − i < p
For the products of the transition rates b1 , ..., bn−1 of L we use the notation

j
Y



bk if i ≤ j ≤ n − 1
.
Λji =
k=i



1
if j = i − 1

Now we introduce an upper triangular matrix S and a pseudo-Leslie matrix
L defined by


1 s1,2 s1,3 · · · s1,n−1 s1,n
 0 1 s2,3 · · · s2,n−1 s2,n 



 0 0
1
·
·
·
s
s
3,n−1
3,n 

S =  ..
,
..
..
..
..
..

 .
.
.
.
.
.


 0 0
0 ···
1
sn−1,n 
0 0
0 ···
0
1
with
si,j
and

with







L=




Γij−i
= j−1 , for j ≥ i
Λi

· · · φn−1 φn
···
0
0 

···
0
0 

..
..  ,
..
.
.
. 

···
0
0 
· · · bn−1 0

φ1 φ2 φ3
b1 0 0
0 b2 0
..
..
..
.
.
.
0 0 0
0 0 0
j

X Γj−k
Γj1
k
+
φj = − j−1
j−1 fk , for j = 1, ..., n.
Λ1
Λ
k
k=1
4

We are now in position to state the main result of this work.
Theorem 1. For any Lefkovitch matrix, L, one has S −1 LS = L where S
and L are the matrices defined above.
The following lemma is used in the proof of theorem 1.
Lemma 2. If L is a n × n Lefkovitch matrix, then Γp+1
= ci−1 Γpi + Γp+1
i
i−1 , for
all p ≥ 0 and n ≥ i > 1.
Proof. As Γ0i = 1, Γ1i − Γ1i−1 = ci−1 and Γpi = Γp+1
= Γp+1
i
i−1 = 0 for p > n − i,
the proof is obvious for p = 0 or p > n − i . So we may assume 0 < p ≤ n − i.
If 0 < p < n − i, then
X
p+1
ci1 ci2 . . . cip+1
Γp+1
i−1 = (−1)
n−1≥ip+1 >···>i2 >i1 ≥i−1

= (−1)p+1

X

ci1 ci2 . . . cip+1

n−1≥ip+1 >···>i2 >i1 ≥i

− (−1)

p

X

ci−1 ci2 . . . cip+1

n−1≥ip+1 >···>i2 ≥i

= Γp+1
− ci−1 Γpi .
i
Finally, assume that 0 < p = n − i. In this case, as Γp+1
= 0, one gets
i
ci−1 Γpi + Γp+1
i−1 =
= ci−1 (−1)p ci ci+1 . . . cn−1 + (−1)p+1 ci−1 ci . . . cn−1
= 0 = Γp+1
. 
i
We are now in position to prove the main result.
Proof of theorem 1. In order to prove the equality LS = SL, we begin by
computing SL. As si,i = 1 and si,j = 0 for i > j, one has

si,1 φn
if j = n
(SL)i,j =
si,1 φj + si,j+1 bj if j < n

φn
if i = 1, j = n




 φj + s1,j+1 bj if i = 1, j < n
bj
if i = j + 1
.
=


s
b
if n > j ≥ i > 1


 i,j+1 j
0
otherwise
5

As Γn1 = 0 and Λj1 = Λ1j−1 bj one has
n

φn = −
=

X Γn−k
Γn1
k
+
fk
Λ1n−1 k=1 Λkn−1

n
X
Γn−k
k

Λn−1
k=1 k

fk ,

and
j

φj + s1,j+1bj = −

X Γj−k
Γj1
Γj1
k
f
+
+
bj
k
Λ1j−1 k=1 Λkj−1
Λj1
j

X Γj−k
Γj1
Γj1
k
fk + j−1
= − j−1 +
Λ1
Λj−1
Λ1
k=1 k
=

j
X
Γj−k
k

Λj−1
k=1 k

fk , for j < n,

finally we get
si,j+1 bj =

Γij+1−i
Γij+1−i
b
=
, for n > j ≥ i.
j
Λji
Λij−1

Thus, we may write

(SL)i,j

 j
X Γj−k


k

fk


Λj−1

 k=1 k
=
bj


Γij+1−i


j−1


 Λi
0

if i = 1
if i = j + 1
if n > j ≥ i > 1
otherwise

Notice that since Γin+1−i = 0 for all i, we finally arrive at
 j
X Γj−k


k

fk if i = 1


Λj−1

 k=1 k
(SL)i,j =
bj
if i = j + 1 .


Γij+1−i


if j ≥ i > 1
j−1


 Λi
0
otherwise
6

.

(2)

Next we compute LS. As si,i = 1 and si,j = 0 for i > j, one has

Pn
if i = 1
k=1 sk,j fk
(LS)i,j =
bi−1 si−1,j + ci−1 si,j if i > 1
 Pj
s f
if i = 1


 k=1 k,j k
bj
if i = j + 1
=
b s
+ ci−1 si,j if j ≥ i > 1


 i−1 i−1,j
0
otherwise
 P
j−k
Γk
j

if i = 1

k=1 Λj−1 fk

k

 b
if i = j + 1
j
=
.
j−i+1
j−i
Γ
Γ
i−1

i

+
c
if
j
≥
i
>
1
b
j−1
j−1
i−1
i−1

Λi−1
Λi


0
otherwise
j−1
As Λi−1
= bi−1 Λij−1 for j ≥ i > 1, one has

bi−1

Γj−i+1
i−1
j−1
Λi−1

+ ci−1

Γj−i+1
Γij−i
Γij−i
i−1
=
+
c
i−1 j−1
Λij−1
Λij−1
Λi
=

Γj−i+1
+ ci−1 Γij−i
i−1
Λij−1

and consequently

(LS)i,j

 P
Γj−k
j
k

fk

k=1

Λj−1
k


bj
=
j−i+1
Γi−1
+ci−1 Γj−i
i



Λj−1

i

0

if i = 1
if i = j + 1
if j ≥ i > 1

.

(3)

otherwise

Now, using lemma 2 we see that (2) and (3) are the same, which completes
the proof. 
The dynamical system (1) can be solved using the easily computable
powers of L
xn = Ln x0 = S −1 Ln Sx0 .
Since L and L are similar, they share the same spectrum and the PerronFrobenius Theorem still holds for L in what concerns the existence of a simple
dominant positive eigenvalue. Using a generating function and formal power
7

series obtained in [1] or the classic Jordan canonical form, it is always possible
to obtain the powers of L. The eigenvectors of L will be studied in the next
section.
3. Sinai Kolmogorov entropy, Markov matrices and stationary distributions
In this section, using a simple example, we show that the KolmogorovSinai entropy [3, 4, 5, 6] is not an algebraic invariant. We also establish that
two Markov matrices associated [6] to population dynamics similar matrices3
are similar. Finally, we establish a transformation rule for the two stationary distributions of Markov matrices associated with two similar population
matrices.
Given two matrices, one of Lefkovitch type and the other of Leslie type4 ,
with the same growth rate, they can have different Sinai-Kolmogorov entropies as we see in the following example.
Example 3. Let
L=



1
3
0.4 0.55





1 −1.375
0
1



,

we have the similarity matrix
S=

,

and a Leslie matrix L similar to L, which is


1.55 1.625
.
L=
0.4
0
The Perron-Frobenius dominant eigenvalue is λ = 1.89331 both for L and
L. The Markov matrix P A [6], corresponding to a population matrix A is
obtained using the relations
pA
ij =
3
4

aij uj
,
λui

Under very general conditions.
We consider a true non-negative Leslie matrix to establish this conclusion.

8

where λ is the dominant eigenvalue of A, and the column vector u = (ui )i=1,...,n >
0 is the Perron-Frobenius right eigenvector of A. (The left eigenvector will
be called the line vector v = (vi )Ti=1,...,n ). For the Lefkovitch matrix L we get
the associated Markov matrix


0.528175 0.471825
L
,
P =
0.709504 0.290496


the stationary distribution of P L is π L = 0.600598 0.399402 . The population Sinai-Kolmogorov entropy [6] is
HL = −

2
X

πiL pLij log pLij ,

i,j

where pLij are the entries of P L and πiL are the components of the stationary distribution π L of P L (the left eigenvector associated with the PerronFrobenius eigenvalue 1 of P L , such that π L P L = π L ). Doing the same computation for L we have
HL = −

2
X

πiL pLij log pLij ,

i,j

where P L is the matrix with entries pLij , the Markov matrix associated to L
is


0.818671 0.181329
L
P =
.
1
0


The stationary distribution of P L is π L = 0.846504 0.153496 and the
entropies of L and L are different, respectively HL = 0.656027 and HL =
0.400738.
The Markov matrices P L and P L associated to L and L are also similar,
with the same eigenvalues as we will see below. This result can be stated
in the general context of similar matrices5 under the following hypothesis,
which are assumed until the end of the paper:
1. L is non-negative and irreducible, therefore has the dominant eigenvalue λ, and associated left and right positive eigenvectors t and w,
respectively.
5

Not necessarily Lefkovitch, Usher or Leslie matrices.

9

2. L and L are similar, related by the invertible similarity matrix S, such
that LS = SL.
3. L, not necessarily non-negative, has right and left eigenvectors, respectively u and v, associated to λ with all entries positive.
The right eigenvector of L associated to the dominant eigenvalue λ
Lu = λu
is related to the right eigenvector w of L by the transformation rule w =Su,
since
LSu =λSu ⇔Lw =λw.
The same happens for the left eigenvector v of L
vL = λv
and the left eigenvector t = vS −1 of L, since
vS −1L=λvS −1 ⇔ tL=λt.
The Markov matrix associated with L [6] is given by its entries
pLij =

Lij uj
.
λui

On the other hand, the Markov matrix associated with L is given by
pLij =

Lij wj
.
λwi

The stationary distribution [6] of P L is


v
u
v
u
.
.
.
v
u
1
1
2
2
n
n
,
πL =
vu
where vu is a compact notation for the inner product of the line vector v
and the column vector u. The stationary distribution of L is


t
w
t
w
.
.
.
t
w
1
1
2
2
n
n
πL =
.
tw
It is possible to prove that the Markov matrices P L and P L are similar.
10

Proposition 4. P L and P L are similar if L and L are similar.
Proof. One defines the square matrices U and W such that



u1
w1



u2
w2



U =
,
W
=


.
..
..



.
un
wn







with all ui 6= 0 and wi 6= 0, the inverses of U and W are

 1
 1
U

−1



=


u1

1
u2

..

.
1
un





 , W −1 = 



w1

1
w2


..

.
1
wn



.


With this notation consider the transformations
PL =

1
1 −1
U LU and P L = W −1 LW ,
λ
λ

where λ 6= 0.
Now, it is straightforward to prove that P L and P L are similar
PL =

1
1 −1
W LW = W −1 SLS −1 W .
λ
λ

On the other hand

1 −1
U LU.
λ
Therefore, λQ and λP are similar, since both are similar to L. Explicitly
PL =

L = λS −1 W P LW −1 S = λUP L U −1
or
P L = U −1 S −1 W P L W −1 SU,

(4)

as desired. 
We can prove that π L is a stationary distribution of P L [6] using matrix
notation.
Proposition 5. The row vector π L is a stationary distribution of P L .
11



Proof. Using the left eigenvector t = t1 t2 . . . tn of L, we define a
diagonal matrix


t1


t2


T =
.
..


.
tn
We have


1 
1 1 ... 1 T W W −1 LW
λtw

1 
t1 t2 ... tn LW ,
=
λtw

πLP L =

since t is a left eigenvector of L we have



1
λ t1 t2 ... tn W
λtw
TW
=
tw
= πL. 

πLP L =

Using analogous techniques we obtain the relation between the two stationary distributions of P L and P L .
Proposition 6. The stationary distributions π L and π L are related by
π L = π L W −1 SU
Proof. From (4) we have
P L = Z −1 P L Z,
where Z = W −1 SU. In that case the stationary distribution π L is given by
the relationship
πLP L = πL,
so
π L Z −1 P L Z = π L ⇐⇒ π L Z −1 P L = π L Z −1 ,
which means that
π L = π L Z −1 ,
as desired. 
12

Remark 7. All the results in this section apply to the case of an irreducible
Lefkovitch matrix L and a similar pseudo-Leslie matrix L, since any matrix
of the form


φ1 φ2 · · · φn−1 φn
 b1 0 · · ·
0
0 



 0 b2 · · ·
0
0
L=
,
 ..
.. 
..
.. . .
 .
.
. 
.
.
0 0 · · · bn−1 0

with positive coefficients bj and with the dominant
itive right eigenvector

 
Λ01
1
 Λ11  
b1
 λ  
λ
 Λ21  
b1 b2


u =  λ2  = 
λ2
..
 ..  
.
 .  
b1 b2 ···bn−1
λn−1

Λn−1
1
λn−1

The similar Lefkovitch matrix

f1
 b1

 0

L =  ..
 .

 0
0

f2 f3
c1 0
b2 c2
.. ..
. .
0 0
0 0

eigenvalue λ has the pos




.



· · · fn−1 fn
···
0
0
···
0
0
..
..
..
.
.
.
· · · cn−2
0
· · · bn−1 cn−1











is always irreducible if fn > 0 and all the bj are positive, [2]. Therefore,
similar Lefkovitch and pseudo-Leslie matrices, L and L, satisfy conditions 1,
2 and 3.
Acknowledgement
The authors were partially funded by FCT/Portugal through project
PEst-OE/EEI/LA0009/2013.

13

References
[1] Alves, J., Bravo, A., and Oliveira, H. (2014). Population Dynamics with
Infinite Leslie Matrices - finite time properties. Journal of Difference
Equations and Applications 20(14), 1307-1318.
[2] Cushing, J. M. (1998). An introduction to structured population dynamics (pp. 133-139). Society Industrial and Applied Mathematics.
[3] Demetrius, L. (1974). Demographic Parameters and Natural Selection.
Proceedings of the National Academy of Sciences 71, 4645-4747.
[4] Demetrius, L. (1976). Measures of Variability in Age-Structured Populations. Journal of Theoretical Biology 63, 397-404.
[5] Demetrius, L. (1978). Adaptive Value, Entropy and Survivorship Curves.
Nature 275, 231-232.
[6] Demetrius, L. A. (2013). Boltzmann, Darwin and directionality theory.
Physics reports, 530(1), 1-85.
[7] Logofet, D. O., and Klochkova, I. N. (2002). Mathematics of the
Lefkovitch model: the reproductive potential and asymptotic cycles.
Matematicheskoe Modelirovanie, 14(10), 116-126. (Russian)
[8] Pollard, J. H. (1973). Mathematical models for the growth of human
populations (Vol. 10). Cambridge: Cambridge University Press.

14

