Reduced models of networks of coupled enzymatic reactions
Ajit Kumara , Krešimir Josića,b,∗
a
b

Department of Mathematics, University of Houston, Houston TX 77204-3008, USA

Department of Biology and Biochemistry, University of Houston, Houston TX 77204-5001, USA

arXiv:1101.1104v2 [math-ph] 7 Jan 2011

Abstract
The Michaelis-Menten equation has played a central role in our understanding of biochemical
processes. It has long been understood how this equation approximates the dynamics of
irreversible enzymatic reactions. However, a similar approximation in the case of networks,
where the product of one reaction can act as an enzyme in another, has not been fully
developed. Here we rigorously derive such an approximation in a class of coupled enzymatic
networks where the individual interactions are of Michaelis-Menten type. We show that
the sufficient conditions for the validity of the total quasi steady state assumption (tQSSA),
obtained in a single protein case by Borghans, de Boer and Segel can be extended to sufficient
conditions for the validity of the tQSSA in a large class of enzymatic networks. Secondly, we
derive reduced equations that approximate the network’s dynamics and involve only protein
concentrations. This significantly reduces the number of equations necessary to model such
systems. We prove the validity of this approximation using geometric singular perturbation
theory and results about matrix differentiation. The ideas used in deriving the approximating
equations are quite general, and can be used to systematize other model reductions.
Keywords: Michaelis Menten, quasi steady state, total quasi steady state, protein
interaction networks, coupled enzymatic networks, geometric singular perturbation

1. Introduction
The Michaelis-Menten (MM) scheme [3, 20] is a fundamental building block of many
models of protein interactions: An enzyme, E, reacts with a protein, X, resulting in an
intermediate complex, C. In turn, this complex can break down into a product, Xp , and the
enzyme E. It is frequently assumed that formation of C is reversible while its breakup is
not. The process is represented by the following sequence of reactions [3, 20, 21]
k1

k

X + E 
 C →2 Xp + E.

(1.1)

k−1

Frequently catalytic activity in protein interaction network is modeled by MM equations [14, 24, 33, 32, 6, 4, 25, 9]. This gives rise to coupled enzymatic networks, where the
∗

Corresponding author
Email addresses: ajitkmar@math.uh.edu (Ajit Kumar), josic@math.uh.edu (Krešimir Josić)

Preprint submitted to Journal of Theoretical Biology

January 10, 2011

Coupled enzymatic networks - tQSSA

2

substrate of one reaction acts as enzyme in another reaction. A direct application of the
law of mass action to such models typically leads to high dimensional differential equations
which are often stiff, and difficult to study directly.
A number of methods have been introduced to address these problems. Most of these
methods are based on quasi steady state assumptions which take advantage of the differences
in characteristic timescales of the quantities being modeled. It is typically assumed that the
chemical species, or some combinations of chemical species, can be divided into two classes:
One which equilibrates rapidly, and a second which evolves more slowly [12, 15]. Assuming
that the members of the first class equilibrate instantaneously leads to a reduced model
involving only elements of the second class.
Reduction methods differ in their assumption on which chemical species, or combinations thereof, are assigned to the two different classes. For instance, the standard quasi
steady state assumption (sQSSA) posits that the concentrations of the intermediate complexes change quickly compared to the protein concentration [10, 30, 31, 8, 23]. An alternative is the reverse quasi steady state assumption (rQSSA) where the protein concentration
is assumed to change rapidly compared to intermediate complexes [29]. Rigorous justifications of these methods are largely available only for isolated reactions of the type shown in
scheme (1.1), and the Goldbeter-Koshland switch1 [10].
The total quasi steady state assumption (tQSSA) was introduced to broaden the range
of parameters over which a quasi steady state assumption is valid. Under this assumption
the concentration of the intermediate complex, C, evolves quickly compared to the sum
of the intermediate complex and the protein concentration [2, 34, 18, 26, 35]. Numerical
experiments and heuristic arguments suggest that tQSSA may be valid in coupled enzymatic
networks over a very broad set of parameters [5].
Here we aim to provide a theoretical foundation for the reductions used in numerical
studies of enzymatic networks. A standard model reduction technique for systems involving quantities that change on different timescales is geometric singular perturbation theory
(GSPT) [7, 17, 12]. For instance, this theory has been used by Khoo and Hegland to prove
several results obtained earlier by Borghans, et al. using self consistency arguments [18, 2].
GSPT has also been used to reduce other models of biochemical reactions [37, 11, 15]. We
derive a sufficient condition for the validity of tQSSA in arbitrary networks of proteins and
enzymes provided the interactions are of MM type and can be modeled by mass action kinetics. This directly extends previous work, like that of Pedersen, et al. [27] who proposed
a sufficient condition for the validity of tQSSA in the Goldbeter-Koshland switch.
The direct application of the tQSSA to coupled enzymatic networks generally leads
to a differential-algebraic system. The algebraic part of this system consists of coupled
quadratic equations that are typically impossible to solve. Our second aim is to show that,
under certain assumptions on the structure of the network, it is possible to circumvent this
problem using ideas introduced by Bennett, et al. [1]. This allows us to obtain reduced
1

A Goldbeter-Koshland switch consist of two coupled reactions. One of these reactions frequently represents protein phosphorylation, and the second dephosphorylation.

Coupled enzymatic networks - tQSSA

3

set of differential equations for a class of protein interaction networks in terms of protein
concentrations only.
We proceed as follows: In section 2 we review the original Michaelis–Menten scheme.
We introduce terminology, and illustrate our approach in a simple setting. In this section
we also give a brief overview of the theory of geometric singular perturbation theory, which
is fundamental in proving the validity of the reduced equations. In section 3 we extend our
approach to a well studied two protein network that plays part in the G2-to-mitosis phase
(G2/M) transition in the eukaryotic cell cycle. We present the ideas in the most general
setting in section 4, where we derive the general form of the reduced equations. Each section
begins by the discussion of the tQSSA in the context of the network under consideration,
and closes with a derivation of the reduced equations under the tQSSA, as well as sufficient
conditions under which the tQSSA holds. A number of technical details used in the proofs
of the main results are given in the appendices. We note that throughout the presentation
the law of mass action is assumed to hold.
2. Isolated Michaelis-Menten reaction
The MM scheme is frequently used to model enzymatic processes in solution which are
ubiquitous in biology. As discussed in the introduction, a number of different approaches
have been proposed to justify the reduced equations mathematically. We start by giving a
detailed overview of the tQSSA approach based on geometric singular perturbation theory
(GSPT)[7]. The setting of a single MM type reaction will be used to introduce the main
ideas and difficulties of reducing equations that describe larger reaction networks.
For notational convenience we will use variable names to denote both a chemical species
and its concentration. For instance, E denotes both an enzyme and its concentration. Reaction (1.1) reaction obeys two natural constrains: The total amount of protein and enzyme
remain constant. Therefore,
X + C + Xp = XT ,

and E + C = ET ,

(2.1)

for positive constants XT and ET . In conjunction with the constraints (2.1), the following
system of ordinary differential equations can be used to model reaction (1.1)
dX
= −k1 X(ET − C) + k−1 C,
dt
dC
= k1 X(ET − C) − (k−1 + k2 )C,
dt

X(0) = XT ,
C(0) = 0.

(2.2)

2.1. The total quasi steady state assumption (tQSSA)
Under the standard quasi steady state assumption (sQSSA), the concentration of the
substrate–bound enzyme, C, equilibrates quickly, which allows system (2.2) to be reduced
by one dimension. Sufficient conditions under which the sQSSA is valid have been studied
extensively [10, 30, 8]. However, it has also been observed that the sQSSA is too restrictive [2,
34].

Coupled enzymatic networks - tQSSA

4

To obtain a reduction that is valid for a wider range of parameters, define X̄ := X + C.
Eq. (2.2) can then be rewritten as
dX̄
= −k2 C,
dt
dC
= k1 [X̄ET − (X̄ + ET + km )C + C 2 ],
dt

X̄(0) = XT ,

(2.3a)

C(0) = 0,

(2.3b)

where km = (k−1 + k2 )/k1 is the Michaelis–Menten constant.
The tQSSA posits that C equilibrates quickly compared to X̄ [2, 34]. Under this
assumption we obtain the following differential–algebraic system
dX̄
= −k2 C,
dt
0 = k1 [X̄ET − (X̄ + ET + km )C + C 2 ].

X̄(0) = XT ,

(2.4a)
(2.4b)

Solving Eq. (2.4b) and noting that only the negative branch of solutions is stable, we can
express C in terms of X̄ to obtain a closed, first order differential equation for X̄,
p
(X̄ + ET + km ) − (X̄ + ET + km )2 − 4X̄ET
dX̄
= −k2
,
X̄(0) = XT .
(2.5)
dt
2
Although the reduced equation is given in the X̄, C coordinates, it is easy to revert to the
original variables X, C. Therefore, from Eq. (2.5) one can recover an approximation to the
solution of Eq. (2.2).
2.2. Extension of the tQSSA
An essential step in the tQSSA reduction is the solution of the quadratic equation (2.4b).
A direct extension of this approach to networks of chemical reaction typically leads to coupled system of quadratic equations [5, 27, 26]. The solution of this system may not be
unique, and generally needs to be obtained numerically. However, an approach introduced
by Bennett, et al. [1], can be used to obtain the desired solution from a system of linear
equations.
In particular, we keep the tQSSA, but look for a reduced equation in the original
coordinates, X, C. Using X̄ = X + C to eliminate X̄ from Eq. (2.4b), we obtain
0 = k1 (X(ET − C) − km C) .

(2.6)

Eq. (2.6) and Eq. (2.4b) are equivalent, but Eq. (2.6) is linear in C, and leads to
C=

XET
XET
, and X̄ = X +
.
km + X
km + X

Using these expressions formulas in Eq. (2.4a), and applying the chain rule gives



−1
XET
dX
XET
dX
km E T
XET
∂
X+
= −k2
=⇒
= −k2 1 +
.
2
∂X
km + X dt
km + X
dt
(km + X)
km + X
(2.7a)

Coupled enzymatic networks - tQSSA

5

The reduced Eq. (2.7a) was obtained under the assumption that there is no significant
change in X̄ = X +C during the rapid equilibration. After equilibration, C = XET /(km +X)
(See Fig. 1). Therefore, the initial value for Eq. (2.7a), denote by X̂(0), can be obtained
from the initial values X(0), C(0) using
X̂ (0) +

ET X̂ (0)
X̂ (0) + km

= X(0) + C(0) = XT .

(2.7b)

Fig. 1c) shows that the solutions of the full system (2.2) and the reduced system (2.7a)
are close when initial conditions are mapped correctly.

Coupled enzymatic networks - tQSSA

6

(a)

(b)

(c)
1

0.2

0.2

0.8

0.15

0.15

0.6

0.1

0.1

0.4

0.05

0.05

0.2

0

0

0.2

0.4

0.6

0.8

0
1

0

0.2

0.4

0.6

0.8

1

Original system
Reduced system

0

5

10

15

20

Figure 1: Proper choice of the initial values of the reduced system. The empty circle at X̄ = 1, C = 0,
represents the initial value for the full system. The solid dot is the initial value of the reduced system. The
dash-dotted (red) line represents the attracting slow manifold. (a) The solid curve represents the numerical
solution of Eq. (2.3). The solution rapidly converges to the manifold, and evolves slowly along the manifold
after this transient. The dashed line satisfies X̄ = XT . The solid dot at the intersection of the dashed
line and the slow manifold represents the projection of the initial condition onto the slow manifold given by
Eq. (2.4b). Thus X̄(0) = XT is the proper initial condition for the reduced system (2.5). (b) The solid line
represents the numerical solution of Eq. (2.2). After a quick transient, the solution again converges to the
slow manifold. However, since the initial transient is not orthogonal to the X axis, the initial conditions do
not project vertically onto the slow manifold. Instead, the initial transient follows the line X + C = XT
(dashed), and the intersection of this line and the slow manifold represents the proper choice of the initial
value for Eq. (2.7a). (c) Comparison of solutions of Eq. (2.2) and the reduced system (2.7a). The graph in
the inset offers a magnified view of the boxed region, showing the quick transient to the slow manifold. We
used: XT = ET = k1 = k2 = 1, k−1 = 3, which, using Eq. (2.7b), gives the initial condition for the reduced
system, X̂(0) = 0.83.

Coupled enzymatic networks - tQSSA

7

The tQSSA implies that Eq. (2.3) can be approximated by Eq. (2.4). Therefore, to
explore the conditions under which Eq. (2.7a) is a valid reduction of Eq. (2.2) we need
to provide the asymptotic limits under which the transition from Eq. (2.3) to Eq. (2.4)
is justified. Different sufficient conditions for the tQSSA have been obtained using selfconsistency arguments [2, 34]. We follow the ideas of pairwise balance to look for a proper
non-dimensionalisation of variables [31, 8]. Although this method gives a weaker result than
the one obtained in [34], it is easier to extend to networks of reactions.
2.3. Review of Geometric singular perturbation (GSPT)
Since geometric singular perturbation theory (GSPT) is essential in our reduction of
the equations describing coupled enzymatic reactions, we here provide a very brief overview
of the theory. Further details can be found in [7, 36, 16, 17, 12]. Readers familiar with GSPT
can skip to section 2.4.
Consider a system of ordinary differential equation of the form
du
= f (u, v, ),
u(0) = u0 ,

dt
dv
= g(u, v, ),
v(0) = v0 ,
(2.8a)
dt
where u ∈ Rk and v ∈ Rl with k, l ≥ 1, and u0 ∈ Rk , v0 ∈ Rl are initial values. The
parameter  is assumed to be small and positive (0 <   1), the functions f and g smooth,
f (u, v, 0) 6≡ 0, g(u, v, 0) 6≡ 0,

and

lim g(u, v, ) ≡ 0.
→0

(2.8b)

The variable u is termed the fast variable, and v the slow variable.
Assume that M0 := {(u, v) ∈ Rk+l | f (u, v, 0) = 0} is a compact, smooth manifold with
(u, v, 0)|M0
inflowing boundary. Suppose further that the eigenvalues λi of the Jacobian ∂f
∂u
all satisfy Re(λi ) < 0, so that M0 is normally hyperbolic. Then, for  sufficiently small, the
solutions of Eq. (2.8a) follow an initial transient, which can be approximated by
du
= f (u, v, 0),
u(0) = u0 ,
ds
dv
= 0,
v(0) = v0 ,
(2.9)
ds
where t = s. After this transient, the solutions are O() close to the solutions of the reduced
system
0 = f (u, v, 0),
dv
= g(u, v, 0), v(0) = v0 .
(2.10)
dt
More precisely there is an invariant, slow manifold M , O() close to M0 . Solutions of
Eq. (2.8a) are attracted to M0 exponentially fast, and can be approximated by concatenating
the fast transient described by Eq. (2.9), and the solution of the reduced Eq. (2.10).
The slow manifold, M0 , consists of the fixed points of Eq. (2.9). The condition that
the eigenvalues, λi , of the Jacobian ∂f
(u, v, 0)|M0 all satisfy Re(λi ) < 0 implies that these
∂u
fixed points are stable.

Coupled enzymatic networks - tQSSA

8

2.4. Validity of the tQSSA
We next show that GSPT can be applied to Eq. (2.3), after a suitable rescaling of
variables [31, 8]. Let
X̄(t)
C(t)
t
, x̄(τ ) =
, c(τ ) =
.
(2.11)
τ=
TX̄
XT
β
We have some freedom in defining β and TX̄ . Using the method of pairwise balance [8, 31],
we let
XT E T
XT
, and TX̄ =
β=
.
(2.12)
XT + ET + km
k2 β
In the rescaled variables, Eq. (2.3) takes the form
dx̄
= −c,
x̄(0) = 1, (2.13a)
dτ
k2
ET
dc
XT x̄ + ET + km
XT E T
=
x̄
−
c
+
c2 , c(0) = 0. (2.13b)
2
2
k1 (ET + XT + km ) dτ
XT + ET + km
(ET + XT + km )
Define the parameter
 :=

k2
ET
β
=
.
k1 TX̄ XT ET
k1 (ET + XT + km )2

(2.14)

For small , Eq. (2.13) is singularly perturbed and has the form given in Eq. (2.8a). Indeed,
we can apply GSPT to Eq. (2.13) directly since in the limit  → 0 the right hand side of
Eq. (2.13) remains O(1). Indeed, the requirement 0 <   1, is equivalent to the sufficient
condition for the validity of the tQSSA derived in [2].
GSPT implies that for small , solutions of Eq. (2.13) are close to those of the reduced
system
dx̄
= −c,
dτ
0 = x̄ −

x̄(0) = 1,
XT ET
XT x̄ + ET + km
c+
c2 .
XT + ET + km
(ET + XT + km )2

(2.15a)
(2.15b)

The normal hyperbolicity and stability of the manifold defined by Eq. (2.15b) can be
verified directly, and also follow from the results of section 4. It follows that GSPT can be
applied to conclude that GSPT implies that Eq. (2.15) is a reduction of Eq. (2.13).
The validity of the reduction in these rescaled equations implies its validity in the
original coordinates: Eq. (2.13) is equivalent to Eq. (2.3) via the scaling given in Eq. (2.11).
Hence, Eq. (2.4) and Eq. (2.15) are related by the same scaling relationship. We note that
choosing the initial values of the intermediate complexes to be zero, implies that solutions
of (2.13) remain O(1) for small  (see section 4.6 for a detailed discussion). It follows that
Eq. (2.4) is a valid reduction of Eq. (2.3) when  is sufficiently small. Hence, for  in the same
range, Eq. (2.7a), with initial values satisfying Eq. (2.7b), is a valid reduction of Eq. (2.2).
Lemma 7 in the Appendix shows that  is always smaller than 1/4. Although this is
suggestive, GSPT only guarantees the validity of the reduced equations in some unspecified
range of  values.

Coupled enzymatic networks - tQSSA

9

3. Analysis of a two protein network
We next show how the reduction described in the previous section extends to a network
of MM reactions. Here the substrate of one reaction acts as an enzyme in another reaction.
To illustrate the main ideas used in reducing the corresponding equations, we start with a
concrete example of two interacting proteins.

Coupled enzymatic networks - tQSSA

(a)

10

(b)
1.6

Original system
1.4

Reduced system

1.2
1
0.8
0.6
0.4
0.2
0
0

2

4

6

8

10

12

14

Figure 2: A simplified description of interactions between two regulators of the G2-to-mitosis phase (G2/M)
transition in the eukaryotic cell cycle [25] (See text). (a) X and Y phosphorylate and deactivate each
other. For instance, the protein X exists in a phosphorylated Xp and unphosphorylated X state, and the
conversion X to Xp is catalyzed by Yp . The conversion of Xp to X is catalyzed by the phosphatase E1 .
(b) Comparison of the numerical solution of Eq. (3.1) and Eq. (3.8). Here k1 = 5, k−1 = 1, k2 = 1, E1T =
10, E2T = 2, XT = 10, YT = 10.1 as in [5]. The initial values for Eq. (3.1) are X(0) = 10, Y (0) = 1.1, Xp (0) =
0, Yp (0) = 9, Cx (0) = 0, Cy (0) = 0, Cxe (0) = 0, Cye (0) = 0, E1 (0) = 10, E2 (0) = 2. The initial values of the
reduced system, X̂p (0) = 0.12, Ŷp (0) = 0.83 are obtained by the projection onto the slow manifold defined
by Eq. (3.7).

Coupled enzymatic networks - tQSSA

11

Fig. 2a) is a simplified depiction of the interactions between two regulators of the G2to-mitosis phase (G2/M) transition in the eukaryotic cell cycle [25]. Here, Y represents MPF
(M-phase promoting factor, a dimer of Cdc2 and cyclin B) and X represents Wee1 (a kinase
that phosphorylates and deactivates Cdc2 ). The proteins exist in a phosphorylated state,
Xp , Yp , and an unphosphorylated state, X, Y , with the phosphorylated state being less active.
The proteins X and Y deactivate each other, and hence act as antagonists. In this network
E1 and E2 represent phosphatases that catalyze the conversion of Xp and Yp to X and Y,
respectively. Each dotted arrow in Fig. 2a) is associated with exactly one MM type reaction
in the list of reactions given below. The sources of the arrows act as enzymes. Therefore,
Fig. 2a) represents the following network of reactions
k1

k

2
Yp + X  Cx −→
Xp + Yp ,

k−1
k1

k

2
Xp + Y  Cy −→
Yp + Xp ,

k−1

k1

k

2
X + E1 ,
E1 + Xp  Cxe −→

k−1

k1

k

2
Y + E2 .
E2 + Yp  Cye −→

k−1

To simplify the exposition, we have assumed some homogeneity in the rates. Since the total
concentration of proteins and enzymes is assumed fixed, the system obeys the following set
of constraints
XT = X(t) + Xp (t) + Cx (t) + Cy (t) + Cxe (t),

E1T = Cxe (t) + E1 (t),

YT = Y (t) + Yp (t) + Cx (t) + Cy (t) + Cye (t),

E2T = Cye (t) + E2 (t),

where XT , YT , E1T , E2T are constant and represent the total concentrations of the respective
proteins and enzymes. Along with these constraints the concentrations of the ten species in
the reaction evolve according to
dXp
= −k1 (YT − Yp − Cx − Cy − Cye ) Xp − k1 Xp (E1T − Cxe ) +k−1 Cxe + (k−1 + k2 )Cy + k2 Cx ,
| {z }
dt
|
{z
}
=E1

=Y

dYp
= −k1 (XT − Xp − Cx − Cy − Cxe ) Yp − k1 Yp (E2T − Cye ) +k−1 Cye + (k−1 + k2 )Cx + k2 Cy ,
|
{z
}
dt
| {z }
=X

=E2

dCx
= k1 (XT − Xp − Cx − Cy − Cxe ) Yp − (k−1 + k2 )Cx ,
|
{z
}
dt

(3.1)

=X

dCy
= k1 (YT − Yp − Cx − Cy − Cye ) Xp − (k−1 + k2 )Cy ,
dt
|
{z
}
=Y

dCxe

= k1 Xp (E1T − Cxe ) −(k−1 + k2 )Cxe ,
| {z }
dt
=E1

dCye
dt

= k1 Yp (E2T − Cye ) −(k−1 + k2 )Cye ,
| {z }
=E2

with initial values
Cx (0) = 0,

Cy (0) = 0,

Cxe (0) = 0,

Cye (0) = 0.

(3.2)

Coupled enzymatic networks - tQSSA

12

The initial values of Xp and Yp are arbitrary.
Following the approach in the previous section, we reduce Eq. (3.1) to a two dimensional system. Assuming the validity of the tQSSA, we obtain an approximating differential–
algebraic system. Solving the algebraic equations, which are linear in the original coordinates, leads to a closed, reduced system of ODEs. We end by discussing the validity of the
tQSSA.
3.1. New coordinates and reduction under the tQSSA
To extend the tQSSA we define a new set of variables by adding the concentration of
the free state of a species to the concentrations of all intermediate complexes formed by that
particular species as reactant [5],
X̄p := Xp + Cy + Cxe ,
Ȳp := Yp + Cx + Cye .

(3.3)

Under the tQSSA, the intermediate complexes equilibrate quickly compared to the
variables X̄p and Ȳp . In the coordinates defined by Eq. (3.3), Eq. (3.1) takes the form
dX̄p
= k2 Cx − k2 Cxe ,
dt
dȲp
= k2 Cy − k2 Cye ,
dt
0 = k1 (XT − X̄p − Cx )(Ȳp − Cx − Cye ) − (k−1 + k2 )Cx ,
0 = k1 (YT − Ȳp − Cy )(X̄p − Cy −

Cxe )

− (k−1 + k2 )Cy ,

(3.4a)
(3.4b)
(3.4c)
(3.4d)

0 = k1 (X̄p − Cy − Cxe )(E1T − Cxe ) − (k−1 + k2 )Cxe ,

(3.4e)

0 = k1 (Ȳp − Cx − Cye )(E2T − Cye ) − (k−1 + k2 )Cye .

(3.4f)

Solving the coupled system of quadratic equations (3.4c-3.4f) in terms of X̄p , Ȳp appears to be
possible only numerically, as it is equivalent to finding the roots of a degree 16 polynomial [5].
However, since we are interested in the dynamics of Xp and Yp , we can proceed as in the
previous section: Using Eq. (3.3) in (3.4c-3.4f) gives a linear system in Cx , Cy , Cxe , Cye .
Defining km := (k−1 + k2 )/k1 , this system can be written in matrix form as


 

Cx
Yp + km
Yp
Yp
0
Yp (XT − Xp )
 Xp
  Cy   Xp (YT − tp ) 
Xp + km
0
Xp

 e  = 
.
(3.5)

  Cx  

0
0
Xp + km
0
Xp E1T
Cye
0
0
0
Yp + km
Yp E2T
The coefficient matrix above is invertible and Eq. (3.5) can be solved to obtain Cx , Cy , Cxe , Cye
as functions of Xp , Yp . Denoting the resulting solutions as Cx (Xp , Yp ), Cy (Xp , Yp ), Cxe (Xp , Yp ),
Cye (Xp , Yp ) and using them in Eqs.(3.4a-3.4b) we obtain the closed system of equations




d X̄p
Cx (Xp , Yp ) − Cxe (Xp , Yp )
= k2
.
Cy (Xp , Yp ) − Cye (Xp , Yp )
dt Ȳp

Coupled enzymatic networks - tQSSA

13

Reverting to the original coordinates, Xp and Yp , and using the chain rule gives




d Xp + Cy (Xp , Yp ) + Cxe (Xp , Yp )
Cx (Xp , Yp ) − Cxe (Xp , Yp )
=⇒
= k2
Cy (Xp , Yp ) − Cye (Xp , Yp )
dt Yp + Cx (Xp , Yp ) + Cye (Xp , Yp )
"
# 



∂Cy
∂Cy
∂Cxe
∂Cxe
1 + ∂X
+
+
d Xp
Cx (Xp , Yp ) − Cxe (Xp , Yp )
∂Xp
∂Yp
∂Yp
p
. (3.6)
= k2
∂C e
∂C e
∂Cx
x
Cy (Xp , Yp ) − Cye (Xp , Yp )
+ ∂Xy
1 + ∂C
+ ∂Y y dt Yp
∂X
∂Y
p

p

p

p

The initial values of Eq. (3.6) are determined by projecting the initial values, given
by Eq. (3.2), onto the slow manifold. Unfortunately, they can be expressed only implicitly.
The reduction from Eq. (3.1) to Eq. (3.6) was obtained under the assumption that X̄p =
Xp + Cy + Cxe and Ȳp = Yp + Cx + Cye are slow variables, and hence constant during the
transient to the slow manifold. Therefore the projections of the initial conditions onto the
slow manifold, X̂p (0) and Ŷp (0), are related to the original initial conditions as
X̂p (0) + Cy (X̂p (0), Ŷp (0)) + Cxe (X̂p (0), Ŷp (0))
Ŷp (0) + Cx (X̂p (0), Ŷp (0)) + Cye (X̂p (0), Ŷp (0))

= Xp (0) + Cy (0) + Cxe (0)
= Yp (0) + Cx (0) + Cye (0)

= XT ,
= YT .
(3.7)

We have therefore shown that, if the tQSSA holds, and if the coefficient matrix on the
left hand side of Eq. (3.6) is invertible, then
#−1 
"



∂Cy
∂Cy
∂Cxe
∂Cxe
+
+
1 + ∂X
d Xp
Cx (Xp , Yp ) − Cxe (Xp , Yp )
∂X
∂Y
∂Y
p
p
p
p
(3.8)
,
= k2
∂C e
∂C e
∂Cx
x
Cy (Xp , Yp ) − Cye (Xp , Yp )
dt Yp
+ ∂Xyp
1 + ∂C
+ ∂Ypy
∂Xp
∂Yp
with initial value obtained by solving Eq. (3.7), is a valid approximation of Eq. (3.1). Fig. 2b)
shows that the solutions of the two systems are indeed close, after an initial transient.
3.2. Validity of the tQSSA for two interacting proteins
To reveal the asymptotic limits for which the tQSSA holds, we again rescale the original
equations. In particular, X̄p and Ȳp are scaled by the total concentration of the respective
proteins. To scale the intermediate complexes, each MM reaction in this network is treated
as isolated. The scaling factors are then obtained analogously to β in Eq. (2.12). Let
XT YT
XT YT
αx :=
,
αy :=
,
XT + YT + km
XT + YT + km
XT E1T
YT E2T
e
βxe :=
,
β
:=
,
y
XT + E1T + km
YT + E2T + km
and


XT XT YT
YT
Ts := max
,
,
,
.
k2 αx k2 βxe k2 αy k2 βye
Therefore, Ts is obtained analogously to TX̄ in Eq. (2.12). The reason for choosing the
maximum will become evident shortly. The rescaled variables are now defined as
τ :=
Cx (t)
cx (τ ) :=
,
αx

t
,
Ts

x̄p (τ ) :=

Cy (t)
cy (τ ) :=
,
αy

X̄p (t)
,
XT
cex (τ )

ȳp (τ ) :=

Cxe (t)
:=
,
βxe

Ȳp (t)
,
YT
cey (τ )

Cye (t)
:=
.
βye

(3.9)

Coupled enzymatic networks - tQSSA

14

Using Eq. (3.3) in the Eq. (3.1) to eliminate Xp , Yp , and then applying the rescaling,
defined by Eq. (3.9), to the new ODE we obtain
dx̄p
k2 αx Ts
k2 βxe Ts e
=
cx −
c ,
dτ
XT
XT x
k2 βye Ts e
dȳp
k2 αy Ts
=
cy −
cy ,
dτ
YT
YT

ȳp − x̄p ȳp − XαxT cx ȳp −
dcx
αx

=
αx βye
αx km
e
k1 XT YT Ts dτ
+
−
c
c
c
,
x
x
y
XT YT
XT YT
| {z }

(3.10a)
(3.10b)
αx
c
YT x

βye e
c
YT y

−

+

αx
c x̄
YT x p

+

βye e
c x̄
YT y p

+

α2x
c2
XT YT x

≤x

(3.10c)
dcy
αy
=
k1 XT YT Ts dτ
| {z }

βxe e
c − XαyT cy −
XT x

α2
+ XT yYT c2y − XαyTkYmT cy ,


x̄p −

x̄p ȳp +

βxe e
c ȳ
XT x p

+

αy
c ȳ
XT y p

αy
c x̄
YT y p

−

(cex )2 +

αy βxe e
c cy
E1T XT x

+

αy βxe e
c c
XT YT x y

≤y

(3.10d)
βxe

dcex

k1 XT E1T Ts

dτ

|

{z

≤ex

= x̄p −

βxe e
c x̄p
E1T x

= ȳp −

βye e
c ȳp
E2T y

−

βxe
XT

cex −

(βxe )2
E1T XT

αy
cy +
XT

−

βxe km e
c ,
E1T XT x

}
(3.10e)

βxe
k1 E2T YT Ts
|

{z

≤ey

dcey
dτ

−

αx
cx −
YT

βye e
c
YT y

αx βye
cx cey
E2T YT

+

+

(βye )2
E2T YT

(cey )2 −

βye km e
c ,
E2T YT y

}
(3.10f)

where
YT
k2
,
k1 (XT + YT + km )2
k2
E1T
,
ex :=
k1 (XT + E1T + km )2

k2
XT
,
k1 (YT + XT + km )2
k2
E2T
ey :=
.
k1 (YT + E2T + km )2

y :=

x :=

The bounds on these coefficients follow from the definition of Ts . Since (1/Ts ) ≤ (k2 αx /XT ),
αx
k2 αx2
k2 1
≤
=
k1 XT YT Ts
k1 XT2 YT
k1 XT2 YT
Similarly,
αy
≤ y ,
k1 XT YT Ts



βxe
≤ ex ,
k1 XT E1T Ts

X T YT
XT + YT + km
and

2
= x .

βxe
≤ ey .
k1 E2T YT Ts

Finally, we define

	
 := max x , y , ex , ey .

(3.11)

The definitions of scaling factors in (3.9) imply that all the coefficients on the right hand
side of (3.10c–3.10f) are O(1). Therefore, in the asymptotic limit  → 0, Eq. (3.10) defines

Coupled enzymatic networks - tQSSA

15

a singularly perturbed system. Since the two equations are related by the scaling given in
Eq. (3.9), we can conclude that in the limit  → 0, the tQSSA is valid. If additionally the
slow manifold is normally hyperbolic, then Eq. (3.4) is a valid reduced model of the network’s
dynamics. The normal hyperbolicity and stability of the slow manifold will be proved in a
general setting in section 4 .
4. The general problem
We next describe how to obtain reduced equations describing the dynamics of a large
class of protein interaction networks [14, 24, 33, 32, 6, 4, 25, 9]. We again assume that the
proteins interact via MM type reactions, and that a generalization of the tQSSA holds [5].
We will follow the steps that lead to the reduced systems in the previous two sections: After
describing the model and the conserved quantities, we recast the equations in terms of the
“total” protein concentrations (cf. sections 2.1 and 3.1). Under a generalized tQSSA, these
equations can be reduced to an algebraic-differential system. We show that the algebraic
part of the system is linear in the original coordinates (cf. sections 2.2 and 3.1), so that
the reduced system can be described by a differential equation with dimension equal to the
number of interacting proteins. We next show that this reduction is justified by proving
that the singularly perturbed system we examine satisfies the conditions of GSPT (cf. section 2.3). Finally, we describe the asymptotic conditions under which the system is singularly
perturbed, following the arguments in sections 2.4 and 3.2.
4.1. Description of the network
We start by defining the nodes and edges of a general protein interaction network. The
nodes in this network represent enzymes as well as proteins, while the edges represent the
catalytic effect one species has on another. Proteins are assumed to come in two states,
phosphorylated and unphosphorylated. Both states are represented by a single node in this
network. Fig. 3 and the following description make these definitions precise.

Coupled enzymatic networks - tQSSA

16

Figure 3: A simple example illustrating the terminology used in describing protein interaction networks.
The shaded regions represent nodes and encompass either an enzyme or a single protein that is part of
an MM type reaction. Each dotted arrow represents an edge in the network. The solid arrows represent
transitions within the nodes, and do not define an edge in the network.

Coupled enzymatic networks - tQSSA

17

In a network of n interacting proteins, and n associated enzymes, we define the following:
Nodes: The two types of nodes in this network represent proteins (P-type nodes) and
enzymes (E-type nodes). Each protein can exist in either an active or inactive form. The
inactive form of the ith protein is denoted by Ui , and the active form by Pi . The ith P-type
node is formed by grouping together Ui and Pi . In addition there are n species of enzymes,
Ei , which exist in only one state.
Edges: All edges in the network are directed, and represent the catalytic effect of a
species in a MM type reaction. There are two types of edges: PP-type edges connect two
P-type nodes, while EP-type edges connect E-type nodes to P-type nodes. In particular, a
PP-type edge from node i to node j represents the following MM type reaction in which Pi
catalyzes the conversion of Uj to the active form Pj ,
1
kij

2
kij

Pi + Uj  CijU −→ Pj + Pi .

(4.1a)

−1
kij

−1
1
2
Note that autocatalysis is possible. The rate constants ki,j
, ki,j
, ki,j
, associated to each edge,
can be grouped into weighted“connectivity matrices”
 
 
 
K1 = kij1 n×n , K−1 = kij−1 n×n , K2 = kij2 n×n .

In the absence of an edge, that is, when Pi does not catalyze the phosphorylation of Uj , the
corresponding (i, j)-th entry in K1 , K−1 , and K2 is set to zero.
EP-type edges are similar to PP-type edges, with enzymes acting as catalysts. To
−1 2
1
each pair of enzyme, Ei , and protein, Pj , we associate three rate constants li,j
, li,j
, li,j of the
corresponding reaction in which Ei is a catalyst in the conversion of Pj into Uj ,
1
lij

2
lij

Ei + Pj  CijE −→ Uj + Ei .

(4.1b)

−1
lij

The rate constants can again be arranged into matrices
 1
 −1 
 2
L1 = lij
,
L
=
l
,
L
=
lij n×n ,
−1
2
ij
n×n
n×n
with zero entries again denoting the absence of interactions.
These definitions imply that the active form of one protein always catalyzes the production of the active form of another protein. This assumption excludes certain interactions
(see section 5 for an example). However, the reduction is easiest to describe under these
assumptions, and we discuss generalizations in the Discussion.
For notational convenience we define U = [U1 , U2 , . . . , Un ]t , P = [P1 , P2 , . . . , Pn ]t , and
E = [E1 , E2 , . . . , En ]t , and arrange intermediate complexes into matrices,




U
U
U
E
E
E
C11
C12
C1n
C11
C12
C1n
U 
E 
 CU CU
 CE CE
C2n
C2n
22 . .
22 . .

 21

 21
.
.
CU =  ..
,
C
=
 ..
..
.. 
..
..  .
E
 .


.
.
.
.
. 
U
E
E
E
U
U
Cn1 Cn2
Cnn
Cn1 Cn2
Cnn

Coupled enzymatic networks - tQSSA

18

Initially all intermediate complexes are assumed to start at zero concentration. Therefore,
any intermediate complex corresponding to a reaction that has zero rates, will remain at
zero concentration for all time.
For instance, in the two protein example analyzed in section 3, we have


 e





0 Cy
Cx 0
X
Xp
CU =
, CE =
, U=
, P =
,
Cy 0
0 Cye
Y
Yp

etc.

Assuming that the system is isolated from the environment implies that the total
concentration of each enzyme, EiT , remains constant. Therefore,
Ei +

n
X

CisE = EiT ,

i ∈ {1, 2, ..., n}.

(4.2a)

s=1

Similarly, for each protein the total concentration, UiT , of its inactive and active form, and
the intermediate complexes is constant,
!
n
n
n
X
X
X
E
U
Cri
= UiT ,
i ∈ {1, 2, ..., n}.
(4.2b)
Cri
− CiiU +
Ui + Pi +
CisU +
s=1

r=1

r=1

Let
V n = [ 1 1 . . . 1 ]t ,
|
{z
}

and UT = [ U1T U2T . . . UnT ]t ,

ET = [ E1T E2T . . . EnT ]t ,

n times

and denote the n × n identity matrix by In . In addition, we use the Hadamard product of
matrices, denoted by ∗, to simplify notation2 . Constraints (4.2) can now be written concisely
in matrix form
ET = E + CE Vn ,
UT = U + P + CU Vn + CUt Vn − (In ∗ CU )Vn + CEt Vn .
Applying the law of mass action to the system of reactions described by (4.1a-4.1b) yields a
(2n2 + n) dimensional dynamical system,
 X

n 
n 
dPi X
−1
−1 E
1
2
U
2
U
1
=
− kis Pi Us + (kis + kis )Cis +
kri Cri − lri Er Pi + lri Cri , Pi (0) = p0i ,
dt
s=1
r=1
dCijU
= kij1 Pi Uj − (kij−1 + kij2 )CijU ,
dt

CijU (0) = 0.
(4.3)

dCijE
dt
2

−1
1
2
= lij
Ei Pj − (lij
+ lij
)CijE ,

For instance, the Hadamard product of matrices A =


ae bf
.
cg dh

CijE (0) = 0,


a
c

b
d




, and B =

e
g

f
h


, is A ∗ B =

Coupled enzymatic networks - tQSSA

19

Due to the constraints (4.2a,4.2b), Ui , Ei , are affine linear function of Pi , CijU , CijE and can
be used to close Eq. (4.3). Our aim is to reduce this 2n2 + n dimensional system to an n
dimensional system involving only Pi .
4.2. The total substrate coordinates
In this section we generalize the change of variables to the “total“ protein concentrations, introduced in Eq. (3.3). Let
P̄i := Pi +

n
X

CisU

+

n
X

E
,
Cri

i ∈ {1, 2, ..., n},

(4.4)

r=1

s=1

so that Eq. (4.3) takes the form
n

n

dP̄i X 2 U X 2 E
=
kri Cri −
lri Cri ,
dt
r=1
r=1
dCijU
= kij1 Pi Uj − (kij−1 + kij2 )CijU ,
dt
dCijE
−1
1
2
= lij
Ei Pj − (lij
+ lij
)CijE .
dt

(4.5a)
(4.5b)
(4.5c)

To close this system we use Eqs. (4.2a,4.2b) with Eq. (4.4), to obtain
Ui = UiT − Pi −

n
X

CisU −

= UiT − P̄i −


U
E
Cri
+ Cri
+ CiiU

r=1

s=1
n
X

n
X

U
Cri
+ CiiU ,

r=1

Ei = EiT −
Pi = P̄i −

n
X

CisE ,

(4.6)

s=1
n
X

n
X

s=1

r=1

CisU −

E
Cri
.

Defining P̄ := (P̄1 , P̄2 , ..., P̄n )t , Eq. (4.4) can be written in vector form as P̄ = P + CU Vn +
CEt Vn , and Eqs. (4.5) and (4.6) can be written in matrix form as
dP̄
=(K2 ∗ CU )t Vn − (L2 ∗ CE )t Vn ,
dt
dCU
=K1 ∗ (P U t ) − (K−1 + K2 ) ∗ CU ,
dt
dCE
=L1 ∗ (EP t ) − (L−1 + L2 ) ∗ CE ,
dt

(4.7a)
(4.7b)
(4.7c)

Coupled enzymatic networks - tQSSA

20

where
U = UT − P − CU Vn − CUt Vn − CEt Vn + (In ∗ CU )Vn
= UT − P̄ − CUt Vn + (In ∗ CU )Vn ,
E = ET − CE Vn ,
P = P̄ − CU Vn − CEt Vn .

(4.8a)
(4.8b)
(4.8c)

4.3. The tQSSA and the resulting reduced equations
The general form of the tQSSA states that the intermediate complexes, CU and CE ,
equilibrate faster than P̄ . This assumption implies that, after a fast transient, Eq. (4.7) can
be approximated by the differential-algebraic system
dP̄
=(K2 ∗ CU )t Vn − (L2 ∗ CE )t Vn ,
dt
0 =K1 ∗ (P U t ) − (K−1 + K2 ) ∗ CU ,
0 =L1 ∗ (EP t ) − (L−1 + L2 ) ∗ CE .
In particular, according to GSPT (see section 2.3), if the slow manifold



  0 = K1 ∗ (P U t ) − (K−1 + K2 ) ∗ CU ;

M0 = P̄ , CU , CE 
0 = L1 ∗ (EP t ) − (L−1 + L2 ) ∗ CE

(4.9a)
(4.9b)
(4.9c)

(4.10)

is normally hyperbolic and stable, then the solutions of Eq. (4.7) are attracted to and shadow
solutions on M0 .
If we consider the system (4.9b,c) entry-wise then it consists of 2n2 coupled quadratic
equations in 2n2 + n variables, namely the entries of P̄ , CU , CE (note that U, E are functions
of P̄ , CU , CE ). As described in section 3.1, we can avoid solving coupled quadratic equations
by seeking a solution in terms of P instead of P̄ . Using Eq. (4.8a,b) we eliminate E, U from
Eqs. (4.9b,c) to obtain





K1 ∗ P Vnt CUt + Vnt CU − Vnt (In ∗ CU ) + P Vnt CE + (K−1 + K2 ) ∗ CU = K1 ∗ P UTt − P t ,
(4.11a)


t
L1 ∗ CE Vn P
+ (L−1 + L2 ) ∗ CE = L1 ∗ ET P t .
(4.11b)
Although complicated, Eq. (4.11) is linear in CU and CE . The following Lemma, proved in
Appendix C, shows that the equations are also solvable.
−1
1
2
Lemma 1. Suppose K1 = [kij1 ], K−1 = [kij−1 ], K2 = [kij2 ], L1 = [lij
], L−1 = [lij
], L2 = [lij
]
n×n
∈ R
are real matrices with non-negative entries. Furthermore, assume that for any
pair i, j ∈ {1, 2, ..., n} either kij1 = kij−1 = kij2 = 0, or all these coefficients are positive, and
n×1
1 −1
2
similarly for the coefficients lij
, lij , and lij
. If UT , ET , P ∈ R+
are real vectors with positive
t
entries, and Vn = [1 1 · · · 1] is a vector of size n, then Eq. (4.11) has a unique solution for
CU , CE ∈ Rn×n in terms of P .

Coupled enzymatic networks - tQSSA

21

We denote the solution of Eq. (4.11) described in Lemma 1 by C̃U (P ), C̃E (P ). This
solution can be used to close Eq. (4.9a), by using Eq. (4.8c) to obtain
 d 

dP̄
dP
d 
t
=
+
C̃U (P )Vn +
C̃E (P ) Vn
dt
dt
dt
dt

 dP
∂ 
∂ 
t
(4.12)
C̃U (P )Vn +
C̃E (P ) Vn
= I+
∂P
∂P
dt
With Eq. (4.9a), this leads to a closed system in P ,


 dP
∂ 
∂ 
t
I+
= (K2 ∗ C̃U (P ))t Vn − (L2 ∗ C̃E (P ))t Vn .
C̃U (P )Vn +
C̃E (P ) Vn
∂P
∂P
dt
(4.13)
The initial value of Eq. (4.13), denoted by P̂ (0), must be chosen as the projection of the
initial value P (0) of Eq. (4.3), onto the manifold M0 . The reduction is obtained under the
assumption that during the initial transient there has not been any significant change in
P̄ = P + CU Vn + CEt Vn . Therefore the projection, P̂ (0), of the initial conditions onto the
slow manifold is related to the original initial conditions, U (0), P (0), CU (0), CE (0), by
P̂ (0) + C̃U (P̂ (0))Vn + C̃Et (P̂ (0))Vn = P (0) + CU (0)Vn + CE (0)Vn = P (0).
In summary, if tQSSA is valid, then Eq. (4.13) is a reduction of Eq. (4.3). We next
study the stability of the slow manifold M0 defined by Eq. (4.10). This is a necessary step
in showing that GSPT can be used to justify the validity of the reduction obtained under
the generalized tQSSA.
4.4. Stability of the slow manifold
We start by introducing several definitions and some notation to simplify the computations involved in showing that the slow manifold M0 , defined by Eq. (4.10), is normally
hyperbolic and stable. The results also apply to the slow manifolds discussed in sections 2
and 3, as those are particular examples of M0 .
Suppose that A and B are matrices of dimensions n × k and n × l, respectively. We
denote by [A : B] the n×(k +l) matrix obtained by adjoining B to A. We use this definition
to combine the different coefficient matrices, and let
C := [CU : CEt ],
We also define


U
Z :=
,
E


Z̄ :=

Q1 := [K1 : Lt1 ],

UT − P̄
ET


,

n
I2n

Q2 := [K−1 + K2 : Lt−1 + Lt2 ].


:=

In
0


,

and

V2n =

t
1 1 ... 1 .
|
{z
}


2n times

Using this notation the right hand side of Eqs. (4.8a-4.8b) can be written as



  t
 

U
UT − P̄
CU Vn
(In ∗ CUt )Vn
Z=
=
−
+
E
ET
CE Vn
0



In
= Z̄ − C t Vn +
∗ C t Vn
0
n
= Z̄ − (C t − I2n
∗ C t )Vn ,

Coupled enzymatic networks - tQSSA

22

and Eq. (4.8c) can be written as P = P̄ − CV2n . Therefore, Eqs. (4.7b-4.7c) can be merged
to obtain
dC
= Q1 ∗ (P Z t ) − Q2 ∗ C .
(4.14)
|
{z
}
dt
:=F (C)

The manifold M0 is defined by


	
M0 = C ∈ Rn×2n  Q1 ∗ (P Z t ) − Q2 ∗ C = F (C) = 0 .
To show that M0 is stable and normally hyperbolic we need to show that the Jacobian,
∂F
∂F
, evaluated at M0 has eigenvalues with only negative real parts. We will show that
∂C
∂C
has eigenvalues with negative real parts everywhere, and hence at all points of M0 , a fortiori.
The mapping F : Rn×2n → Rn×2n is a matrix valued function of the matrix variables C.
∂F
Therefore
represents differentiation with respect to a matrix. This operation is defined
∂C
by “flattening” a m × n matrix to a mn × 1 vector and taking the gradient. More precisely,
suppose M = [M.1 : M.2 : . . . : M.n ] is a m × n matrix, where M.j is the jth column of M .
Then define


M.1
 M.2 


c := diag( vec (M )) ∈ Cmn×mn .
and
M
vec (M ) :=  ..  ∈ Cmn×1 ,
 . 
M.n
(4.15)
c
Therefore, vec (M ) is obtained by stacking the columns of M on top of each other, and M
is the mn × mn diagonal matrix whose diagonal entries are given by vec (M ).
Suppose G : Cp×q → Cm×n is a matrix valued function with X ∈ Cp×q 7→ G(X) ∈
Cm×n . Then the derivative of G with respect to X is defined as
∂ vec (G)
∂G
:=
,
∂X
∂ vec (X)

(4.16)

where the right hand side is the Jacobian [19]. In the appendix we list some important
properties of these operators which will be used subsequently (see Appendix B).
A direct application of Theorem 11 stated in Appendix B yields
t
∂F
∂ vec (F )
b1 ∂ vec (P Z ) − Q
b2 ∂ vec (C) .
=
= Q
∂C
∂ vec (C)
∂ vec (C)
∂ vec (C)

We first assume that all the entries in the connectivity matrices are positive, so that
all entries in the matrix C are actual variables. At the end of Appendix D we show how to
remove this assumption.

Coupled enzymatic networks - tQSSA

23

b2 to both side,
Replacing ∂ vec (C)/∂ vec (C) with the identity matrix, I2n2 , adding Q
using Theorems 8, 9,10, 11, and treating P̄ and Z̄ as independent of C we obtain


t
∂
vec
(P
)
∂
vec
(Z
)
∂
vec
(F
)
b1 (Z ⊗ In )
b2 +
= Q
+ (I2n ⊗ P )
Q
∂ vec (C)
∂ vec (C)
∂ vec (C)



t
t
n
t
∂
vec
((C
−
I
∗
C
)
V
)
n
2n
b1 − (Z ⊗ In ) ∂ vec (CV2n ) − (I2n ⊗ P )

= Q
∂ vec (C)
∂ vec (C)
"
#
t
t
n t
∂
vec
V
C
−
V
((I
)
∗
C)
∂
vec
(CV
)
2n
n
n
2n
b1 − (Z ⊗ In )
= Q
− (I2n ⊗ P )
∂ vec (C)
∂ vec (C)
"
∂ vec (C)
t
b1 − (Z ⊗ In ) (V2n
⊗ In )
= Q
∂ vec (C)

#
n t
∂ vec (Vnt C) ∂ vec (Vnt ((I2n
) ∗ C))
− (I2n ⊗ P )
−
∂ vec (C)
∂ vec (C)
h
n


 n oi
[)t
b1 − ZV t ⊗ In − (I2n ⊗ P ) I2n ⊗ V t − I2n ⊗ V t (I
= Q
2n
2n
n
n
h
i



n t
[
b1 − ZV t ⊗ In − I2n ⊗ P V t + I2n ⊗ P V t (I
= Q
2n )
2n
n
n
h
i


t
t
n
t
[
b
= −Q1 ZV2n ⊗ In + I2n ⊗ P Vn I2n2 − (I2n )
.
n t
[
Here (I
2n ) is the matrix obtained by applying the operator defined in Eq. (4.15) to the
n
transpose of I2n
.

This computation shows that the Jacobian matrix of interest has the form





∂F
t
[
t
t
n
b
b2 .
= −Q1 ZV2n ⊗ In + I2n ⊗ P Vn I2n2 − (I2n )
−Q
J :=
∂C

(4.17)

The following Lemma, proved in the Appendix D, shows that this Jacobian matrix always
has eigenvalues with negative real part.
Lemma 2. Suppose Z ∈ R2n×1
is a 2n dimensional vector with positive entries, Y ∈ Rn×1
+
+
2
2
is an n dimensional vector with positive entries, Λ, Γ ∈ R2n ×2n are diagonal matrices with
positive entries on the diagonal. Further assume that Rn and R2n are row vectors of size n
and 2n respectively with all entries equal to 1. Then the 2n2 × 2n2 matrix



t
[
n
J = Λ (ZR2n ⊗ In ) + (I2n ⊗ Y Rn ) I2n2 − (I2n )
+Γ
(4.18)
has eigenvalues with strictly positive real parts.
This Lemma applies to connectivity matrices with strictly positive entries. In Appendix
D.2 we show how to generalize the Lemma to the case when the connectivity matrices contain
zero entries. In this case only the principal submatrix of the Jacobian, J, corresponding to
the positive entries of the connectivity matrices needs to be examined. Since any principal
submatrix of J inherits the stability properties of J, the result follows. We therefore obtain
the following corollary.

Coupled enzymatic networks - tQSSA

24

Corollary 3. The manifold M0 defined in Eq. (4.10) is normally hyperbolic and stable.
4.5. Validity of tQSSA in the general setup
We next investigate the asymptotic limits under which the tQSSA is valid in the general
setting described at the beginning of this section. We follow the approach given in the
previous sections to obtain a suitable rescaling of the variables. While this rescaling does
not change the stability of the slow manifold, M0 , it allows us to more easily describe
the asymptotic limits in which the timescales are separated, and the system is singularly
perturbed.
Recall that Eq. (4.7) and Eq. (4.5) are equivalent. The concise form given in Eq. (4.7)
was useful in obtaining a reduction and checking the stability of the slow manifold. However,
to obtain sufficient conditions for the validity of the tQSSA, we will work with Eqs. (4.5)
and (4.6).
−1
1
2
m
, kijm := (kij−1 + kij2 )/kij1 denote the MM constants. Then the
)/lij
:= (lij
+ lij
Let lij
following scaling factors are natural generalizations of those introduced in section 3,

βij :=

EiT UjT
,
m
EiT + UjT + lij

αij :=

UiT UjT
,
UiT + UjT + kijm

i, j ∈ {1, 2, ..., n}.

Note that for each pair (i, j) either all of kij1 , kij−1 , kij2 are all zero or all nonzero. In the case
−1
1
2
m
that kij1 = kij−1 = kij2 = 0 we define kijm := 0. Similarly, if lij
= lij
= lij
= 0 then lij
:= 0. Let
(
TŪ := max

(
max
i,j

UjT
2
lij
βij

)

(
, max
i,j

UjT
kij2 αij

))

UjT0
= 2
,
li0 j0 βi0 j0

for some i0 , j0 ∈ {1, 2, ..., n}.

We next define the following dimensionless rescaling of the variables in Eq. (4.5)
t
,
τ=
TŪ

P̄i (t)
and p̄i (τ ) =
,
UiT

cuij (τ )

CijU (t)
,
=
αij

ceij (τ )

CijE (t)
,
=
βij

i, j ∈ {1, 2, ..., n}.
(4.19)

After rescaling, Eqs. (4.5) take the form
n

dp̄i X
=
dτ
r=1




2
2
lri
βri UjT0 e
kri
αri UjT0 u
c −
c ,
li20 j0 βi0 j0 UiT rj li20 j0 βi0 j0 UiT rj

(4.20a)

Coupled enzymatic networks - tQSSA



βij
1
T T
lij Ei Uj TŪ



dceij
dτ

25





n
n
n
X
1 X
X βis e  

e
c
1 − x̄j − T
= 1 − ceij − 
αjs cujs 
βrj crj +
T is  
Ei
Uj r=1
s=1
s=1
r6=i

s6=j



n

n

r6=i

s6=j

s6=j



X
X
1 

βrj cerj +
− T UjT x̄j +
αjs cujs 
Uj
r=1
s=1

X
1 
βrj cerj +
− T UjT x̄j +
Uj
r=1
r6=i

n
X

αjs cujs

+

s=1
s6=j

n
X
s=1



βis ceis 

βij ceij (βij ceij )2
+ T T .
EiT
Ei Uj

s6=i

(4.20c)
The rescaled form of Eq. (4.5b) is similar to the rescaled form of Eq. (4.5c), and we therefore
omit it. If we define
kij2
UiT
,
ij := 1
kij (UiT + UjT + kijm )2
and let

eij

2
lij
EiT
:= 1
,
m 2
lij (EiT + UjT + lij
)



 e	
 := max max {ij } , max ij
,
i,j

(4.21)

i,j

then the following theorem defines the conditions under which Eq. (4.20) defines a singularly
perturbed system and, hence, conditions under which GSPT is applicable.
1 2 −1
, lij , lij and for all UiT , EiT
Theorem 4. If for all non-zero kij1 , kij2 , kij−1 and for all non zero lij

O

 k1 
ij
1
krs
2
kij
2
krs
−1
kij
−1
krs





=

O

 l1 
ij
1
krs
2
lij
2
krs
−1
lij
−1
krs





=

O

 l1 
ij

1
 llrs

2
O l2ij
rs

= O(1),

= O
=
= O(1),
O
 
 
 −1 
l
O
= O
= O lij−1
= O(1),
 T
 T
 rsT 
X
E
X
O XiT
= O EiT
= O EiT
= O(1),
j

j

1 ≤ i, j, r, s ≤ n,

j

in the limit  → 0, then Eq. (4.20) is a singularly perturbed system with the structure of
Eq. (2.8). In particular, the p̄i are the slow variables, and the cij and ceij are the fast variables.
2
2
Proof. For each i there always exist indices r, s such that kri
6= 0 6= ksi
. Hence, the the
right hand side of Eq. (4.20a) is not identically zero for any i ∈ {1, 2, ..., n}. Furthermore,
by assumption all coefficients on the right hand side of Eq. (4.20a) are O(1) as  → 0. This
implies that  times the right hand side of Eq. (4.20a) is identically zero, in the limit  → 0.

Secondly, the definition of βij implies that all coefficients on the right hand side of
Eq. (4.20c) are less than or equal to 1. Also, by definition, at least one coefficient has value

Coupled enzymatic networks - tQSSA

26

exactly equal to 1. Hence, the right hand side of Eq. (4.20c) is not identically zero in the
limit  → 0.
The definitions of , αij , βij , TŪ imply that coefficients of
or equal to . For example

dceij
dτ

in Eq. (4.20c) are less than

2
βij
1
βij
βij lij
= eij ≤ .
≤
1
T T
1
T T
lij Ei Uj TŪ
lij Ei Uj UjT

Hence, in the limit  → 0, the left hand side of Eq. (4.20c) vanishes while the right hand side
does not. To conclude the proof we only need to show the stability of the slow manifold in
rescaled coordinates. But we have already shown that for unscaled coordinates in section 4.4
and a non-singular scaling of variable, as in Eq. (4.19), will not affect the eigenvalues of the
Jacobian.
Hence, under the assumptions of the above theorem, Eq. (4.20) has the form of Eq. 2.8a.
Hence, switching back to unscaled variables we conclude that in the limit  → 0, tQSSA is
valid, i.e. the reduction from Eq. (4.7) to Eq. (4.9) is valid.
4.6. The assumption of zero initial concentrations of intermediate complexes and the choice
of scaling
Before concluding, we discuss the significance of zero initial concentrations of intermediate complexes and the benefit of the choice of scaling we used to verify the asymptotic
limits in which the system is singularly perturbed. Proposition 5 below proves that if the
reaction starts with zero initial concentration of intermediate complexes then the solution
of both Eqs. (4.7) and (4.20) are trapped in an O(1) neighborhood of the origin. Hence,
separation of time scale in Eq.(4.20), implied by Theorem 4 can be used to obtain the reduction of Eq. (4.7) given by Eq. (4.9). This is important, since GSPT would not be applicable
if the rescaling were to send O(1) solutions of Eq. (4.7) to solutions of Eq. (4.20) that are
unbounded as  → 0.
Proposition 5. The 2n2 + n dimensional hypercube Ω defined by

	
Ω := {p̄i }, {cuij }, {ceij } | 0 ≤ p̄i ≤ 1, 0 ≤ cuij ≤ 2, 0 ≤ ceij ≤ 2, ∀ i, j ∈ {1, 2, ..., n} ,
is invariant under the flow of Eq. (4.20).
Proof. By the construction of the differential equations from the law of mass action, all the
species concentration variables can take only non negative values. This together with the
conservation constraints (4.2b) force the P̄i to take values between 0 and UiT . Therefore
0 ≤ p̄i (τ ) ≤ 1, ∀ τ > 0, provided the initial conditions are chosen in Ω.
Positivity of variables also implies that cuij (τ ) ≥ 0, ceij (τ ) ≥ 0 if the flow starts inside
Ω. So we only need to show that cuij (τ ) ≤ 2 and ceij (τ ) ≤ 2. It is sufficient to show that

Coupled enzymatic networks - tQSSA



dcu
ij 
dτ 

27



≤ 0, and
cu
ij =2

dceij 

dτ 



≤ 0, or equivalently that
ceij =2

U
dCij

dt 



≤ 0, and
U =2α
Cij
ij

E
dCij

dt 

≤ 0.
E =2β
Cij
ij

But



dCijU 
−1
1
2
U 

=
k
P
U
−
(k
+
k
)C
i
j
U =2α
ij
ij
ij
ij
Cij
ij
dt C U =2αij
ij
"
!
!
n
n
n
X
X
X
E
U
= kij1
P̄i −
CisU −
Cri
UiT − P̄i −
Cri
s=1

r=1

r=1

#

−1
2
U 
−(kij + kij )Cij 


U =2α
Cij
ij

≤ kij1 PiT − 2αij (Uj − 2αij ) − (kij−1 + kij2 )2αij




= kij1 PiT − 2αij UjT − 2αij − kijm 2αij
≤ 0.


Similarly we can show that CijE is decreasing when CijE = βij . This concludes the proof.
From this we conclude that the assumptions of Theorem 4 and the zero initial values
of intermediate complexes together imply the tQSSA.
Finally, we combine the results of section 4.4 with Theorem 4 and Proposition 5 to
obtain the main result of this study.
Theorem 6. If the parameters of Eq. (4.3) are such that assumptions of Theorem 4 are
satisfied and the initial values of intermediate complexes are zero, then the tQSSA holds.
For  defined by Eq. (4.21), there exists an 0 such that for all 0 <  < 0 , the solutions of
Eq. (4.7) are O() close to the solutions of Eq. (4.9) after an exponentially fast transient.
Eq. (4.3) can therefore be reduced to the n dimensional Eq. (4.13) involving only the protein
concentrations, Pi .
5. Discussion
We obtained sufficient condition for the validity of tQSSA in non-isolated MichaelisMenten type reactions. We therefore significantly generalized previous approaches that
extended the MM scheme to small networks of reactions [27], and provided a theoretical
justification of the numerical results obtained in [5].
We noted that the direct application of the tQSSA to equations modeling networks
of reactions produces a reduction that contains coupled quadratic equations. However, for
the class of networks discussed here we were able to circumvent this problem by solving
and equivalent linear system. Moreover, we obtained a closed form equation in terms of
protein concentrations only. A direct application of the tQSSA leads to a reduced system
that involves the concentration of proteins and intermediate complexes. It was also shown
that the slow manifold used in the system reduction is always attracting.

Coupled enzymatic networks - tQSSA

28

MM type reactions are often used in models of signaling networks. In such models it is
frequently assumed that the reduced equation describing the dynamics of a single, isolated
protein can be used to study interactions in networks. It has been noted that this use of
MM differential equations is not necessarily justified [5]. The present approach provide an
alternative approximation that was proved to be valid.
Recently, a general reduction procedure for multiple timescale chemical reaction networks has been proposed [15]. That study considered a general chemical interaction network,
with a pre–determined set of fast and slow reactions. We deal with a more restrictive class
of equations, which makes it unnecessary to start with a prior knowledge of fast and slow
reactions. Moreover, we are able to show the normal hyperbolicity of the slow manifold in
our reduction, something that was not possible in the more general setting described in [15].
We end by pointing out a couple of limitations of this work. Firstly, not all enzymatic
networks belong to the class we have considered here. For example, our full reduction scheme
does not work for the network depicted in Fig. 4.

Coupled enzymatic networks - tQSSA

29

Figure 4: A hypothetical network for which the reduction described in sections 4.2–4.3 leads to a differential–
algebraic system of equations. The concentrations of the intermediate complexes appear in a nonlinear way
in the resulting algebraic equations. A further reduction to a form involving only the protein concentrations
is therefore not apparent.

Coupled enzymatic networks - tQSSA

30

This network is a slight modification of the network in Fig. 2a). Although the tQSSA
can be justified, the algebraic part of the reduced equations cannot be solved using our
approach. These equations have the form
0 = (XT − Xp − Cxe − Cx − Cy ) (YT − Y − Cy − Cx − Cye ) −km Cx ,
{z
}|
|
{z
}
=X

=Yp

Cye ) −km Cy ,

0 = Xp (YT − Y − Cy − Cx −
{z
|

}

=Yp

0 = (E1T − Cxe )Xp − km Cxe ,
0 = (E2T − Cye )Y − km Cye ,
which has to be solved for Cx , Cy , Cxe , Cye in terms of Xp , Y . Immediately we run into problems because the first equation in the above algebraic system is quadratic in the unknown
variables.
We also note that no approximation theory is truly complete unless error bounds are
investigated. Although GSPT guarantees that the derived approximations are O() close to
the true solutions, a more precise description of the error terms may be desired.
Acknowledgements: We thank Patrick de Leenheer, Paul Smolen and Antonios
Zagaris for helpful discussions and comments on earlier version of the manuscript. This
work was supported by NSF Grants DMS-0604429 and DMS-0817649 and a Texas ARP/ATP
award.
Appendix A. Bound on the expression for  as obtained in Eq. (2.14)
Lemma 7. (Bound on ): If k1 , k2 , k−1 , e, x ∈ R+ , then
 :=

k2
e
1
k1 e k2
≤ .
≤
k
+k
2
−1
2
k1 (e + x + k )2
(k1 e + k2 )
4
1

Proof. Since k1 , k2 , k−1 , e, x are all positive,
k2
e
k2
e
k1 e k2
≤
=
.
k1 (e + x + k−1k+k2 )2
k1 (e + kk2 )2
(k1 e + k2 )2
1

1

Since for any positive number s, s + 1/s ≥ 2, we obtain
k1 e k2
1
1
≤ q
q 2 ≤ .
2
(k1 e + k2 )
4
k1 e
+ kk12e
k2

This bound is sharp because for k1 = 1, k2 = 1, k−1 → 0, e = 1, x → 0 we obtain
 → 1/4.

Coupled enzymatic networks - tQSSA

31

Appendix B. Differentiation with respect to a matrix
The theory of differentiation with respect to a matrix is described in [19]. We already
introduced the vec and hat operators and the definitions of differentiation with respect to a
matrix variable in Eqs. (4.15) and (4.16). Below we list some important properties of these
operators as they relate to differentiation with respect to a matrix. Proofs can be found
in [19].
Theorem 8 ([28, 22]). For any three matrices A, B and C such that the matrix product
ABC is defined,
vec (ABC) = (C t ⊗ A) vec (B).
Theorem 9 ([19]). For any two matrices A and B of equal size
b vec (B) = B
b vec (A).
vec (A ∗ B) = A
Theorem 10 (Product rule[19]). Let G : Cp×q → Cm×r and H : Cp×q → Cr×n be two
differentiable function then
∂ vec (G)
∂ vec (H)
∂ vec (GH)
= (H t ⊗ Im )
+ (In ⊗ G)
.
∂ vec (X)
∂ vec (X)
∂ vec (X)
Theorem 11 (Hadamard product rule [19]). Let G : Cp×q → Cm×n and H : Cp×q →
Cm×n be two differentiable functions then
∂ vec (G ∗ H)
b ∂ vec (G) + G
b ∂ vec (H) .
=H
∂ vec (X)
∂ vec (X)
∂ vec (X)
Appendix C. Proof of Lemma 1
Note that the unknowns in Eq. (4.11) are matrices and the structure of the equation is
somewhat similar to a Lyapunov equation, AX + XB = C. A standard approach to solving
Lyapunov equations is to vectorize the matrices (see [13]), resulting in an equation of the
type [(Im ⊗ A) + (B t ⊗ In )] vec (X) = vec (C). Proving solvability then essentially reduces
to proving the non-singularity of the coefficient matrix [(Im ⊗ A) + (B t ⊗ In )]. We will use
this approach to show the solvability of Eq. (4.11).
In the proof of this Lemma we first assume that all possible reactions occur at nonzero
rates so that all entries in the matrices K1 , K2 , K−1 , L1 , L2 and L−1 are strictly positive.
The result is then generalized to the case when some reaction rates are zero, so that no all
reactions occur.
Note that Eq. (4.11b) is uncoupled from Eq. (4.11a). Using Theorems 8 and 9 from
section Appendix B, we vectorize Eq. (4.11b) to obtain



vec L1 ∗ CE Vn P t
+ (L−1 + L2 ) ∗ CE


= vec L1 ∗ CE Vn P t
+ vec [(L−1 + L2 ) ∗ CE ]


b−1 + L
b2 ) vec (CE )
b1 vec CE Vn P t + (L
= L

b−1 + L
b2 ) vec (CE )
b1 P V t ⊗ In vec (CE ) + (L
= L
n
h
i

b−1 + L
b2 ) vec (CE )
b1 P V t ⊗ In + (L
= L
(C.1)
n

Coupled enzymatic networks - tQSSA

32

The following lemma shows that the matrix multiplying vec (CE ) in this equation is invertible.
2

2

Lemma 12. If A, B ∈ Rn+ ×n are diagonal matrices with positive entries on the diagonal,
Y ∈ Rn×1
is a column vector with positive entries , Vn = [1 1 · · · 1]t is a column vector of
+
size n, and In is the n × n identity matrix, then the n2 × n2 matrix

D = A Y Vnt ⊗ In + B
is invertible.
Proof. Invertibility of D is equivalent to invertibility of B −1 D. Therefore it is sufficient to
prove the result with B = In2 ×n2 =: I, so that D = A (Y Vnt ⊗ In ) + I. If A (Y Vnt ⊗ In ) does
not have −1 as an eigenvalue, then D cannot have 0 as an eigenvalue. Demonstrating this
will complete the proof. Let




y1
A1


 y2 
A2




,
Y
=
A=

 ..  ,
.
.


 . 
.
An
yn
where Ai ∈ Rn×n
+ , i ∈ {1, 2, ..., n} are diagonal matrices, and yi ∈ R+ . Now



y1 y1
y1
y1 In y1 In
y1 In
 y2 y2


y2 
y2 In

 y2 In y2 In
Y Vnt ⊗ In =  ..
.. ... ..  ⊗ In =  ..
.. ... ..
 .
 .
.
. 
.
.
yn yn
yn
yn In yn In
yn In




.


This implies that

 

A Y Vnt ⊗ In = 


y1 A 1
y2 A 2
..
.
yn A n


y1 A1
y1 A1
y2 A2
y2 A2 

...
..
..  .
.
. 
yn An
yn An

Suppose λ is an eigenvalue of A (Y Vnt ⊗ In ), and

X1
 X2

X̄ =  ..
 .
Xn

(C.2)




,


Xi ∈ Cn×1 , i ∈ {1, 2, ..., n} the corresponding eigenvector. Using Eq. (C.2) we have





y1 A1 y1 A1
y1 A 1
X1
X1
 y2 A2 y2 A2


 X2 
y2 A 2 

  X2 


...
=
λ
 ..
 ..  .
..
..   .. 
 .




.
.
.
. 
yn An yn An
yn A n
Xn
Xn

Coupled enzymatic networks - tQSSA
This implies that for all k ∈ {1, 2, ..., n},

y1 A1k
y1 A1k y1 A1k
 y2 A2 y2 A2
y2 A2k
k
k

...

..
..
..

.
.
.
yn Ank
yn Ank yn Ank

33







X1k
X2k
..
.









 = λ



X1k
X2k
..
.




,


(C.3)

Xnk

Xnk

where Aik is (k, k)-th entry in the matrix Ai , and Xik is the kth entry in the vector Xi .
Therefore, if λ is an eigenvalue of A (Y Vnt ⊗ In ) then it must be an eigenvalue of one
of its n × n principal submatrices which have the form
Pn of the coefficient matrix in Eq. (C.3)
and whose eigenvalues we know are either zero or i=1 yi Aik (see reason in the footnote3 ).
Hence λ can not be −1, and hence D cannot have a zero eigenvalue.
This settles the problem of solvablity of CE in Eq. (4.11b). We can use this solution to
eliminate CE from Eq. (4.11a). Rewriting Eq. (4.11a) with all the known terms on the right
hand side we obtain


K1 ∗ P Vnt CUt + Vnt CU − Vnt (In ∗ CU ) + (K−1 + K2 ) ∗ CU




=
K1 ∗ P UTt − P t − K1 ∗ P Vnt CE .
(C.4)
We can write




vec P Vnt CUt + Vnt CU − Vnt (In ∗ CU )
= (In ⊗ P ) vec Vnt CUt + Vnt CU − Vnt (In ∗ CU ) .
(C.5)
Since (CU Vn )t is a row vector, we have vec [(CU Vn )t ] = vec (CU Vn ). Therefore, using Theorems 8 and 9
vec (Vnt CUt ) = vec (CU Vn ) = (Vnt ⊗ In ) vec (CU ),
vec (Vnt CU ) = (In ⊗ Vnt ) vec (CU ),

vec Vnt (In ∗ CU ) = (In ⊗ Vnt ) vec (In ∗ CU ) = (In ⊗ Vnt )Ibn vec (CU ).
Plugging these in Eq. (C.5) we get


vec P Vnt CUt + Vnt CU − Vnt (In ∗ CU )
h
i
= (In ⊗ P ) (Vnt ⊗ In ) + (In ⊗ Vnt ) − (In ⊗ Vnt )Ibn vec (CU )
h
i
t
t
t b
= (In ⊗ P )(Vn ⊗ In ) + (In ⊗ P Vn ) − (In ⊗ P Vn )In vec (CU ).
3

We have






y1 A1k
y2 A2k
..
.
y n An k

y 1 A1 k
y1 A1k
y 2 A2 k
y2 A2k
...
..
..
.
.
yn Ank
y n An k

t 










1
1
..
.





n
 X



yi Aik 
=
 i=1


1

Since the coefficient matrix in the above equation is rank one,

1
1
..
.




.


1
Pn

i=1

yi Aik is the only non-zero eigenvalue.

Coupled enzymatic networks - tQSSA

34

The vectorized form of the left hand side of Eq. (C.4) is
h n
o
i
b 1 (In ⊗ P )(V t ⊗ In ) + (In ⊗ P V t ) − (In ⊗ P V t )Ibn + (K
b −1 + K
b −1 ) vec (CU ).
K
n
n
n
The following Lemma shows that the matrix mutliplying vec (CU ) in this expression is invertible.
2

2

Lemma 13. If A, B ∈ Rn+ ×n are diagonal matrices with positive entries on the diagonal,
Y ∈ Rn×1
is a column vector with positive entries, Vn = [1 1 · · · 1]t is a column vector of size
+
n, then the n2 × n2 matrix

 


D = A (In ⊗ Y ) Vnt ⊗ In + In ⊗ Y Vnt − In ⊗ Y Vnt Ibn + B
is invertible.
Proof. The invertibility of D is equivalent to invertibility of A−1 D. We can therefore assume
that A = In2 . Now

y1
..
.

0
..
.



 yn



 0
 .
 ..

 0


(In ⊗ Y ) Vnt ⊗ In = 








 0

 ..

..

.

0
y1
..
.

..

.

yn

0
..
.

.
0

..

0

.

0
..
.

y1
..
.

0
..
.

0

yn

0

0
..
.

0
..
.

y1
..
.

0

0

yn

y1
..
.

0
..
.

0
..
.

yn

0

0

..

.

0
..
.

...

0

..

.

0
..
.

...

0

..

.

y1
..
.

..

.

..

.

...

yn

y1
..
.

0
..
.

yn

0

0
..
.

y1
..
.

0

yn

0
..
.

0
..
.

0

0

..

0
..
.

.

0

..

0
..
.

.

0

..

.

y1
..
.














,












yn

and











t
In ⊗ Y Vn = 









y1
..
.

y1
..
.

yn

yn

...



y1
..
.
yn
y1
..
.

y1
..
.

yn

yn

...

y1
..
.
yn
..

.
y1
..
.

y1
..
.

yn

yn

...

y1
..
.
yn










.









Coupled enzymatic networks - tQSSA

35

So,



t

In ⊗ Y Vn (In2

y1
..
.
yn

0
..
.
0







− Ibn ) = 









y1
..
.
yn

...

y1
..
.
yn

0
..
.
0

y1
..
.
yn

...

..

.
y1
..
.
yn

y1
..
.
yn

...

and



(In ⊗ Y ) Vnt ⊗ In + In ⊗ Y Vnt − In ⊗ Y Vnt Ibn












=












y1
..
.

y1
..
.

y1
..
.

y1
..
.

0
..
.

yn

yn

yn

yn

0

0
..
.

y1
..
.

0
..
.

y1
..
.

y1
..
.

0

yn

0

yn

yn

...

...

...

...

0
..
.

y1
..
.

0
..
.

0

yn

0

0

y1
..
.

0
..
.

y1
..
.

0
..
.

0

yn

y1
..
.

y1
..
.

yn

yn

...

...

yn
..

0
..
.

0
..
.

0

0

...

y1
..
.

0
..
.

0
..
.

yn

0

0

...

y1
..
.



0
..
.

...

...












.












0

.

...

yn

y1
..
.

...

yn

Clearly, its sufficient to show the invertibility of D with y1 = y2 = ... = yn = 1. We
examine













D−B =












1
..
.

1
..
.

1
..
.

1
..
.

0
..
.

1

1

1

1

0

0
..
.

1
..
.

0
..
.

1
..
.

1
..
.

0

1

0

1

1

...

...

...

...

0
..
.

1
..
.

0
..
.

0

1

0

0

1
..
.

0
..
.

1
..
.

0
..
.

0

1

0

1
..
.

1
..
.

1
..
.

1

1

...

...

1
..

0
..
.

0
..
.

0

0

...

1
..
.

0
..
.

0
..
.

1

0

0

...

1
..
.
1

...

...

0
..
.

.

...

...

1












.












0
..
.
0







,







Coupled enzymatic networks - tQSSA

36

Now let
V =



v11 . . . v1n

v21 . . . v2n

...

vn1 . . . vnn

t

be an eigenvector of D corresponding to a zero eigenvalue. We aim to show that V = 0. Let
B = diag



b11 · · ·

b1n b21 · · ·

b2n · · ·

bn1 · · ·

bnn



.

Then for each i, j ∈ {1, 2, ..., n},
n
X

vis +

s=1

|

n
X

vri = −bij vij .

(C.6)

r=1
r6=i

{z

:=−λi

}

Note that the left hand side of this equation, which we denote by −λi , is independent of j.
Hence, for all i, j ∈ {1, 2, ..., n} we obtain vij = bλiji . Using this observation in Eq. (C.6) we
get
n
n
X
λi X λr
+
= −λi ,
b
b
r=1 ri
s=1 is

∀ i ∈ {1, 2, ..., n}.

r6=i

This equality can be written in matrix form as
P

1
1
1 + ns=1 b11s
...
b21
bn1
P

1
1
1 + ns=1 b12s
...

b12
bn2

..

.
P
1
1
1
.
.
. 1 + ns=1 bns
b1n
b2n







λ1
λ2
..
.




=0


λn

The coefficient matrix is diagonally dominant along the columns, and hence invertible. This
implies that λi = 0, and so vij = 0.
Lemmas 12 and 13 together complete the proof of Lemma 1 for the case when all the
entries in the connectivity matrices are strictly positive. This proof can be extended to
general connectivity matrices, as stated in the Lemma 1 in the following way.
Suppose that some of the entries in the connectivity matrix are zero. Let,
(
1 if kij1 , kij−1 , kij2 are nonzero,
n
IK = [IK (i, j)]i,j=1 such that IK (i, j) =
0 if kij1 = kij−1 = kij2 = 0,
(
1 −1 2
1 if lij
, lij , lij are nonzero,
n
IL = [IL (i, j)]i,j=1 such that IL (i, j) =
−1
1
2
0 if lij
= lij
= lij
= 0.

(C.7a)
(C.7b)

Hence IK and IL are the unweighted connectivity matrices of the reaction network. The
matrices of intermediate variables, corresponding to existing connections, now have the form
CUIK = IK ∗ CU

CEIL = IL ∗ CL .

(C.8)

Coupled enzymatic networks - tQSSA

37

Replacing CU with CUIK and CE with CEIE in Eq. (4.11), one can easily check that the
solution of the non-zero entries of CUIK and CEIE does not depend on the zero entries of K1 ,
K2 , K−1 , L1 , L2 , L−1 . This observation completes the proof of Lemma 1.
Appendix D. Stability and normal hyperbolicity of the slow manifold M0
Following the approach in the previous section, we first prove the result under the
assumption that K1 , K2 , K−1 , L1 , L2 and L−1 are strictly positive. At the end of this section
we show how to generalize the proof to the case when some of the reactions do not occur.
First we start with a preliminary lemma.
Lemma 14. Suppose Z ∈ R2n×1
is a 2n dimensional vector with positive entries, Y ∈
+
n×1
b = [ψbij ], Γ
b = [b
R+ is an n dimensional vector with positive entries, and Ψ
γij ] ∈ Rn×2n
+
real matrices with positive entries. Let λ ∈ C be a complex number with nonpositive real
part. If V = [vij ] ∈ Cn×2n is a complex matrix that satisfies the following system of linear
homogeneous equations,
2n
n
1 X
ψbij
1 X
vis +
vrj =
(λ − γ
bij ) vij ,
yi s=1
zj r=1
yi zj

1 ≤ i ≤ n,
1 ≤ j ≤ n,

(D.1a)

1 ≤ i ≤ n,
n + 1 ≤ j ≤ 2n,

(D.1b)

r6=j

1
yi

2n
X

n
1 X
ψbij
vis +
vrj =
(λ − γ
bij ) vij ,
zj r=1
yi zj
s=1

then V is the zero matrix.
Proof. Let V = [vij ] ∈ Cn×2n satisfy Eq. (D.1). We will show that vij = 0 for all i, j. Let
P
2n
 n vij , 1 ≤ j ≤ n,
X
i=1
Ri :=
vij , 1 ≤ i ≤ n,
Cj := P i6=j
n

n + 1 ≤ j ≤ 2n.
j=1
i=1 vij ,
Then Eq. (D.1) can be written as
1
1
ψbij
Ri + Cj =
(λ − γ
bij ) vij ,
yi
zj
yi zj
Setting aij =

bij
ψ
yi zj

1 ≤ i ≤ n,
1 ≤ j ≤ 2n,

(λ − γ
bij ), we have
1
1
Ri +
Cj = vij ,
aij yi
aij zj

1 ≤ i ≤ n, 1 ≤ j ≤ 2n.

(D.2)

By summing Eq. (D.2) over i and j separately we obtain the following system of linear
equations in the unknowns {R1 , R2 , ..., Rn , C1 , C2 , ..., C2n }
Ri

2n
2n
X
1 X 1
1
+
Cj = Ri ,
yi j=1 aij j=1 zj aij

n
n
X
1
1 X 1
Ri + Cj
= Cj ,
y
a
z
a
i
ij
j
ij
i=1
i=1

1 ≤ i ≤ n,

(D.3a)

1 ≤ j ≤ 2n

(D.3b)

Coupled enzymatic networks - tQSSA

38

Eq. (D.3) can be written in matrix form as
P2n 1

1
−1 +













1
z1 a11

j=1 a1j

y1

..

..
.

.
−1 +

1
y1 a11

...

..
.

1
y1 a1,2n

1
yn

P2n

1
j=1 anj

1
yn an1

..
.

1
z1 an1

−1 +

..
.

...

1
z2n a1,2n

...

1
z1

1
z2n an,2n

...

Pn

1
i=1 ai1

..

1
yn an2n

.
−1 +

|

{z

1
z2n

Pn

1
i=1 ai,2n















R1
R2
..
.
Rn
C1
C2
..
.








 = 0.






C2n
}

:=A

(D.4)
We next show that the the coefficient matrix, A, is invertible. This will imply that
Ri = Cj = 0, ∀ i, j. This, together with (D.2), will force vij to be zero and we will be done.
To show the non-singularity of A it is sufficient to show the non singularity of the
product of A with a non-singular diagonal matrix


y1
...






yn


A

z1




..


.
z2n


P
1
1
1
.
.
.
−y1 + 2n
j=1 a1j
a11
a1,2n


..
..
...


.
.


P
2n


1
1
1
−y
+
.
.
.
n


j=1 anj
an1
an,2n




=
.


Pn 1


1
1


...
−z1 + i=1 ai1
a11
an1


..
..


..
.
.
.


P
n
1
1
1
...
−z2n + i=1 ai,2n
a1,2n
an2n
|
{z
}
=X

Note that X is a complex symmetric matrix (i.e. X = X t ). To show the non singularity of
X, it is sufficient to show that X has no zero eigenvalue. Assume that α is an eigenvalue of
X and u ∈ R3n a corresponding eigenvector. Break X into two Hermitian matrices,
X=

X + X∗
X − X∗
+i
= S + iT,
2
2i
| {z } | {z }
:=S

:=T

where X ∗ is the conjugate transpose of X). Then,
αhu, ui = hXu, ui = hSu, ui + ihT u, ui.

Coupled enzymatic networks - tQSSA

39

To show that α is not zero, it is sufficient to show that hSu, ui is not zero for any 0 6= u ∈ R3n .
Note that, since S, and T are Hermitian, the terms hSu, ui and hT u, ui) are always real.
X +X̄

X +X̄

But since X is a complex symmetric matrix, Sij = ij 2 ji = ij 2 ij = Re(Xij ),
where Sij , and Xij are the (i, j)-th entries of the matrices S and X respectively, and X̄ij
is the complex conjugate of the complex number Xij , and Re(Xij ) is the real part of Xij .
Therefore,
P2n


1
1
1
−y1 +






S=






j=1

Re a11
..
.
Re a1n1

Re a1j

..

.
−yn +

Re a111
..
.
1
Re a1,2n

...
...

P2n

j=1

Re a1nj

Re a1n1
..
.
1
Re an,2n

−z1 +

Pn

i=1

...

Re a1,2n
..
.
1
Re an,2n

...

Re a1i1
..

.
−z2n +

Pn

i=1






.






1
Re ai,2n

b
ψ

Recall that aij = yiijzj (λ − γ
bij ). If the real part of λ is nonpositive then the real parts of
aij are negative. This implies that Re a1ij < 0 for all i, j. In turn, this implies that S is
diagonally dominant, and all the eigenvalues of S are negative and real, since S is a real
symmetric matrix.
Therefore hSu, ui < 0 for all u ∈ R3n , and α cannot be zero. This implies that X is
invertible, which further implies that A is invertible. So, Ri = Cj = 0 for i, j. Eq. (D.2)
therefore implies that V = 0.
Appendix D.1. Proof of Lemma 2:
Proof. We will prove the lemma by contradiction. Let



z1
y1
 z2 
 y2



Z =  ..  , Y =  ..
 . 
 .
z2n
yn




.


Then



ZR2n ⊗ In = 


z1
z2
..
.
z2n

z1
z1
z2
z2
.. . . . ..
.
.
z2n
z2n









 ⊗ In = 



z1 In
z2 In
..
.
z2n In

|

z1 In
z1 In
z2 In
z2 In
...
..
..
.
.
z2n In
z2n In
{z

2n block columns




,

}

Coupled enzymatic networks - tQSSA




I2n ⊗ Y Rn = I2n ⊗ 

|

y1 y1
y2 y2
..
.. . . .
.
.
yn yn
{z





Y Rn
Y Rn

 
 
=
 



.


...
Y Rn

yn
}


1





y1
y2
..
.

=Y Rn


(i)
Let Rn = 1 · · · 1 0 1 · · ·
1s everywhere else. Then,


(I2n ⊗ Y Rn ) I2n2

40

{z

|

}

2n block columns

be a row vector with a zero in the i-th place and


(1)

Y Rn

..



 

n t
=
− Id
2n









.





.
(n)

Y Rn

Y Rn
..

.
Y Rn

{z

|

}

2n block columns

Therefore,


n t
ZR2n ⊗ In + (I2n ⊗ Y Rn ) I2n2 − Id
2n


(1)

z1 In + Y Rn
 ..
 .

 z I
n n
=
 z I
 n+1 n
 .
 ..
z2n In

...
..
.
...
...
..
.

z1 In
..
.

z1 In
..
.
(n)

zn In + Y Rn
zn+1 In
..
.

. . . z2n In



zn In
zn+1 In + Y Rn
..
.

...
..
.
...
...
..
.

z1 In
..
.

z2n In

. . . z2n In + Y Rn





.





zn In
zn+1 In
..
.

Let



Λ=




Λ(1)
Λ(2)
..

.
Λ

(2n)



,





Γ=




Γ(1)
Γ(2)
..

.
Γ(2n)



,


where Λ(k) , Γ(k) , k ∈ {1, 2, ..., 2n} are n × n diagonal blocks of Λ, Γ respectively. Hence


A11 A12
,
J=
A21 A22

Coupled enzymatic networks - tQSSA

41

where

(1)
z1 Λ(1) + Λ(1) Y Rn + Γ(1) . . . z1 Λ(1)


. . . ..
=  ...
,
.
(n)
zn Λ(n)
. . . zn Λ(n) + Λ(n) Y Rn + Γ(n)


z1 Λ(1) . . . z1 Λ(1)
 ..

. . . ..
=  .
,
.
(n)
(n)
zn Λ
. . . zn Λ


zn+1 Λ(n+1) . . . zn+1 Λ(n+1)


. . ..
=  ...
,
. .
(2n)
(2n)
z2n Λ
. . . z2n Λ

zn+1 Λ(n+1) + Λ(n+1) Y Rn + Γ(n+1) . . . zn+1 Λ(n+1)

. . ..
=  ...
. .


A11

A12

A21

A22

z2n Λ(2n)



. . . z2n Λ(2n) + Λ(2n) Y Rn + Γ(n+1)

Let λ be an eigenvalue of J, with a corresponding

 (k)

v1
V (1)
 v (k)
 V (2) 
2



V =  ..  ∈ C2n , where V (k) =  2.
 ..
 . 
(k)
V (2n)
vn


.

eigenvector



 ∈ Cn , k ∈ {1, 2, ..., 2n}.


(k)

We will show that vl = 0 for all l, k. By definition of eigenvalues
structure of J we get
 

P
(1)
(j)
+ Λ(1) Y Rn V (1) + Γ(1) V (1)
z1 Λ(1) 2n
j=1 V
 

..
 

.
 

P
(n)
2n
(j)
(n)
(n)
(n)
(n)
(n)
 

V + Λ Y Rn V + Γ V
zn Λ
j=1


 z Λ(n+1) P2n V (j) + Λ(n+1) Y R V (n+1) + Γ(n+1) V (n+1)  = 
n
 
 n+1
j=1
 

.
..
 

P
(j)
z2n Λ(2n) 2n
+ Λ(2n) Y Rn V (2n) + Γ(2n) V (2n)
j=1 V

and using the block
λV (1)
..
.
λV (n)
λV (n+1)
..
.






.




λV (2n)

Looking at the above equation row by row we get
zk Λ

(k)

2n
X

V (j) + Λ(k) Y Rn(k) V (k) + Γ(k) V (k) = λV (k) ,

k ∈ {1, 2, ..., n}

(D.5a)

j=1

zk Λ(k)

2n
X

V (j) + Λ(k) Y Rn V (k) + Γ(k) V (k) = λV (k) ,

k ∈ {n + 1, ..., 2n} (D.5b)

j=1

Note that Eq. (D.5) is still in matrix multiplication form. Writing it further in terms of each
of its rows, for each k ∈ {1, 2, ..., 2n} and l ∈ {1, 2, ..., n}, we have (For notational simplicity

Coupled enzymatic networks - tQSSA
let Λ(k)

−1

42

:= Ψ(k) )

2n
n
(k)

1 X (j)
1 X (k)
ψl 
(k)
(k)
λ − γl
vl ,
vl +
vh =
yl j=1
zk h=1
yl zk

k ∈ {1, ..., n},

(D.6a)

k ∈ {n + 1, ..., 2n}.

(D.6b)

h6=l

1
yl

2n
X
j=1

(j)
vl

n
(k)

1 X (k)
ψl 
(k)
(k)
λ − γl
vl ,
+
vh =
zk h=1
yl zk

(k)

Now, Lemma 14 applied to Eq. (D.6) immediately yields that vl = 0 for all l, k. This
implies that the real part of λ cannot be nonpositive. This completes the proof of stability
of J.
Appendix D.2. Stability of slow manifold in the absence of some connections
Lemma 2 show that the slow manifold defined by Eq. (4.10) is normally hyperbolic
and stable when all entries in the connectivity matrices are positive. We next show how to
extend the result to the case when some reactions are absent.
Recall the definitions of the unweighted connectivity matrices, IK , IL , and the associated matrices CUIK and CEIL given in Eqs. (C.7) and (C.8). Let ILt be a n × n matrix with
ones at the places where Lt1 , Lt2 , Lt−1 are non zero and zero where Lt1 , Lt2 , Lt−1 are zeros. Now,
recall the definition of C in section 4.4 and define


C0 = IU ILt ∗ C
Then, in the sense that we only need to differentiate along the coordinates corresponding to
positive connections, one can formally write
#
"
∂ vec (C0 )
Ic
0
K
I0 :=
.
(D.7)
=
∂ vec (C0 )
0 Ic
Lt
Replacing C with C0 in the definition of F and repeating the whole process of finding
the Jacobian of F , now with respect to C0 , and using Eq. (D.7) we obtain the new Jacobian
J0 :=

∂ vec (F (C0 ))
= I0 JI0 ,
∂ vec (C0 )

where the matrix J is the Jacobian matrix given in Eq. (4.17). If the connectivity matrices
have zero entries, then I0 will have zero entries in the diagonal. Therefore, some eigenvalues
of J0 will be zero. But, this does not affect the stability of slow manifold because we only
need to look for the stability along the directions of intermediate complexes that occur in
the reactions. That is, we only need to look at the principal submatrix of J0 corresponding
to the positive entries in the diagonal of I0 . Let this principal submatrix be J0+ . But, since
I0 J0 I0 = I0 JI0 , we see that J0+ is also a principal submatrix of J. And J0+ is independent of
zero entries in the connectivity matrices. Since Lemma 2 implies that, when all the entries
in connectivity matrices are positive, J has eigenvalues with only negative real parts, we get
that J0+ will have eigenvalues with only negative real parts. We conclude that the results
hold even if some entries in the connectivity matrices are zero.

Coupled enzymatic networks - tQSSA

43

References
1. Bennett, M., Volfson, D., Tsimring, L., and Hasty, J. (2007) , Biophys. J. 92(10), 3501
2. Borghans, J., de Boer, R., and Segel, L. (1996) , B. Math. Biol. 58(1), 43
3. Briggs, G. E. and Haldane, J. B. (1925) , Biochem. J. 19(2), 338
4. Chock, P. B. and Stadtman, E. R. (1977) , P. Natl. Acad. Sci. USA 74(7), 2766
5. Ciliberto, A., Capuani, F., and Tyson, J. J. (2007) , PLOS Comput. Biol. 3(3)(3), e45
6. Davidich, M. and Bornholdt, S. (2008) , J. Theor. Biol. 255(3), 269
7. Fenichel, N. (1979) , J. Differ. Equations. 31(1), 53
8. Frenzen, C. L. and Maini, P. K. (1988) , J. Math. Biol. 26, 689
9. Goldbeter, A. (1991) , P. Natl. Acad. Sci. USA 88(20), 9107
10. Goldbeter, A. and Koshland, D. E. (1981) , P. Natl. Acad. Sci. USA 78(11), 6840
11. Hardin, H. M., Zagaris, A., Krab, K., and Westerhoff, H. V. (2009) , FEBS J. 276(19),
5491
12. Hek, G. (2010) , J. Math. Biol. 60(3), 347
13. Horn, R. A. and Johnson, C. R. (1991) , Topics in matrix analysis, Chapt. 4, pp.
268–269, Cambridge University Press
14. Huang, C. Y. and Ferrell, J. E. (1996) , P. Natl. Acad. Sci. USA 93(19), 10078
15. Hyeong, C. and Othmer, H. G. (2010) , J. Math. Biol. 60(3), 387
16. Jones, C. (1995) , In Dynamical Systems, Vol. 1609 of Lecture Notes in Mathematics,
Chapt. 2, pp. 44–118, Springer Berlin Heidelberg
17. Kaper, T. J. (1998) , In Analyzing Multiscale Phenomena Using Singular Perturbation
Methods: American Mathematical Society Short Course, January 5-6, 1998, Baltimore,
Maryland (Proc. Sym. Ap.), pp. 85–132
18. Khoo, C. F. and Hegland, M. (2008) , ANZIAM J. 50, C429
19. Magnus, R. J. and Neudecker, H. (1985) , J. Math. Psychol. 29(4)(4), 474
20. Michaelis, L. and Menten, M. (1913) , Biochem. Z.
21. Murray, J. D. (2003) , Mathematical Biology II, Springer, 3rd edition
22. Neudecker, H. (1969) , J. Am. Stat. Assoc. 64(327), 953
23. Noethen, L. and Walcher, S. (2007) , Nonlinear Anal.-Real. 8(5), 1512

Coupled enzymatic networks - tQSSA

44

24. Novak, B., Pataki, Z., Ciliberto, A., and Tyson, J. J. (2001) , Chaos 11(1), 277
25. Novak, B. and Tyson, J. J. (1993) , J. Cell. Sci. 106(4)(4), 1153
26. Pedersen, M., Bersani, A., and Bersani, E. (2008a) , J. Math. Chem. 43(4), 1318
27. Pedersen, M., Bersani, A., Bersani, E., and Cortese, G. (2008b) , Math. Comput. Simulat.
79(4), 1010
28. Roth, W. E. (1934) , Bull. Amer. Math. Soc. 40, 461
29. Schnell, S. and Maini, P. K. (2000) , B. Math. Biol. 62(3), 483
30. Segel, L. (1988) , B. Math. Biol. 50(6), 579
31. Segel, L. A. and Slemrod, M. (1989) , SIAM Rev. 31(3), 446
32. Shinar, G., Milo, R., Martinez, M. R., and Alon, U. (2007) , P. Natl. Acad. Sci. USA
104(50), 19931
33. Tyson, J. J., Chen, K. C., and Novak, B. (2003) , Curr. Opin. Cell. Biol. 15(2), 221
34. Tzafriri, A. R. (2003) , B. Math. Biol. 65(6), 1111
35. Tzafriri, A. R. and Edelman, E. R. (2004) , J. Theor. Biol. 226(3), 303
36. Wiggins, S. (1994) , Normally hyperbolic invariant manifolds in dynamical systems,
Springer-Verlag
37. Zagaris, A., Kaper, H. G., and Kaper, T. J. (2004) , J. Nonlinear. Sci. 14(1), 59

