arXiv:1109.3888v1 [q-bio.NC] 18 Sep 2011

ANALYZING PROPERTIES OF THE C. ELEGANS NEURAL
NETWORK: MATHEMATICALLY MODELING A BIOLOGICAL
SYSTEM
DANIEL J. KELLEHER, TYLER M. REESE, DYLAN T. YOTT,
AND ANTONI BRZOSKA
Abstract. The brain is one of the most studied and highly complex systems in the biological world. It is the information center behind all vertebrate and most invertebrate life, and thus has become a major focus
in current research. While many of these studies have concentrated on
studying the brain directly, our focus is the structure of the brain itself:
at its core an interconnected network of nodes (neurons). A better understanding of the structural aspects of the brain should elucidate some of
its functional properties. In this paper we analyze the brain of the nematode Caenorhabditis elegans. Consisting of only 302 neurons, it is one
of the better-understood neural networks. Using a Laplacian matrix of
the 279-neuron “giant component" of the network, we use an eigenvalue
counting function to look for fractal-like self similarity. This matrix representation is also used to plot (in eigenfunction coordinates) both 2 and
3 dimensional visualizations of the neural network. Further analysis examines the small-world properties of the system, including average path
length and clustering coefficient. We then test for localization of eigenfunctions, using graph energy and spacial variance. To better understand
these results, all of these calculations are also performed on random networks, branching trees, and known fractals, as well as fractals which have
been “rewired" to have small-world properties. This analysis is one of
many stepping-stones in the research of neural networks. While many of
the structures and functions within the brain are known, understanding
how the two interact is also important. A firmer grasp on the structural
properties of the neural network is a key step in this process.
Contents
Author Summary
1. Introduction
2. Results and Discussion
3. Methods
Acknowledgements
Author Contributions
References

2
2
4
16
22
22
22

Research supported in part by NSF grant DMS-0505622.
1

2

Author Summary
The brain is the biological center driving all animal life, and certainly
our own. Though fundamentally an interconnected system of nodes, the
information-transfer that occurs inside of these networks perpetuates life itself. As a result, the brain is the focus of immeasurable scientific research.
While many studies clinically analyze the brain and its function, our goal
is to look at the brain on a simpler level- as a network of connected points.
Studying the structural connectivity and network properties within the brain
will help further our understanding of the organization underlying its many
functions. In this paper, we study the neural network of the nematode worm
Caenorhabditis elegans. It is a well-understood system consisting of 302
neurons, making it an excellent candidate for our research. (The human
brain is composed of billions of neurons, the connections between which
are not completely known). Through the course of our study, we look for
both self-similarity and small-world characteristics in the structure of the
C. elegans neural network. A better understanding of the brain’s physical
configuration will help to reveal the mechanisms behind its structure and
function.

1. Introduction
Fractal theory has become an increasingly popular topic of both debate
and research in recent years. Beginning with Mandelbrot’s discussion of
Britain’s immeasurable coastline [1], fractal theory has found applications
in both the mathematics and scientific communities. In the geometric sense,
fractals are objects that exhibit self-symmetry: they exhibit the same pattern
on increasingly smaller scales. In other words, magnifications of smaller
portions resemble the whole object.
More recently, fractal theory has found applications in the biological realm.
Kinetics of ion channels have been modeled with fractal structures [2, 3].
Fractal dimension has been used to analyze human EEG signals [4] as well
as the complex morphology of living cells [5, 6]. The applications of fractal
theory in neuroscience have been a particularly prevalent topic of research
[7, 8, 9, 10, 11]. Glial cells have been analyzed in-depth using fractal dimensions and modeling [12, 13, 14]. Dendritic branching has been shown
to have self-similarity [15, 16], and other studies have examined fractal patterns in neuron connectivity [17]. Further applied research has used threedimensional fractal structures to approximate the white matter surface of the
human brain, based on MRI images [18].

MATHEMATICALLY MODELING THE C. ELEGANS NEURAL NETWORK

3

In this paper we use a graph-theoretical approach to probe the structure of
the Caenorhabditis elegans neural network for self-similar structures. Advances in graph theory have proven highly useful in analyzing complex neural networks [19, 20, 21] as well as underlying motifs in the brain [22, 23].
These methods have made considerable contributions to our understanding
of the structure and function of one of biology’s most intricate and important
systems. In this paper we apply these techniques to a physical map of the
C. elegans brain. With a well-connected component of only 279 neurons, it
is an excellent candidate for graph theoretical research on a complete-brain
model. While [24] presents a geometric structure of this nematode brain, our
research continues that of [25] in which Chklovskii et al. propose a finalized
schematic of the C. elegans neural network.
The C. elegans brain is composed of three types of neurons: sensory neurons, motor neurons, and interneurons. Two types of connections exist between these neurons: chemical synapses and gap junctions. The gap junction
network, which sends electrical signals via ion transport, is an undirected
system. Conversely, chemical synapses possess clear directionality [25].
We are only interested in studying the overall connectivity between neurons.
Thus in order to analyze the structure of the C. elegans neural network, we
consider only the skeleton of the brain’s organization. Although some neurons share multiple points of contact (they have a multiplicity of connection
> 1) we consider this a single connection. While chemical synapses send
directional signals, we only observe that two neurons are connected: regardless of that connection’s direction. As a result, we are able to study a
weakly connected network representing only the framework of connections.
(See Methods)
In order to index each of these connections we used the graph Laplacian
matrix, L = [li,j ]. For a graph, G, we define dv as the degree of a vertex v:
the number of total connections. (Note that each vertex represents a neuron).
If vertex u is connected to vertex w then lu,w = −1 and lw,u = −1. These
correspond to the entries in the uth row and wth column, and the wth row
and uth column. Furthermore, Lv,v = dv . All other entries of matrix L
are 0. We also generated similar matrices for randomly generated networks,
random branching trees, and known fractals.
The original goal of this study was to examine the structure of the C. elegans neural network for self-similarity. Through the course of our research
we analyzed many other network properties, and compared these results with
similar calculations on other systems. Although fractal theory has repeatedly been applied in neuroscience, in studying the structure of the nematode
brain the results are not as simple as saying “fractal" or “not-fractal." Instead
we search for self-similar structures, as there is no precise definition of what

4

D. J. KELLEHER, T. M. REESE, D. T. YOTT, AND A. BRZOSKA

it means for a network to have "fractal properties." Nevertheless, we uncover
several interesting properties of the C. elegans neural network.
2. Results and Discussion
Before we could begin our analysis, we had to construct a variety of Laplacian matrices. For our C. elegans model, we derived a Laplacian matrix
from the adjacency matrices used in [25] (See Methods). We already had
the Laplacian matrices of known fractals such as the Sierpinski Carpet, the
Octagasket, the Hexacarpet, and the Sierpinski Gasket (specific subdivisions
were chosen which had similar numbers of vertices as the C. elegans neural
network). Next we wrote a series of MATLAB programs which would generate Laplacian matrices with specific conditions. One produced that of a
random network when given a defined number of vertices (n) and probability of connection (p). Another produced the Laplacian matrix of a randombranching tree, given the total number of vertices (n) as well as the maximum number of branches possible from any point (m). One final program
randomly rewired these networks, moving connections from one vertex to
another with a given probability, p. Details on these programs can be found
in Methods 3.1 and 3.9.
2.1. The Eigenvalue Counting Function. To begin our analysis, we applied the eigenvalue counting function to our Laplacian matrices. The eigenvalue counting function is a cumulative distribution function on the spectrum of a matrix (see Methods 3.2). It computes the set of all eigenvalues of
a given matrix (the spectrum), and counts the total number of eigenvalues
less than the given input. Plotting this function gives an expedient way to analyze how the graph of a given matrix should be generally organized, based
on the spectrum of the graph Laplacian [26]. Figure 2.1 shows the plots of
the eigenvalue counting function on a variety of our Laplacian matrices.
Upon examination of these graphs, a few patterns immediately emerge.
The first is the presence of step-like portions of those graphs corresponding
to known fractals (Fig. 1(b), 1(d), 1(f), 1(h)). These sections of slope-zero
correspond to gaps in the spectrum of the graph. This feature is closely
linked to self-similar fractal structures [27]. Although the eigenvalue counting function plot of the C. elegans brain (Fig. 1(a)) does not show these definitive spectral gaps, this does not conclusively eliminate the possibility of
self-similar structures existing within the neural network. At the same time,
however, this does indicate that the nematode brain is not strictly fractal-like
in structure.
Another interesting pattern appears in the graph corresponding to the
random-branching tree (Fig 1(c)). There is a large vertical jump at x = 1,

MATHEMATICALLY MODELING THE C. ELEGANS NEURAL NETWORK

5

300

400
250
350

200

300

250
150
200

100

150

100
50
50

0

0

10

20

30

40

50

60

70

80

90

0
−1

100

(a) C. elegans neural network

0

1

2

3

4

5

6

7

8

(b) Sierpinski Gasket, Level 5

300

250

250
200

200
150

150

100
100

50
50

0
−2

0

2

4

6

(c)
Random
n = 279, m = 10

8

10

12

0
−2

14

Branching

−1

Tree

0

1

2

3

4

5

6

7

6

7

(d) Hexacarpet Level 3

300
600

250
500

200
400

150
300

100
200

50

0
−5

100

0

5

10

15

20

25

30

35

0
−2

40

−1

(e) Random Network n = 279, p = 0.07

0

1

2

3

4

5

(f) Octagasket, Level 3

400
600
350

500
300

250

400

200
300

150
200
100

100
50

0
−2

0

2

4

6

8

10

(g) Sierpinski Gasket Rewiring p = 0.15

0
−1

0

1

2

3

4

5

6

7

8

(h) Sierpinski Carpet, Level 3

Figure 2.1. The Eigenvalue Counting Function

with a change on the y-axis of approximately 200. This indicates that for this
graph Laplacian, the eigenvalue 1 occurs with extremely high multiplicity.
This is caused by the nature of the tree’s structure. With a finite number of
points (in this case 279) a large number of these points are endpoints: vertices at which no further branching occurs. These points are only connected
to one other: their “parent" vertex. The lack of this spectral “jump" in the C.
elegans brain indicates that there are very few singly-connected endpoints
in the system. Rather, the neural network is highly inter-connected, with
structural properties baring little resemblance to the branches of a tree.
On the other hand, the eigenvalue counting patterns of the C. elegans
neural network do resemble those of the random network (Fig. 1(e)) and
the rewired Sierpinski Gasket (Fig 1(g)). While a similarity in these patterns
(as opposed to the aforementioned dissimilarities) cannot conclusively point

6

D. J. KELLEHER, T. M. REESE, D. T. YOTT, AND A. BRZOSKA

to similar structural properties, these eigenvalue counting functions are a
prerequisite to the next step in our analysis, Weyl ratios.
2.2. Weyl Ratios. In order to find Weyl ratios for our network, we plotted
the respective eigenvalue counting functions on a log-log scale. We then
searched for an interval on which this graph is roughly linear. We determined
a line of best fit for this section, and found its slope, α. We then used this α
to produce a Weyl ratio for each graph (see Methods 3.2). A Weyl ratio is
essentially a rescaling of points in our eigenvalue counting graph, providing
a more revealing visualization. Figure 2.2 shows the Weyl ratios for each
of our Laplacian matrices. Periodicity in the Weyl ratio plot suggests the
presence of self-similar structures. For more on Weyl ratio analysis of known
fractals, see [28].
As expected, the Weyl ratios of known self-similar fractals (Fig. 2(b),
2(d), 2(f), 2(h)) show a high degree of organization. That of the Sierpinski
gasket in particular (Fig. 2(b)), shows unmistakable periodicity. Although
not as readily noticeable, clear patterns exist in the Weyl ratios of other fractals as well.
It should be noted that the Weyl ratio graph of the branching-tree (Fig.
2(c)) is different from those of other networks. Although the tree structure
lacks the high ordering of known fractals, there is a clear distinction between
this special case and all other networks: what we will call “looping". In
fractals, random networks, and the C. elegans brain alike, the vertices are
highly interconnected. Many cyclic paths exist which allow a signal to arrive
back at a starting vertex by traveling through a series of other vertices. Trees,
on the other hand, lack this feature: only one path exists between any two
points. Not only does this create a unique Weyl ratio pattern, but it also
suggests that neural networks are not strictly branching structures, as one
might expect.
While the Weyl ratio pattern of the C. elegans brain ( Fig. 2(a)) is dissimilar from that of a branching tree, it also differs greatly from those of known
fractals. While several cases of slight periodicity could be argued for, this
evidence is not definitive enough to indicate concrete self-similarity in the
C. elegans neural network. However, there does exist similarity between the
Weyl ratio patterns of the C. elegans neural network, the randomly generated
network (Fig. 2(e)), and the rewiring of the Sierpinski Gasket (Figure 2(g)).
(It should be noted that many random networks and SG rewirings were generated, these two examples were chosen as representatives). Although the
significance of examining a "rewired" fractal structure will be explained in
Section 2.4 of this paper, it is important to note that this likeness in Weyl

MATHEMATICALLY MODELING THE C. ELEGANS NEURAL NETWORK
4

7

3

10

10

3

10

2

10

1

2

10

10

0

10

−1

10

−2

10

1

−2

10

−1

0

10

1

10

10

2

10

10
−3
10

(a) C. elegans neural network

−2

−1

10

0

10

10

1

10

(b) Sierpinski Gasket, Level 5

3

10

1.9

10

1.8

10

2

10

1.7

10

1.6

10

1

10
−2
10

−1

0

10

1

10

10

2

−2

10

(c)
Random-Branching
n = 279, m = 10

−1

10

Tree

0

10

1

10

10

(d) Hexacarpet Level 3

10

10

8

10

2.2

10

6

10

4

10

2

10

2.1

10

0

10

−2

10

−4

10

−2

10

−1

0

10

1

10

10

2

−2

10

(e) Random Network n = 279, p = 0.07
3

−1

10

0

10

1

10

10

(f) Octagasket, Level 3
3

10

10

2

10

2

10

1

10

0

10
−2
10

1

−1

10

0

10

1

10

(g) Sierpinski Gasket Rewiring p = 0.15

10
−3
10

−2

10

−1

10

0

10

1

10

(h) Sierpinski Carpet, Level 3

Figure 2.2. Weyl Ratios

ratio patterns can suggest a structural similarity. While it seems counterintuitive that the nematode brain would be a random arrangement of neurons,
the evidence found in the Weyl ratios alone cannot conclude that this is (or
is not) indeed the case. Our further analysis will make distinctions between
these 3 networks.

8

D. J. KELLEHER, T. M. REESE, D. T. YOTT, AND A. BRZOSKA

2.3. The Eigen-Projection Method. Next, we wanted a way to visualize
the neural network. We did this by embedding a graph of all neurons in
Euclidean space via the eigen-projection method explained in [29], similar to
those processes described in [30, 31]. This spectral approach to visualizing
graphs utilizes the eigenfunctions of degree-normalized Laplacian matrices
(see Methods 3.3).
The eigen-projection method plots the vertices of a graph using the eigenfunctions of its Laplacian matrix as a coordinate system (it is also referred
to as ‘plotting in eigenvector coordinates’). This method essentially projects
the graphs into a smaller Euclidean space, typically either R2 or R3 , using
appropriate eigenfunctions. See Methods 3.4 for a more rigorous description.
After embedding each vertex in either 2- or 3-dimensional space, we then
represented neuronal connections (or network connections) with line segments between the appropriate points. In the case of our C. elegans brain
diagram, we also used the same color-coding as [25]: where red represents
sensory neurons, green are motor neurons, and blue indicates interneurons.
Lastly, we labeled the points with the corresponding neuron name abbreviations. This was done using a slight variation of the VISUALIZE program
used by Chklovskii and Varshney, available at [32].
The eigen-projection visualizations (Figure 2.3) allow us to make further
distinctions between the C. elegans brain and other networks. In support of
our previous observations, it is again clear that the nematode brain (Fig. 3(a)
and 3(b) is not strictly fractal in structure. The eigenfunction graphs of the
Sierpinski gasket (Fig. 3(c) and 3(d)), once again display characteristics expected of self-similar fractals: a high degree of ordering and self-symmetry.
While, the eigenvalue counting function and Weyl ratios showed little distinction between the C. elegans brain, and a random graph, these eigenprojections make a clear differentiation between the two. The random graph
(Fig. 3(e) and 3(f)) appears, as expected, more or less a scatter of points. The
C. elegans brain, however, shows a definite structure with organized connectivity. Thus while our previous results appeared more or less inconclusive,
these eigen-projection techniques suggest that the structure of the C. elegans
neural network is not a randomly connected system of neurons. On the other
hand, the C. elegans neural network maintains its resemblance to a rewired
Sierpinski gasket when plotted in eigenfunction coordinates (Fig. 3(g) and
3(h)). While there is no effective way to quantify this heuristic similarity, it
sustains its interest experimentally. This additional similarity continues to
suggest the presence of structural parallels.
The eigen-projection method allows us to view not only the structural ordering, but also the functional organization of the C. elegans neural network.

MATHEMATICALLY MODELING THE C. ELEGANS NEURAL NETWORK

9

0.25

0.2

ASEL

ASER
AIAL
AWCR

AIYL AWCL
ASIL
AIAR
ASIR
AWAL
AWAR
AIYR AINR
AFDL
AFDR
AIBL

0.15

0.2

AINL
AIZR
ADFR

ASKR

0.05
0

PVQL
ASJL
AIMR
ASJR

ASHR
AWBR
RIR
AWBL
AUAR
ASHL

0.05

VD02
DD01
VC01
VD04
VC02
VC03
VD03
VD05
DD03
VD01 VB02
DB01
VD06
VA03
DA03
DB03
AS03
HSNR
DB02
DA02
DA04
VA04
DB04
VB04
PVQR
VA02VB03
VA05
ASER
VB01
VB05
AIAL
VA06
AS02
AWCR
DA01
AS05
AIAR
ASEL
AS01
DA06
AIYLAWCL
ASIL
ASIR
AS04 DA05
VA01
RID
AWAL
VC04
AWAR
AFDL
ASKL HSNL
AIZLAIBR
AFDR
ASJR
AIYRAINR
ASGL
PVPRSABD
AIBL
AVDL
ASJL
AVDR
VA07
AVFR
ASKR
ASHR AIMR
ASGR
PVQL
AVERSABVL
AVL AVBL
SABVR
AVFL
AIML RIFR
AVEL
AIZR
AVHLVC05
RIFL
AWBL
AINL
ASHL ADLR
VB06
AWBR
PVNL VB07 PVNRAVBR
ADFRRIR
AVJR
AVHR FLPR
AUAR
ADLL
AS10
AVG
VD07 AVAL
ADAL
AVJL
SAADLPLNL
PQR
RIML
AS07
ADFL
VA10
ALAFLPL
BAGL
AUAL
DVC
ADAR
DA07
AS08
PHAL
DD04 AVAR
BAGR
PVPL
SMBVL
AVM AS06
PLNR SDQL
BDUL
AQRPVT
RIMR
RMGR
DB05
SMBVR
URXL
SAADR
PHARDB06
BDUR
ALNL
RMFL
RMGL RIGL
RMFR
PHBR
LUAR
SMBDL
SDQR
SIBDL
SAAVL
SAAVR
ALML
DVA
PLML
PVWR
PDB
SIADR
AS09
PVWL
PLMR
SIBVL
PHBL
AVKR
PVCL
ALNR
RIGR SIAVL
SIADL
VD11
RIBL
ADER
VD08
SMBDR
LUAL
SIAVR
RIVL
SIBDR
URYDR
RIS
URYVL
ALMR
PVMDB07
DA08
RIAL
SMDVR
AVKL
VD12
RICL
SIBVR
RIBRSMDDR
SMDDL
URYDL
RIVR
RMHL
URBL
ADEL
URXR
SMDVL
RMHR
URYVR
VB11
VA11
VB10
RIAR
PHCR
AS11
RMDR
URBR URADL
PVCR
RICR
VD13
OLQVL
CEPVL
PVRPDEL
IL2L
OLQDR
OLLR
PVDR
CEPVR
OLLL
PHCL DA09
IL2DL
OLQDL
IL1L
CEPDL
RMED
RMDL
URAVL
URAVR
IL2R
URADR
IL1VL
PDA
RMDDR
RMDVR
IL2VL
RMDVL
RMDDL
CEPDR
IL1DR
OLQVR
IL1R
RIPL
DD06
RIH
IL2VR
IL1DL
IL2DR
IL1VR
PDER
RMEL
RIPR
VA08
RMEV
VA12
DVB
RMER

0.1
HSNL

AIBR
ASGR

0.1

DD02

0.15
ASGLASKL

AIZL

PVQR
HSNR
AIML
AVFR
ADLR
RIFR
AVFL
ADLL
AVHL
RIFL
ADAL
ADFL
AVHR
AUAL
BAGR
RIML
BAGL
SMBVL
SAADL
PHAL
ADAR
SMBVR
RIMR
PHAR
AVJL
RMGL
AVJR
PLNL
AVG
VC05
AVDR
PVPR
RMGR
PLNR
VC04
SAADR
RIBL
PVNL
PLML
URXL
SMBDL
AQRFLPL
SABVL
BDUL
PHBR
PVPL
FLPR
AVDL
RIGR
SAAVL
AVKR
DVC
SABVR
PQR PHBL
ALNL
AS10
VB01
RIGL
RMFR
VD11
VA10
PVT DA07
AS07
AS08
SDQR
SAAVR
DVA VD01
AVBL
DA08 AVL
RIVL
RIBR
SDQL
LUAL
AS09
PVWL
PVNR
SMBDR
PVWR
ALA
SABD
DB05
DB06
PHCR
DA06
ALNR
SIADR
SIBDL
RICL
SIAVL
RMFL
VA06
AS05
VA01
LUAR
VA02
VA11
VD12
SIADL
AS04
PDB
DB07
AVBR
DA01
RID
VB02
PLMR
ALML
PHCL
SMDDR
DA05
AS01
VB10
VB11
VC02
RIVR
DA02
VC03
SIBVL
BDUR
DD01
SMDDL
AS11
SIAVR
AS02
VB03
VA05
VA03
VA04
AVKL
AS03
DB01
SIBDR
PVM
SMDVL
VB07
PVDR
PDA
AS06
DA04
DD06
ADEL
VD04
DB04VC01
DA03
AVM PDEL
DVB
VB05
VD02
AVAL
VB04
AVEL
SIBVR
VD13
VD03
VA07
URXR
DA09
VD08
DB02
VA12
SMDVR
PDER
ADER
AVER
RMHL
VD07 DB03 VD05
PVDL
VD06
ALMR
RMHR
URYVL
AVAR
RIS
DD03
DD02
URBL
VB06
URYVR
PVCL
URYDLURYDR
RICR
RMDR
VD10 VB09 DD04
CEPVR OLQVL
VD09
URBR
OLQDR
PVCR
CEPVL
DD05VB08 VA08
VA09
IL2L RMED
RMDL OLLR
CEPDL
URADL
IL2DL
OLLL OLQDL
PVR
RMDDR IL2R
IL2VL
RIPL IL1L
RMDDL
URAVL
RMDVR
RMDVL
IL1VL
OLQVR
CEPDR URAVR
URADR
IL2VRIL1DL
RIPR
IL1R
IL1DR
IL1VR
IL2DR
RMEL
RMEV

−0.05
−0.1
−0.15

RIAL

RIAR

0

−0.05

RIH

PVDL

−0.2

VB09

−0.25
VD10
VD09

−0.3
0.25

0.15

0.15
0.1

0.1

−0.1

0.05

0.05

RMER

0

0

−0.05

−0.05

−0.1
−0.1

−0.15
−0.2

−0.15

−0.1

−0.05

0

0.05

0.1

VA09

VB08

DD05

0.2

−0.15
−0.15

0.15

−0.2

(a) C. elegans neural network, (ϕ2 , ϕ3 ) (b) C. elegans
(ϕ2 , ϕ3 , ϕ4 )

neural

network,

0.1

0.08

0.06
0.05

0.04
0

0.02
−0.05

0
−0.1

−0.02
−0.08
−0.06
−0.04
−0.02

−0.04

0.04
0.02

0

0

0.02

−0.02
0.04

−0.06
−0.1

−0.04
0.06

−0.08

−0.06

−0.04

−0.02

0

0.02

0.04

0.06

0.08

−0.06
0.08

0.1

(c) Sierpinski Gasket, Level 5, (ϕ2 , ϕ3 ) (d) Sierpinski
(ϕ2 , ϕ3 , ϕ4 )

−0.08

Gasket,

Level

5,

0.2

0.15
0.25

0.1

0.2

0.15

0.05
0.1

0

0.05

0

−0.05
−0.05

−0.1

−0.1

−0.15
0.2

−0.15

0.15
0.1

0.2
0.05

0.15
0

−0.2

0.1
−0.05

0.05
−0.1

0
−0.15

−0.25
−0.15

−0.05
−0.2

−0.1

−0.05

0

0.05

0.1

0.15

−0.1
−0.25

0.2

−0.15

(e) Random Network n = 279, p = 0.07, (f) Random Network n = 279, p = 0.07,
(ϕ2 , ϕ3 )
(ϕ2 , ϕ3 , ϕ4 )
0.15

0.1
0.15

0.1

0.05

0.05

0

0

−0.05
−0.05

−0.1

−0.15
−0.1
−0.2
0.15
0.1
0.15

0.05

−0.15

0.1

0

0.05
−0.05

0
−0.05

−0.1
−0.2
−0.2

−0.1

−0.15
−0.15

−0.1

−0.05

0

0.05

0.1

0.15

−0.15
−0.2

−0.2

(g) Sierpinski Gasket Rewiring p = 0.15, (h) Sierpinski Gasket Rewiring p = 0.15,
(ϕ2 , ϕ3 )
(ϕ2 , ϕ3 , ϕ4 )

Figure 2.3. The Eigen-Projection Method

It is clear that the neurons are arranged roughly by neuron type. There is a
distinctive cluster of motor neurons (green), a larger sub-component of sensory neurons (red), and interneurons interspersed throughout the network

10

D. J. KELLEHER, T. M. REESE, D. T. YOTT, AND A. BRZOSKA

(blue). This indicates that although the brain may not posses the strict selfsimilarity of a fractal structure, it is indeed highly organized. The neuron
grouping evident in our visualization has most likely developed for entirely
functional purposes: producing more efficient signal transfer and more organized communication between neurons.
2.4. Small-World Network Properties. When analyzing graphs as networks of nodes, it is useful to consider the nature of the graph’s connections.
To do this, we consider two functions defined on graphs: average clustering
coefficient and average path length. The clustering coefficient, cv , of a vertex
v, is the probability that any two vertices neighboring v are also connected
to each other. Formally, this can be calculated by counting the number of
edges between neighbors of v and dividing by the number of total possible
connections that could exist between neighbors of v. (For more details, see
Methods 3.5). For a graph G, the average clustering coefficient, c, is the
average of cv over all vertices.
The path length between two vertices u and v is the shortest path along the
graph’s edges connecting u and v (Note that this path usually travels through
a number of other vertices). Using Djisktra’s algorithm, it is possible to
rigorously determine the shortest path between a given vertex and each other
vertex on the graph. By repeating the algorithm for each node on the graph,
it is possible to determine the shortest path between each pair of vertices. It
follows naturally that the average path length, l, is calculated by finding the
arithmetic mean of the shortest paths between each pair of vertices on the
graph. We use both c and l to analyze small-world behavior.
One prominent theme in modern graph-theoretic and fractal research is
the “small-world phenomenon". This phenomenon is best described as the
tendency for certain networks to have a much shorter path length than intuition suggests. For example, the term “Six Degrees of Separation" suggests
that any two people on earth are no more than six “steps" away from each
other, even though it seems that this number should be much larger than six.
This phenomenon can be explained by the generalization that humans live
in relatively large and tight-knit social networks, and thus have a relatively
high c value. However, each person also likely possesses a few long distance relationships, allowing l to attain very small values without lowering
the value of c significantly. Thus, small-world networks are (generally) defined as networks which have a much higher c value than random networks,
but maintain a value of l only slightly larger than that of a random network
[35].
Small-world networks arise quite often in the natural sciences, as they allow for the efficient transfer of information while maintaining a certain level

MATHEMATICALLY MODELING THE C. ELEGANS NEURAL NETWORK

11

Graph
Clustering Coefficient Average Path Length
Sierpinski Gasket, Level 5
0.4495
17.3721
Random(Sierpinski Gasket)
0.0104
5.748
Sierpinski Gasket Rewire p = 0.15
0.2843
7.3833
Random(SG Rewire)
0.0104
5.748
C. elegans Neural Network
0.3371
2.5377
Random(C. elegans Neural Network)
0.0581
2.3458
Figure 2.4. Clustering Coefficient and Path Length

of complexity. There is a great deal of research which suggests that neural networks possess small-world properties [33, 34]. Our findings propose
that C. elegans is no exception. As Figure 2.4 shows, the C. elegans neural
network has an average path length only slightly larger than that of its associated random network (see Methods 3.6 for how these ‘associated random
networks’ were constructed). At the same time, the average clustering coefficient for C. elegans is six times larger than that of its associated random
network. This being the case, the neural network of C. elegans satisfies the
small-world properties as defined by [35].
It should be noted that this discussion of small-world networks is relevant
to our discussion of self-similar fractals. Certain research [36] suggests that
there is an apparent dichotomy between fractal structures and small-world
networks. To illustrate this idea, refer again to Figure 2.4. It is apparent
that the 5th level Sierpinski Gasket is not small-world in nature: its average
path length is significantly larger than that of its associated random network.
Before we continue our discussion of small-world networks, we must define
the neighborhood of a graph.
The neighborhood of a graph, H(m), where m is a positive integer, is also
useful in analyzing small-world networks. For our purposes a neighborhood
of size m around a vertex v is the set of all vertices that can be reached in m
steps or less from v (see Methods 3.7 for a rigorous definition). The behavior
of H(m) can tell us quite a bit about structure of a graph, G. If we look at
the growth characteristics of H(m) for small m, we begin to understand the
localized neighborhoods of G. Certain research suggests that H(m) grows
exponentially for small m if G is a small-world network [36]. Likewise,
H(m) tends to grow polynomially if G is a self-similar fractal. Figure 5(a)
shows a plot of H(m) for the C. elegans neural network. Figures 5(b) and
5(c) show the same plot on log-log axes and linear-log axes, respectively.
Unfortunately, the number of relevant points is simply too small to make
a concrete statement as to whether or not this H(m) shows exponential or

12

D. J. KELLEHER, T. M. REESE, D. T. YOTT, AND A. BRZOSKA

300

250

200

150

3

10

100

2

10

50

0

1

2

3

4

5

6

7

8

9

10
1

10
0
10

(a) C. elegans neural network

1

10

(b) C. elegans neural network, log-log
400
350

300

250

200

3

10

150
100
2

10

50

0

0

5

10

15

20

25

30

35

40

1

10

2

3

4

5

6

7

8

9

10

(c) C. elegans neural network, linear-log

(d) Sierpinski Gasket, Level 5

Figure 2.5. Graph Neighborhoods
polynomial growth. On the other hand, H(m) is clearly polynomial for the
Sierpinski Gasket (Fig. 5(d)). In fact, it appears roughly linear.
Thus far, our research suggests that C. elegans neural network does not appear to structurally resemble a tree, a random graph, or a self-similar fractal.
However, it does appear to possess small-world properties. This realization
motivated our work with network-rewiring, related to that done by Watts and
Strogatz. In [35] they showed that moving connections in an ordered network, with a certain probability p, led to some interesting changes in graph
structure. Namely, when p is small, a slight increase in p causes a large drop
in l but does not change c appreciably: thus the network takes on small-world
characteristics. Intuitively this can be explained by the fact that these sparse
random connections don’t change a graph’s strong localized structure, but it
is now easier to travel long distances via these new connections which can
span large gaps.
This was our motivation in analyzing the rewired Sierpinski Gasket (seen
throughout previous sections). Self-similar fractals are highly ordered networks, as were the ordered graphs analyzed in [35]. By rewiring certain

MATHEMATICALLY MODELING THE C. ELEGANS NEURAL NETWORK

13

known fractal structures, we were able to observe if the resulting smallworld network was comparable to our C. elegans neural network, which has
been demonstrated to have small-world properties (See Methods 3.8 for our
rewiring algorithm). This would suggest that the C. elegans brain has localized self-similarity with interspersed gap-spanning connections, allowing
for more efficient signal transfer. Figure 2.4 shows the results of rewiring the
5th level Sierpinski Gasket. Note that the random graphs associated with the
Sierpinski Gasket and its rewiring are identical because rewiring preserves
the number of connections, and thus the average degree. It is clear that the
rewired Sierpinski Gasket is an example of a small-world network based on
our definitions, and thus maintains interest as a comparison to the C. elegans
neural network. While previous evaluations inferred similarities between
these two networks, we now know that both show small-world properties as
well.
2.5. Energies and Spacial Variances. Next, we analyzed energies and spacial variances on each of our graphs. Using an eigenfunction of a graph’s
Laplacian, ϕ, one can calculate a graph energy specific to ϕ (See Methods
3.9). Knowing the resistance between any two vertices and a constant γ, one
can also use this ϕ to calculate a spacial variance (See Methods 3.10). These
two quantities allow us to observe localization of eigenfunctions. This localization occurs when eigenfunctions are approximately zero except for in
a localized region. Localized eigenfunctions are a feature of certain selfsimilar fractals, such as the Sierpinski Gasket [37].
The energies and spacial variances (at γ = 1) of the eigenfunctions of the
unnormalized Laplacian of the C. elegans neural network were compared to
those of other graphs. These included random graphs, fractal graphs, smallworld networks, and random trees. Distributions of these values were plotted
for each network. Any resemblance in the distributions of the energies and
spacial variances could indicate some similarity in the structure of the graphs
[37].
The energies and spacial variances of the random graph (Fig. 6(c) and
6(d)) were quite different from those of the neural network. In the random
network, the distributions of these values tend to be peaked and symmetric,
whereas those of the neural network are more spread-out and skewed (Fig.
6(a) and 6(b)). This evidence suggests that the neural network of C. elegans
is not randomly distributed. Intuitively, this is what one would expect, and
is consistent with our earlier observations.
Next, we continued our comparison of the neural network of C. elegans
to known self-similar fractals, once again using the 5th subdivision of the
Sierpinski Gasket. The energies and spacial variances of this fractal (Fig.

14

D. J. KELLEHER, T. M. REESE, D. T. YOTT, AND A. BRZOSKA
Energies of Symmetric Unweighted Graph
120
Spacial Variance of Symmetric Unweighted Graph
80
100
70

60

80

Count

50
Count

60

40

40

30

20
20
10
0

0

10

20

30

40

50
Energies

60

70

80

90

0

100

0

0.1

0.2

0.3

0.4

0.5
Spacial Variance

0.6

0.7

0.8

0.9

1
−3

x 10

(a) C. elegans neural network energies (b) C. elegans neural network spacial variances)
Spacial Variances of Random Graph, p=.07

Energies of Random Graph, p=.07

100

60

90
50

80
70

40

Count

Count

60

30

50
40

20

30
20

10
10
0

0

5

10

15

20

25

30

0

35

0

1

2

3

Spacial Variances

Energies

−4

x 10

(c) Random graph (n = 279, p = 0.07) (d) Random graph (n = 279, p = 0.07)
energies
spacial variances
Energies of Sierpinski Triangle, degree 6
120
Spacial Variance of Sierpinski Triangle, degree 6
250
100

200
80

Count

150
Count

60

100

40

50

20

0

0

1

2

3

4

5

6

0

7

Energies

0

1

2

3

4
Spacial Variance

5

6

7

8
−3

x 10

(e) Sierpinski Gasket, Level 5 energies (f) Sierpinski Gasket, Level 5 spacial variances
Spacial Variances of Random Tree, m=10

Energies of Random Tree, m=10

100

250

90
80

200

70
60

Count

Count

150

50
40

100

30
20

50

10
0

0

2

4

6

8

10

12

0

14

0

0.002

0.004

0.006
Spacial Variances

Energies

0.008

0.01

0.012

(g) Random Tree (n = 279, m = 10) en- (h) Random Tree (n = 279, m = 10) spaergies
cial variances
Spacial Variances of Rewired Sierpinski Gasket, p=.15

Energies of Rewired Sierpinski Gasket, p=.15

200

60

180
50

160
140

40

Count

Count

120
30

100
80

20

60
40

10
20
0

0

1

2

3

4

5

6

7

8

Energies

(i) Sierpinski Gasket Rewiring (p
0.15), energies

9

0
0.4

0.6

0.8

1

1.2
Spacial Variances

1.4

1.6

1.8

2
−3

x 10

= (j) Sierpinski Gasket Rewiring (p
0.15), spacial variances

=

Figure 2.6. Graph Energies and Spacial Variances
6(e) and 6(f)) vary considerably from those of the neural network. Although
the spacial variances of all graphs were roughly symmetric, the variances of
the neural network were much lower than those of the Sierpinski Gasket.
On the neural network, the spacial variances were all less that 1 × 10−3 ,
whereas those of the fractal network ranged between 1 × 10−3 and 8 × 10−3 .

MATHEMATICALLY MODELING THE C. ELEGANS NEURAL NETWORK

15

Furthermore, the distribution of energies of the neural network was skewed
right and ranged from 0 to almost 100, while the energies of the Sierpinski
Gasket were very jagged (no resemblance to a normal distribution) and contained many gaps. In addition, all of these energies were in a narrow range
between 0 and 6. These differences are in agreement with earlier results,
suggesting that the nematode brain is not strictly fractal in structure.
We also compared the C. elegans neural network to a random branching
tree (Fig 6(g) and 6(h)). The energies and spacial variances of the random
tree are again different from those of the neural network. The energy distribution of the tree was peaked, with most values falling between 0 and 10,
whereas those of the neural network were distributed over a wider range,
from 0 to 100. The energies of the neural network are skewed right. The
differences in spacial variances were even greater. The spacial variances of
the neural network lie between 0 and 1 × 10−3 , whereas those of the random
trees are spread over a larger range, up to about 1.5 × 10−2 . The distribution
of the neural network is again skewed right, whereas that of the random tree
is very much skewed left. Once again, the neural network does not exhibit
the same structural properties as a random-branching tree.
Thus far, the “small-world" rewired Sierpinski gasket has shown the most
similarities to the C. elegans neural network. Once again we analyzed the
rewiring of the fifth level Sierpinski triangle, with p = 0.15. This probability
was chosen to generate a small-world network without disturbing much of
the self-similar structure. After rewiring, the energies of the graph (Fig.
6(i)) were distributed in nearly the same pattern as those of the original selfsimilar fractal, only the values were shifted slightly to the right. The same
is true of the spacial variances (Fig. 6(j)), except that this distribution was
shifted to the left. Although the range of the distributions on the rewired
fractal is closer to that of the neural network, the distributions themselves
remain markedly different from those of the C. elegans brain. This leads
us to believe that the structure of the C. elegans neural network, although
small-world in nature, does not structurally resemble the Sierpinski Gasket.
On the other hand, the spacial variances of the C. elegans neural network
are considerably lower in magnitude than those of the Sierpinski Gasket.
This suggests localization of eigenfunctions, which could in turn indicate
the presence of self-similarity in the network.

2.6. Conclusions. Using a variety of mathematical techniques including
the eigenvalue counting function, Weyl ratios, and the eigen-projection method,
analyzing small-world properties, and calculating of graph energies and spacial variances, we were able to uncover some structural properties of the C.

16

D. J. KELLEHER, T. M. REESE, D. T. YOTT, AND A. BRZOSKA

elegans neural network. Although much previous research has been dedicated to applying fractal theory to neuroscience, our results suggest otherwise. The known structure of the C. elegans neural network does not exhibit
properties characteristic of strictly self-similar fractal networks. While some
evidence suggests that there may be localized instances of self-similarity, we
cannot quantify or definitively state such a conclusion. Our research found
additional structures which the C. elegans neural network does not resemble:
it does not exhibit the branching properties of a tree, nor does it constitute a
randomly connected network.
As to what we can conclude, our research is consistent with related work,
showing that the brain exhibits small-world network properties. Furthermore, the network has highly localized eigenfunctions, which could suggest
the presence of self-similar structures. Further research would be required
to determine the nature of these localized eigenfunctions. Although the C.
elegans neural network does not appear to be random, tree-like, or fractal in
structure, it is certainly highly ordered. This organization most likely aids
in functional efficiency of the system. Further research is needed to determine a more refined view of the brain’s structural properties. Although C.
elegans has proven to be a useful model organism, with a well-defined map
of its neural network, this network consists of only 279 nodes. While this
makes the system fairly efficient to study computationally, this small number
of nodes makes network-analysis somewhat limited and rather unrevealing.
However, due to the difficulty in determining the exact layout of each neuron
in the network, very few consistent complete-brain maps exist at this time.
Similar analysis as that provided in this paper, applied to a more complex
or higher-order neural network, could potentially show more conclusive results.

3. Methods
In order to analyze only the framework of the C. elegans neural network,
we constructed a Laplacian matrix derived form the adjacency matrices in
[32]. We wanted to look only at connections between neurons, regardless
of type or direction. The network of chemical synapses sends signals in one
direction only, resulting in a non-symmetric adjacency matrix, C. In order
to disregard this directionality, we added this matrix to its own transpose, C 0 ,
creating a symmetric matrix indexing all chemical connections. We added
this matrix to the adjacency matrix of the gap junction system, G (which is
already symmetric because these connections are bidirectional).
B = [bi,j ] = (C + C 0 ) + G such that i, j ≤ 279

MATHEMATICALLY MODELING THE C. ELEGANS NEURAL NETWORK

17

We then normalized all non-zero entries of this combined matrix, B, to
be 1 (in order to avoid multiplicity of connection), resulting in an adjacency
matrix representing only the framework of the entire network, A.
A = [ai,j ] where ai,j = bi,j /bi,j = 1 if bi,j > 0, otherwise ai,j = 0( when bi,j = 0)
It is then simple to produce a Laplacian matrix, L, as shown below:
dj =

i=279
X

ai,j for each j ≤ 279

i=1

Note that dj is the degree of each vertex j. The degree matrix, D, is now
defined as:
D = [di,j ] where di,j = dj when i = j otherwise di,j = 0(when i 6= j)
Then the Laplaican matrix, L, is given by:
L=D−A
3.1. Generating Random Graphs and Trees. Throughout this project, we
compared the C. elegans neural network to both random graphs and branching trees. In order to generate a Laplacian matrix representation of the random graphs, we used the following algorithm:
First, we fixed the number of vertices, n, and the probability of connection, p. We then constructed an empty n × n matrix, R = [ri,j ].
For each ri,j such that i < j we assign a random value ai,j such that
0 ≤ ai,j ≤ 1 for all i, j ≤ n. If ai,j ≤ p then ri,j = 1, otherwise ri,j = 0.
To produce an adjacency matrix of this graph, A, we must add R to its
own transpose:
A = R + R0
Using this adjacency matrix we can construct a Laplacian matrix using the
method described previously.

The algorithm for producing the Laplacian matrix of a random-branching
tree is more involved. Again, we fix the number of vertices, n, and also
specify the maximum number of "children" from any given branch-point,
m. We create an empty n × n matrix, T = [ti,j ]
We begin by generating a random integer a1 such that 0 < a1 ≤ m, and
take t1,1 = a1 . This corresponds to the first vertex having |a1 | branches. To
represent these branches in the matrix, we take t1,j = −1 for j = 2, · · · , a1 +
1 and ti,1 = −1 for i = 2, · · · , a1 + 1.

18

D. J. KELLEHER, T. M. REESE, D. T. YOTT, AND A. BRZOSKA

Next we move to all subsequent vertices. Because no “looping" exists in
the structure of the tree, each node can only be connected to its parent vertex
and its "children" vertices. We take S = {j : ti,j = 0 for all i ≤ n} Then k,
where k =min(S) is the smallest-labeled node which does not have a parent
vertex, i.e. the first column with all 0 entries corresponds to the first point
not yet connected. (Note in the case of vertex 2, k = a1 + 2). This vertex k
is the first "offspring" from the next branch-point.
Now, as above, for each remaining vertex v we choose another random
integer, av , such that 0 < av ≤ min(m, n − k + 1) and take tv,v = av + 1.
(Note that vertex v has av children, however av + 1 is the degree of node
v, taking into account its parent-connection). To represent the "offspring"
branches of this vertex v, we use the following formula:
ti,v = −1 for i = k, k + 1, · · · , k + (av − 1)
and
tv,j = −1 for j = k, k + 1, · · · , k + (av − 1)
We use min(m, n−k+1) when choosing av to avoid adding more vertices
than the n which we originally fixed. This algorithm, when repeated for each
vertex v, produces the Laplacian matrix of a random branching tree.
3.2. The Eigenvalue Counting Function and Weyl Ratios. For a given
graph Laplacian matrix, L, the eigenvalue counting function, N (x) is a cumulative frequency function on the spectrum of the matrix where:
N (x) = #{λj ≤ x} where each λj is an eigenvalue of L
The growth of N (x) is approximately xα , thus the relevant portion of each
graph, when using a logarithmic scale, appears to be linear. A line of best
fit was found for each relevant interval, and the slope, α, calculated. Using
this α, we plotted the Weyl ratio, W (x), such that:
W (x) = N (x)/xα .
These Weyl ratios allow us to examine the spectrum of each matrix, looking
for elements such as symmetry and periodicity. [28]
3.3. Normalizing a Laplacian Matrix. We used two different forms of
the graph-Laplacian matrix: the standard Laplacian matrix and the degreenormalized Laplacian. In the case of eigen-projections, we utilize the degreenormalized matrix. We define the degree matrix, D, as before: a diagonal
matrix whose non-diagonal elements are 0, and each entry dj,j is the degree
of the j th vertex. Using both the standard Laplacian, L and its corresponding
degree matrix, D, we produce the degree-normalized Laplacian, Q:
Q = D−1/2 LD−1/2

MATHEMATICALLY MODELING THE C. ELEGANS NEURAL NETWORK

1.2

0.25

0.2

1

ASEL

PLNL

ASER
AIAL
AWCR

AIYL AWCL
ASIL
AIAR
ASIR
AWAL
AWAR
AIYR AINR
AFDL
AFDR
AIBL

0.15
0.8

AIZL

ASGLASKL

AIBR
ASGR

0.1

HSNL

AINL
AIZR
ADFR

ASKR
ASHR
AWBR
RIR
AWBL
AUAR
ASHL

0.6
0.05
0.4
0

0.2

19

VD08

−0.05

SMBVL
SAADL
DD04

0

VA08

SAAVR
ADFL
SMBDL
BDUL
AIML
AIZL
RIVR
RMEV
AVHR
AVKR
VB07
ALNR
RIML
RMGL
VB01
RMGR
ASGL
RIMR
AWBL
AIBL
VB06
AIBR
AWAL
SMDDL
VA07
VD07
ASHL
AIAL
DVA
ASKL
ASIL
RMDR
RIR
SIAVL
RIAL
AUAL
AIYL
RMFR
R
ICL
ASEL
SMDDR
RMED
ADAL
RMDVR
PVQL
AWCL
SMDVR
RMDL
RMHR
IL2L
OLQVL
RIGL
RIFL
RMFL
ADEL
ALML
SIBDR
AWCR
ASIR
RIVL
ADLL
VA09
ASER
AFDL
AIZR
IL2R
IL2VL
URBR
ADER
ADAR
URXL
SMDVL
HSNL
ALNL
RIH
RMDDL
RMHL
RIS
RIBL
URADL
URAVL
RMEL
AINR
RIGR
SAAVL
SDQR
AVHL
RIAR
AIYR
AVKL
SMBDR
CEPVL
RMER
RMDVL
AFDR
SIBVR
AVFL
AQR
RIBR
URXR
AIAR
OLLL
IL1L
IL1DL
IL2DR
OLLR
IL1R
RIPL
IL1DR
IL2VR
OLQDR
BAGR
URAVR
CEPDL
CEPDR
AVER
ADLR
AWBR
ASHR
AWAR
AVEL
AVFR
RICR
URYDL
URYVL
BAGL
ADFR
ASGR
RMDDR
PVT
AVJR
AVBR
FLPR
FLPL
OLQDL
IL1VL
URBL
OLQVR
AUAR
DD03
AS06
VC03
HSNR
CEPVR
DVC
PDER
SDQL
ASKR
VB02
AVBL
AVJL
AINL
URYDR
IL2DL
URYVR
RIPR
PVNL
PHAL
PVPL
PVPR
AIMR
RIFR
URADR
IL1VR
PVR
PVQR
SIAVR
VC04
AVM
SIBVL
VA02
SABD
VD01
ASJL
AVDR
AVAL
ALA
VC05
PHAR
VB09
BDUR
VB08
PVNR
PVCR
SIADL
AVDL
AVG
VA01
PLMR
VA03
PVCL
PVM
AVAR
SABVL
DB02
DB03
VD02
DD01
DB01
AVL
ASJR
SIADR
VD06
DB04
AS05
VC02
PDEL
DB06
SABVR
AS01
DA02
DA01
DA04
DB05
ALMR
VB05
VC01
VD03
DA05
PHBR
PQR
VB03
VB04
DD02
VA04
AS03
DA03
LUAR
PVDR
VA06
VD05
VA05
AS04
VD04
AS10
AS02
PHCR
PVWL
SAADR
LUAL
PHBL
DA06
RID
DA08
DB07
SIBDL
VB10
PVWR
VB11
AS07
VA12
PVDL
VD10
PHCL
VA11
DVB
DA09
VD09
DD05
VD11
SMBVR
AS09
VD12
PLML
DD06
VA10
VD13
PDA
AS11
PDB

RIH

PVQL
ASJL
PVQR
AIMR
ASJR
HSNR
AIML
AVFR
ADLR
RIFR
AVFL
ADLL
AVHL
RIFL
ADAL
ADFL
AVHR
AUAL
BAGR
RIML
BAGL
SMBVL
SAADL
PHAL
ADAR
SMBVR
RIMR
PHAR
AVJL
RMGL
AVJR
PLNL
RIAL
AVG
VC05
AVDR
PVPR
RMGR
PLNR
VC04
SAADR
RIBL
PVNL
PLML
URXL
SMBDL
AQR
SABVL
BDUL
PHBR
FLPL
RIAR
PVPL
FLPR
AVDL
RIGR
SAAVL
AVKR
DVC
SABVR
PQR PHBL
ALNL
AS10
VB01
RIGL
RMFR
VD11
VA10
PVT DA07
AS07
AS08
SDQR
SAAVR
DVA VD01
AVBL
DA08 AVL
RIVL
RIBR
SDQL
LUAL
AS09
PVWL
PVNR
SMBDR
PVWR
ALA
SABD
DB05
DB06
PHCR
DA06
ALNR
SIADR
SIBDL
RICL
SIAVL
RMFL
VA06
AS05
VA01
LUAR
VA02
VA11
VD12
SIADL
AS04
PDB
DB07
AVBR
DA01
RID
VB02
PLMR
ALML
PHCL
SMDDR
DA05
AS01
VB10
VB11
VC02
RIVR
DA02
VC03
SIBVL
BDUR
DD01
SMDDL
AS11
SIAVR
AS02
VB03
VA05
VA03
VA04
AVKL
AS03
DB01
SIBDR
PVM
SMDVL
VB07
PVDR
PDA
AS06
DA04
DD06
ADEL
VD04
DB04VC01
DA03
AVM PDEL
DVB
VB05
VD02
AVAL
VB04
AVEL
SIBVR
VD13
VD03
VA07
URXR
DA09
VD08
DB02
VA12
SMDVR
PDER
ADER
AVER
RMHL
VD07 DB03 VD05
PVDL
VD06
ALMR
RMHR
URYVL
AVAR
RIS
DD03
DD02
URBL
VB06
URYVR
PVCL
URYDLURYDR
RICR
RMDR
VD10 VB09 DD04
CEPVR OLQVL
VD09
URBR
OLQDR
PVCR
CEPVL
DD05VB08 VA08
VA09
IL2L RMED
RMDL OLLR
CEPDL
URADL
IL2DL
OLLL OLQDL
PVR
RMDDR IL2R
IL1L
IL2VL
RIPL
RMDDL
URAVL
RMDVR
RMDVL
IL1VL
OLQVR
CEPDR URAVR
URADR
IL2VRIL1DL
RIPR
IL1R
IL1DR
IL1VR
IL2DR
RMEV RMEL

−0.1

AS08
DA07

RMER
PLNR

−0.2
−1

−0.8

−0.6

−0.4

−0.2

0

0.2

0.4

(a) Un-normalized Laplacian, (ϕ2 , ϕ3 )

−0.15
−0.2

−0.15

−0.1

−0.05

0

0.05

0.1

0.15

(b) Normalized Laplacian (ϕ2 , ϕ3 )

Figure 3.1. C. elegans neural network
Using the degree-normalized Laplacian has many aesthetic advantages,
as shown in Figure 1(a) and 1(b). The normalized matrix also has all eigenvalues λj such that 0 ≤ λj ≤ 2.
3.4. Graphing in Eigenfunction Coordinates. We found all eigenvalues,
λk , and their corresponding eigenfunctions, ϕk , for each matrix. Given two
eigenfunctions ϕi and ϕj , (such that i 6= j) we then plotted the ordered
pair (ϕi (n), ϕj (n)) for each n from 1 to 279, as described in [38]. The first
eigenvalue of any Laplacian matrix is always 0, corresponding to a constant
eigenfunction. Thus we only consider ϕi and ϕj with i, j ≥ 2. Edges were
then added between points to represent relevant connections, and the same
color-coding as [25] was used: where red represents sensory neurons, green
are motor neurons, and blue indicates interneurons. The same process was
then repeated in three dimensions, plotting (ϕi (n), ϕj (n), ϕk (n)) for some
i, j, k ≥ 2, such that i 6= j 6= k.
3.5. Clustering Coefficient. The clustering coefficient is a common measure for vertices on a graph. It is typically measured on graphs with unweighted edges. For a graph G and a given vertex v, let ev denote the number
of connections that exist between the neighbors of v. Take dv as the number
of neighbors of v (the degree of vertex v). Then the clustering coefficient of
vertex v, cv , is given by:
2ev
cv =
dv (dv − 1)
Note that total number of possible connections among neighbors of v is
dv (dv −1)
.
2
Therefore, the clustering coefficient is essentially the probability that two
neighbors of v are connected. For a graph G with n vertices, the average

20

D. J. KELLEHER, T. M. REESE, D. T. YOTT, AND A. BRZOSKA

clustering coefficient, c, is defined as:
n

1X
c=
cv
n v=1
3.6. Generating a Related Random Graph for Small-World Analysis.
In order to analyze our networks for small-world properties, it was useful
to compare these graphs to those of similar networks with randomly assigned edges. Small-world networks are nearly as well-connected as random
graphs, but possess a surprisingly well-localized structure. We developed
the following algorithm for this process:
For a graph G with n vertices, let k be the number of edges on G. Therefore the average number of edges per vertex is k/n. Furthermore, the probability that any two random vertices are connected, p, is given by the number
of existing connections divided by the total possible connections:
p=

k
n(n−1)
2

=

2k
n(n − 1)

Next we generate a random graph, Rand(G), with n vertices and a p probability of connection between two vertices (See Methods 3.1). We then compute c and l for G and Rand(G).
G has small-world network properties [33] if:
1. l(G) & l(Rand(G))
and
2. c(G) > > c(Rand(G)) where c(Rand(G)) ≈ p
3.7. The Neighborhood of a Graph. On a graph G with n vertices, the
neighborhood, H(m) where m is a positive integer, is useful in analyzing
small-world networks. A neighborhood of size m around vertex v is the set
of all vertices that can be reached from v in m steps or less. We shall refer
to the number of vertices reachable in m steps or less as Hv (m). To get a
sense of the global neighborhood size on the graph, we can average Hv (m)
over each vertex v in G. This gives us a global H(m) for a given m:
n

H(m) =

1X
Hv (m)
n v=1

It is clear that H(m) is non-decreasing and as long as G is complete, H(m)
achieves its maximum, n, for finite m.

MATHEMATICALLY MODELING THE C. ELEGANS NEURAL NETWORK

21

3.8. Graph Rewiring. The rewiring principle can be rigorously explained
as follows. We first number each vertex in G from 1 to |G| (where n = |G|, n
being the total number of vertices). If there is a connection between vertices
u and v in G, we generate a random number between 0 and 1. If this random
number is less than a given probability p, then the connection will be rewired.
Without loss of generality assume u < v. We then fix the connection to
vertex u, and move the connection to another vertex, k, such that u and k are
now connected whereas they were not previously.
3.9. Graph Energy. For a graph G = (V, E) where V is the set of vertices
and E is the set of edges, one can define an arbitrary scalar function u :
V → R. Consequently, one can then define the energy of u associated with
the graph. The energy of u associated with G, E(u) is defined as:
X
E(u) =
(u(x) − u(y))2 .
x,y∈E

We analyzed the energies of the Laplacian matrix eigenfunctions, thus u =
ϕ.
3.10. Spacial Variance. In order to discuss spacial variance, we must first
define the resistance between two vertices on a graph. Let G = (V, E) be a
graph and x, y ∈ V . Then the resistance between x and y, d(x, y), is given
by:
d(x, y) = E(h(x, y))−1
Where h(x, y) is a harmonic function defined as follows:
Let G = (V, E) be a graph and x, y ∈ V . Then the harmonic function
corresponding to (x, y) is a scalar function h(x, y) : V → R such that:
1. h(x, y)(x) = 0
2. h(x, y)(y) = 1
3. E(h)−1 , where h is an arbitrary scalar function on V, is maximized at h(x, y).
Finding the harmonic function is equivalent to finding a vector h such that
Lh = z, where z is a vector whose entries are all 0 except for those entries
corresponding to x and y. This is analogous to what “harmonic" means in
Euclidean space. This changes the maximization problem in condition 3. to
solving a system of linear equations.
Using these we can now define the spacial variance of a graph. Again, let
G = (V, E) be a graph with n vertices and u be a scalar function on V . Let
γ be a constant. Then the γ th spacial variance of u over G is given by:
1 X
V arγ (u) =
d(x, y)γ (u(x) − u(y))2
n x,y∈E

22

D. J. KELLEHER, T. M. REESE, D. T. YOTT, AND A. BRZOSKA

In this paper, the spacial variances of eigenfunctions of Laplacian matrices
were evaluated at γ = 1 and then analyzed.
Acknowledgements
We thank Dr. Alexander Teplyaev, Department of Mathematics, University of Connecticut, for his guidance in organizing and overseeing our
project. We thank Dr. Dmitri Chklovskii, Howard Hughes Medical Institute, Janiela Farm Research Campus, for allowing us to extend his work and
use his adjacency matrices. We thank Matthew Begué, Department of Mathematics, University of Maryland, for his help with our MATLAB code. We
also thank Lisa Pham, Boston University, for her advice.
Author Contributions
DJK conceived and designed the experiments. TMR performed the experiments, analyzed the data, and wrote the paper sections concerning the
Eigenvalue Counting Function, Weyl Ratios, and the Eigen Projection Method.
DTY performed the experiments, analyzed the data, and wrote the paper sections concerning Small-World properties. AB performed the experiments,
analyzed the data, and wrote the paper sections concerning Graph Energy
and Spacial Variance. TMR wrote the remainder of the manuscript. DJK,
TMR, AB, and DTY carried out revisions of the manuscript.
References
[1] Mandelbrot BB (1967) How long is the coast of Britain? Statistical self-similarity and
fractal dimension. Science 156: 636–638.
[2] Liebovitch LS, Fischbarg J, Koniarek JP, Todorova I, Wang M (1987) Fractal model
of ion-channel kinetics. Biochim Biophys Acta 896: 173–180.
[3] Lowen SB, Liebovitch LS, White JA (1999) Fractal ion-channel behavior generates
fractal firing patterns in neuronal models. Phys Rev E Stat Phys Plasmas Fluids Relat
Interdiscip Topics 59: 5970–5980.
[4] Paramanathan P, Uthayakumar R (2008) Application of fractal theory in analysis of
human electroencephalographic signals. Comput Biol Med 38: 372–378.
[5] Bernard F, Bossu JL, Gaillard S (2001) Identification of living oligodendrocyte developmental stages by fractal analysis of cell morphology. J Neurosci Res 65: 439–445.
[6] Smith TG, Lange GD, Marks WB (1996) Fractal methods and results in cellular
morphology–dimensions, lacunarity and multifractals. J Neurosci Methods 69: 123–
136.
[7] Fernandez E, Jelinek HF (2001) Use of fractal theory in neuroscience: methods, advantages, and potential problems. Instituto de Bioingenier ia 24: 309–321.
[8] Kiselev VG, Hahn KR, Auer DP (2003) Is the brain cortex a fractal? Neuroimage 20:
1765–1774.
[9] Jelinek HF, Fernández E (1998) Neurons and fractals: how reliable and useful are
calculations of fractal dimensions? J Neurosci Methods 81: 9–18.

MATHEMATICALLY MODELING THE C. ELEGANS NEURAL NETWORK

23

[10] Werner G (2010) Fractals in the nervous system: conceptual implications for theoretical neuroscience. Front Physiol 1: 15.
[11] Murray J (1995) Use and Abuse of Fractal Theory in Neuroscience. The Journal of
Comparative Neurology 361: 369–371.
[12] Smith TG, Behar TN (1994) Comparative fractal analysis of cultured glia derived
from optic nerve and brain demonstrate different rates of morphological differentiation. Brain Res 634: 181–190.
[13] Smith TG, Behar TN, Lange GD, Marks WB, Sheriff WH (1991) A fractal analysis of
cultured rat optic nerve glial growth and differentiation. Neuroscience 41: 159–166.
[14] Reichenbach A, Siegel A, Senitz D, Smith TG (1992) A comparative fractal analysis
of various mammalian astroglial cell types. Neuroimage 1: 69–77.
[15] Caserta F, Stanley HE, Eldred WD, Daccord G, Hausman RE, et al. (1990) Physical
mechanisms underlying neurite outgrowth: A quantitative analysis of neuronal shape.
Phys Rev Lett 64: 95–98.
[16] Bieberich E (2002) Recurrent fractal neural networks: a strategy for the exchange of
local and global information processing in the brain. BioSystems 66: 145–164.
[17] Sporns O (2006) Small-world connectivity, motif composition, and complexity of
fractal neuronal connections. BioSystems 85: 55–64.
[18] Free SL, Sisodiya SM, Cook MJ, Fish DR, Shorvon SD (1996) Three-dimensional
fractal analysis of the white matter surface from magnetic resonance images of the
human brain. Cereb Cortex 6: 830–836.
[19] Bullmore E, Sporns O (2009) Complex brain networks: graph theoretical analysis of
structural and functional systems. Nat Rev Neurosci 10: 186–198.
[20] Stam CJ, Reijneveld JC (2007) Graph theoretical analysis of complex networks in the
brain. Nonlinear Biomed Phys 1: 3.
[21] Fallani FV, Costa LF, Rodriguez FA, Astolfi L, Vecchiato G, et al. (2010) A graphtheoretical approach in brain functional networks. Possible implications in EEG studies. Nonlinear Biomed Phys 4 Suppl 1: S8.
[22] Sporns O, Kotter R (2004) Motifs in brain networks. PLoS Biol 2: 1910-1918.
[23] Itzkovitz S, Alon U (2005) Subgraphs and network motifs in geometric networks. Phys
Rev E Stat Nonlin Soft Matter Phys 71: 026117.
[24] Morita S, Oshio Ki, Osana Y, Funabashi Y, Oka K, et al. (2001) Geometrical structure
of the neuronal network of Caenorhabditis elegans. Physica A 298: 553–561.
[25] Varshney LR, Chen BL, Paniagua E, Hall DH, Chklovskii DB (2011) Structural
Properties of the Caenorhabditis elegans Neuronal Network. PLoS Comput Bio 7 7:
e1001066.
[26] Das KC (2004) The Laplacian spectrum of a graph. Comput Math Appl 48: 715–724.
[27] Zhou D (2008) Spectral analysis of Laplacians on certain fractals. ProQuest
LLC, Ann Arbor, MI, 109 pp. URL http://gateway.proquest.com/
openurl?url_ver=Z39.88-2004&rft_val_fmt=info:ofi/fmt:kev:mtx:
dissertation&res_dat=xri:pqdiss&rft_dat=xri:pqdiss:NR43396. Thesis
(Ph.D.)–University of Waterloo (Canada).
[28] Berry T, Heilman SM, Strichartz RS (2009) Outer approximation of the spectrum of
a fractal Laplacian. Experiment Math 18: 449–480.
[29] Koren Y (2005) Drawing graphs by eigenvectors: theory and practice. Comput Math
Appl 49: 1867–1888.

24

D. J. KELLEHER, T. M. REESE, D. T. YOTT, AND A. BRZOSKA

[30] Mohar B (1991) The Laplacian spectrum of graphs. In: Graph theory, combinatorics,
and applications. Vol. 2 (Kalamazoo, MI, 1988), New York: Wiley, Wiley-Intersci.
Publ. pp. 871–898.
[31] Pisanki T, Shawe-Taylor J (2000) Characterizing Graph Drawing with Eigenvectors. J
Chem Inf Comput Sci 40: 567–571.
[32] Varshney L, Chen B, Paniagua E, Hall D, Chklovskii D (2011) Structural properties
of the Caenorhabditis elegans neuronal network. http://mitedu/lrv/www/elegans/ .
[33] Bassett DS, Meyer-Lindenberg A, Achard S, Duke T, Bullmore E (2006) Adaptive
reconfiguration of fractal small-world human brain functional networks. Proc Natl
Acad Sci USA 103: 19518–19523.
[34] Sporns O, Honey CJ (2006) Small worlds inside big brains. Proc Natl Acad Sci 103:
19219–19220.
[35] Watts DJ, Stogartz SH (1998) Collective dynamics of ’small-world’ networks. Nature
393: 440–442.
[36] Csányi G, Szendrői B (2004) Fractal-small-world dichotomy in real-world networks.
Phys Rev E Stat Nonlin Soft Matter Phys 70: 016122.
[37] Okoudjou KA, Saloff-Coste L, Teplyaev A (2008) Weak uncertainty principle for fractals, graphs and metric measure spaces. Trans Amer Math Soc 360: 3857–3873.
[38] Begue M, Kelleher DJ, Nelson A, Panzo H, Pellico R, et al. (2011) Random walks on
barycentric subdivisions and the Strichartz hexacarpet. ArXiv e-prints .
(D. J. Kelleher) Department of Mathematics, University of Connecticut, Storrs,
CT 06269, USA
E-mail address, D. J. Kelleher: kelleher@math.uconn.edu
URL: http://www.math.uconn.edu/~kelleher/
(T. M. Reese) Department of Mathematics, University of Connecticut, Storrs,
CT 06269, USA
E-mail address, T. M. Reese: tyler.reese@uconn.edu
(D. T. Yott) Department of Mathematics, Boston University, Boston, MA, 02135,
USA
E-mail address, D. T. Yott: dyott@bu.edu
(A. Brzoska) Department of Mathematics, University of Connecticut, Storrs,
CT 06269, USA
E-mail address, A. Brzoska: antoni.brzoska@uconn.edu

