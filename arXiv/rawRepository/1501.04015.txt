Optimizing information flow in small genetic networks.
IV. Spatial coupling
Thomas R. Sokolowski∗ and Gašper Tkačik†

arXiv:1501.04015v1 [q-bio.MN] 16 Jan 2015

Institute of Science and Technology Austria, Am Campus 1, A-3400 Klosterneuburg, Austria
We typically think of cells as responding to external signals independently by regulating their
gene expression levels, yet they often locally exchange information and coordinate. Can such spatial
coupling be of benefit for conveying signals subject to gene regulatory noise? Here we extend our
information-theoretic framework for gene regulation to spatially extended systems. As an example,
we consider a lattice of nuclei responding to a concentration field of a transcriptional regulator
(the “input”) by expressing a single diffusible target gene. When input concentrations are low,
diffusive coupling markedly improves information transmission; optimal gene activation functions
also systematically change. A qualitatively new regulatory strategy emerges where individual cells
respond to the input in a nearly step-like fashion that is subsequently averaged out by strong
diffusion. While motivated by early patterning events in the Drosophila embryo, our framework is
generically applicable to spatially coupled stochastic gene expression models.

I.

INTRODUCTION

Signals encoded by spatial or temporal concentration
profiles of certain proteins play a crucial role in communicating information within and between cells. Such signals are established and read out by a vast variety of gene
regulatory networks. In this process, however, information flow is limited by the randomness associated with
gene regulatory interactions—essentially chemical reactions between different species of signaling molecules and
DNA—taking place at very low copy numbers [1]. While
we increasingly understand distinct strategies of noise
control in biological systems [2–6], it remains largely unclear how nature orchestrates these strategies to maximize information flow.
A recent proposal takes the idea of “information flow”
in biological networks seriously, as formalized by Shannon’s information theory, and hypothesizes that at least
some of the structure of genetic regulatory networks
could be derived mathematically, by maximizing information transmission that such networks can sustain subject to biophysically realistic constraints [7]. The feasibility of information as the metric of network performance was recently established by demonstrating that
morphogen patterns in early fly development transmit
information with an accuracy close to the physical limits
[8, 9]. Theoretically, this optimization principle was applied to study information flow in different paradigmatic
gene-regulatory scenarios, including single and multiple
target genes regulated by a single input [10–12], feedforward cross-regulation [12], autoactivation [13], multistate promotor-switching [14], and time-dependent inputs [15–19]. These attempts yielded important insights
into optimal strategies with which single cells can reliably respond to external stimuli. The issue that to-date
has not received attention, however, is that many cells or

∗
†

thomas.sokolowski@ist.ac.at
gasper.tkacik@ist.ac.at

nuclei can respond to a spatially distributed signal collectively, by exchanging information among themselves,
e.g., via diffusion of signaling proteins. Prominent examples are the specification of emerging body tissues during
embryo development [20–25], the aggregation response in
colonies of amoebae [26, 27], and collective chemosensing
in cell colonies and tissues [28, 29]. Importantly, spatial aspects not only add another layer of complexity
to the distributions of input and output signals of generegulatory networks; they can also markedly alter noise
levels—and thus information capacity—through spatial
averaging [30–35]. A truly predictive theoretical framework therefore must take into account the spatial setting, where multiple regulatory networks can read out
the inputs at various locations and exchange information
between themselves locally.
Here we extend the existing theory of optimal gene
regulatory networks to such a spatial setting. We construct a spatial-stochastic model of gene regulation that
takes into account diffusive coupling between neighboring reaction volumes and the relevant sources of noise.
We derive simple expressions for the stationary means
and variances of input-activated local protein levels as
a function of their regulatory parameters and diffusion
rate. From this we compute information transmission in
various spatial scenarios and systematically explore how
transmission can be optimized by changing key system
parameters. As a motivating example, we study a model
variant representative of the bicoid-hunchback system in
early fruit fly embryogenesis, which enables differentiating cells to acquire position-dependent fates with high
reliability and reproducibility in spite of stochasticity in
the underlying biophysical processes [32, 36–42]. Our approach thus specifically optimizes positional information,
a notion that has been extensively discussed throughout
developmental biology [43–47], but only recently rigorously formalized in mathematical terms, using information theory [48]; the proposed formalism, however, generalizes to other spatially coupled gene regulatory setups.

2

II.

Spatial-stochastic model of gene regulation

Figure 1 shows a schematic of the spatially coupled
gene regulation model that we study throughout this paper. We consider a two-dimensional lattice of Nx × Ny
reaction volumes with equal spacing δ between the volumes. In this work, we particularly focus on a cylindrical
geometry of the lattice, with periodic boundary conditions along the circumference (y-direction), and reflective
boundary conditions in axial (x-) direction. While this
geometry deliberately mimics the syncytial state of the
developing embryo of the fruit fly Drosophila, our model
could be easily adapted to any arbitrary discrete arrange-

f(c)
c
λ0
x

δ

METHODS

Here we construct a model in which we can analytically calculate how much information expression levels
of diffusible proteins encode locally about the position
itself, if these proteins are expressed in response to a
concentration field of regulatory input molecules. The
outline of our approach is as follows. We (i) define a
generic spatial-stochastic model of gene regulation that
explicitly accounts for diffusive signaling between adjacent volumes which collectively interpret a spatially distributed input signal (Section II A). Starting from a set
of coupled Langevin equations, in Section II B we (ii) derive general analytic expressions for the stationary means
and variances of the regulated protein levels, and provide
intuitive insight for the role of diffusion prior to specifying any gene regulatory details. We then (iii) impose
realistic expressions for the gene regulatory function and
noise, based on well-established biochemical models (Section II C). Section II D illustrates how we (iv) quantify
the encoding of positional information, using information
theory and the stationary moments derived in (ii). Finally, we vary the parameters of the model to find the optimal regulatory strategies in the spatially coupled setup,
which we present in the “Results” Section III.

A.

G
Protein level

We find that spatial coupling can markedly improve
information transmission when the dominant source of
noise in gene regulation is on the “input side,” e.g., due
to the random arrival of the regulatory molecules (transcription factors) to their binding sites on the DNA. This
is in accordance with the known fact that spatial averaging can remove super-Poissonian contributions to the
noise [30, 31]. Moreover, with diffusion the maximal information capacity reached upon optimization becomes
increasingly invariant to the spatial details of the input
signal. Finally, in a defined noise regime that we detail
below, we observe the emergence of a novel optimal regulatory strategy where diffusion generates graded, and
thus informative, spatial profiles of regulated genes despite their sharp, threshold-like activation by the regulatory inputs.

Gi

ci

ri

K

τ -1

h

Ø

FIG. 1. Model schematic. The spatial-stochastic model of
gene regulation consists of a discrete set of identical reaction
volumes (indicated by i) arranged in a regular lattice with
lattice spacing δ. While here for clarity we only draw a 1D
lattice, we also study a 2D model with periodic boundary conditions, and our framework supports arbitrary coordination
numbers. The volumes collectively sense a spatial signal c(x)
which maps the position x to an input concentration c (red),
creating a spatial distribution of output proteins G (blue).
Each volume contains an identical promotor activated with
probability f (ci ), where f (c) is the regulatory function and
ci the activator concentration in volume i. This results in a
local production rate ri = rmax f (ci ) and local levels Gi of the
product protein. G proteins are degraded with a rate 1/τ and
can hop to the neighboring volumes with a rate h = D/δ 2 ,
where D is their diffusion coefficient. The regulatory function
f (c) is characterized by the activation threshold K and the
regulatory cooperativity H, as detailed in Section II C.

ment of equally spaced reaction volumes. We will initially
consider the special case Ny = 1 as the “1D model,” while
referring to the case Ny > 1 as the “2D model.”
Each volume contains the promotor of an identical gene
controlled by a single transcription factor, whose concentration we denote by c. The copy number of proteins
expressed from this gene of interest will be denoted by

3
G, while g = G/Nmax will refer to the copy number normalized by the maximal average expression level Nmax
at full induction. At the core of our model is the regulatory function f (c) which determines how the activator
concentration c maps to the effective synthesis rate of
G proteins. We will also refer to c as the “input,” and
to G and g as the “output.” For simplicity we treat
transcription and translation as a single production step
with maximal production rate rmax reached at full activation. G molecules are degraded with a constant rate 1/τ ,
where τ is the average protein lifetime. In addition, each
volume can exchange the product molecules G with its
neighboring volumes via diffusion. Here, we approximate
this exchange with an effective “hopping rate” h = D/δ 2 ,
where D is the diffusion coefficient of G molecules.
Denoting the position of volume i by xi , we can write
down a stochastic equation for the combined productiondegradation-diffusion process in volume i as follows:
1
∂t Gi = rmax f (c(xi )) − Gi
τ
X
D X
(Gi − Gn ) +
Γik ηk
− 2
δ
n∈N (i)

(1)

k

Here Gi denotes the number of G proteins in the volume, while the first and second term in the equation
describe their production and degradation, respectively.
The third term is a discretized Laplacian accounting for
the diffusive exchange of G molecules between volume
i and its nearest-neighbor volumes n ∈ N (i). Function
c(x) maps positions xi to local transcription factor concentrations ci . In this work we consider the case in which
c(x) is invariant in y-direction, i.e. ci ≡ c(xi ) = c(x(i));
we specify the functional form
P of c(x) at the end of this
section. The noise term
k Γik ηk comprises all noise
sources ηk that act on the protein level Gi , including
those outside of volume i. We assume that all fluctuations are well represented by non-multiplicative, zeromean Gaussian white noise, and compute the relevant
noise powers Γik below.

B.

Means and variances with spatial coupling

The set of coupled Langevin equations [Eq. (1)] is a
special case of what is known as the “N-unit generalized
Langevin model” [49, 50] in other contexts. To compute
the steady-state means and variances we employ a technique based on Itō calculus which allows to convert the
set of coupled stochastic equations for the variables Gi
into a set of ODEs for their moments that hold exactly.
This can be performed for an arbitrary discrete coupling
network, and even for the case of multiplicative noise (not
considered here) [49–51].
We can write down the equations of motion for the
mean of the normalized local output gi = Gi /Nmax and
the (co)variances of its fluctuations δgi ≡ gi − hgi i as

follows [49–51]:
X 


gi − gni

∂t hgi i = hF (gi , ci )i − h

(2)

ni ∈N (i)

∂t hδgi δgj i = hδgi F (gj , cj )i + hδgj F (gi , ci )i
*
+
X
+ h δgi
(gnj − gj )
nj ∈N (j)

*

+
X

+ h δgj

(gni − gi )

ni ∈N (i)

+

X

hΓik Γjk i

(3)

k

Here the function F (gi , ci ) = τ1 (f (ci ) − gi ) groups the
production and degradation terms and depends on the
regulatory function f (c). The ni - and nj -sums run over
the nearest-neighbor volumes of i and j, respectively.
Note that in the k-sum running over all noise sources
in the system usually most terms will be zero.
The hitherto arbitrary noise powers Γik can be written
out more explicitly by listing all noise sources that affect
volume i in the following way:
X
Γik ηk =Gi (ci , g)γi
k

−

X

D(i→n) ξ(i→n) +

n∈N (i)

X

D(n→i) ξ(n→i)

n∈N (i)

(4)
Herein γi is the noise in the combined process of random regulation, production and degradation, and ξ(i→j)
the noise caused by random hopping from volume i to
j. A crucial step in specifying the expression above is to
write the noise powers of the incoming and outgoing hopping processes with different signs, because each hopping
event causing a negative fluctuation in the volume of origin always causes a positive fluctuation in the volume of
arrival. The hopping thus is a birth process when seen
from the volume of arrival, and a death process when seen
from the volume of origin. This intuitive argument can
be derived more rigorously from the Langevin equation
following the method portrayed by Gillespie [52], and is
quantitatively confirmed by stochastic simulations, employing (e.g.) the next-subvolume method [53, 54].
PUsing Eq. (4) we can rewrite the noise term
k hΓik Γjk i in Eq. (3) for the variances (case i = j) and
nearest-neighbor covariances (case i ∈ N (j)) as follows:
X
X
2
2
hΓik Γjk i = hGi2 (c, g)i +
hD(i→n)
+ D(n→i)
i
k

n∈N (i)

≡
X
k

Nii2

for i = j

(5)

hΓik Γjk i = hΓiκ Γjκ i + hΓiκ0 Γjκ0 i
| {z }
| {z }
hopping (i→j)

=
≡

2
−hD(i→j)
i
2
Nij

hopping (j→i)

2
− hD(j→i)
i

for i ∈ N (j) (6)

4
To obtain the stationary means and covariances of the
protein number gi , we solved Eqs. (2) and (3) in steady
state by setting their left sides to zero (∂t h..i = 0). After substituting gi = hgi i + δgi , we regroup covariances
hδgi δgj i and means hgi i and relate them to the respective
quantities in the neighboring volumes (see Appendix A).
In this context, we introduce the pragmatic assumption that only concentrations in volumes that are nearest
neighbors on the lattice have significant correlations, i.e.,
we enforce
hδgi δgj i = 0

for j ∈
/ N (i)

(7)

While this “short correlations assumption” markedly facilitates both analytical progress and computation speed,
and yields formulas that are intuitive to interpret, our
results only change marginally when the assumption is
released (see Section III D). For brevity, in the following
we write
σi2 ≡ hδgi2 i,

ḡi ≡ hgi i,

Cij ≡ hδgi δgj i

(8)

for the steady-state means, variances and covariances,
respectively. Treating the cases i = j and i ∈ N (j)
in Eq. (3) separately, we arrive at the following set of
coupled equations for these quantities (cf. Appendix A):


X
τ
ri + h
ḡi =
ḡni 
1 + 2d∆
ni ∈N (i)
X
2
≡ T ri + Λ
ḡni
(9)
ni ∈N (i)

σi2 = Λ2

X
ni ∈N (i)

Cij =

Cini +

T 2
N
2 ii

 T
Λ2 2
σi + σj2 + Nij2
2
2

(10)

(11)

Here we abbreviate normalized production rate ri =
f (ci )/τ ; d is the lattice dimension, or half of the coordination number of a reaction volume. We introduce the
dimensionless diffusion constant ∆ ≡ D/D0 , which is
equal to the diffusion constant measured in the “natural” unit D0 = δ 2 /τ ; note that ∆ = hτ . We will also
refer to ∆ as the “spatial coupling.”
The above equations define two “effective parameters”:
(i), an “effective residence time” T = τ /(1 + 2d∆), reflecting the fact that with diffusion proteins are taken
out from the reaction volume faster than through regular degradation in the absence of diffusion; and
(ii),
√
+
the
(dimensionless)
“mixing parameter” Λ =
hT =
p
√
+
DT /δ =
∆/(1 + 2d∆), which equals the distance
travelled via diffusion during the time T , measured in
units of the lattice spacing δ. These quantities capture the essential effect of diffusive coupling between
the stochastic processes in neighboring reaction volumes:
With increasing coupling (∆ > 0 ⇒ Λ2 > 0), the mean
output level ḡi is increasingly set by the mean levels in
the neighboring volumes ḡni , whereas the contribution of

the local production to the apparent copy number in the
volume is reduced (T < τ ). An analogous interpretation
holds for σi2 if 12 Nii2 is interpreted as a “noise production”
term.
We verified that Eqs. (9), (10) and (11) correctly reproduce the known result that all super-Poissonian noise
is attenuated in the “Poissonian limit,” meaning that (in
non-normalized units) the variance becomes equal to the
mean for inifinitely strong coupling ∆ → ∞ [30, 31]. This
holds both in 1D and 2D, and with or without shortcorrelations assumption.
Equations (9), (10) and (11) can be solved for the variables ḡi , σi2 and Cij after specifying the detailed forms
of the regulatory function and noise strength and imposing meaningful boundary conditions. If the regulatory
function and noise do not contain terms nonlinear in the
variables of interest, Eqs. (9), (10) and (11) form a set
of coupled linear equations that can be solved by simple
matrix inversion. Also notice that we may use Eq. (11)
to simplify Eq. (10) further if we are only interested in
solving for the variances σi2 (as in this work); we show
the respective formulas for the 1D and 2D model in Appendix B.

C.

Regulatory function and gene expression noise

To describe the probability of the promotor being in its
active state given that the concentration of the transcription factor is c, we choose a simple Hill-type regulation
model:
f (c) =

cH

cH
,
+ KH

(12)

where H is the Hill coefficient, quantifying the cooperativity of the activation process, and K the activation
threshold, i.e. the concentration at which half-activation
occurs, f (K) = 1/2.
To complete our analytical model we need to accu2
rately specify the noise powers hGi2 i and hD(i→j)
i appear2
2
ing in the noise terms Nii and Nij . In steady state, all
of these noise powers only depend on the mean levels of
the transcription factor ({ci }) and product ({ḡi }).
Let us first specify the power of the regulation/production/degradation noise, hGi2 i, which has two
contributions: super-Poissonian “input noise” hGT2 F,i i
originating from random arrival of regulatory transcription factors, and Poissonian “output noise” hGP2 D,i i from
the production and degradation of the gene product. The
input noise is a function of the transcription factor concentration and is well-approximated by [11, 55, 56]
"
#

2
∂f (c)
2c
2
2
hGT F,i i = rmax
(13)
∂c
Dc lc
c=ci

where Dc is the diffusion coefficient of the transcription
factors, lc the typical size of a transcription factor binding

5
site and ci the local activator concentration. The above
formula describes fluctuations of Gi in absolute units;
to obtain the noise power hĜT F,i i of fluctuations in the
normalized output gi , hGT2 F,i i has to be normalized as
2
well by Nmax
= (rmax τ )2 :
"
#
2
2
hG
i
1
∂f
(c)
2cN
max
T
F,i
=
hĜT2 F,i i =
2
Nmax
Nmax τ
∂c
Dc lc τ
c=ci
"
#
2
1
∂f (c)
=
2cc0
(14)
Nmax τ
∂c
c=ci

In the last step, c0 ≡ Nmax /(Dc lc τ ) defines a typical
concentration scale for our problem; in the following we
will measure concentrations in units of c0 .
The output noise in absolute units can be written as
the sum of production and degradation rate, as for a
regular birth/death process:
1
hGi i
(15)
τ
Note that in general hGi i 6= rmax f (ci )τ due to the diffusive coupling. Also note that bursty production (not
considered in this work) could be easily incorporated into
the model via a prefactor φ (Fano factor) in the production term: rmax f (ci ) → φrmax f (ci ). In normalized units
the production/degradation noise reads:
hGP2 D,i i = rmax f (ci ) +

hĜP2 D,i i =

hGP2 D,i i
1
=
(f (ci ) + ḡi )
2
Nmax
Nmax τ

(16)

In our model, diffusive hopping of a molecule is identical with its degradation in the volume of origin and
simultaneous production of a molecule in the volume of
2
arrival. The corresponding noise powers D(i→j)
thus are
given by the rate of particle loss through diffusive hopping from the volume of origin, which in steady state is
given by the mean copy number in that volume times the
hopping rate, and can be normalized in the same way as
the other noise powers:
2
hD(i→j)
i=

D
hGi i,
δ2

2
hD̂(i→j)
i=

2
hD(i→j)
i
2
Nmax

=

∆
ḡi
Nmax τ
(17)

Adding up all contributions, we obtain for the (normalized) combined noise powers Nij2 and Nii2 :
Nij2

2
−hD(i→j)
i

(ḡi + ḡj ) (18)
=−
Nmax τ
X
2
2
Nii2 = hGP2 D,i i + hGT2 F,i i +
hD(i→n)
+ D(n→i)
i
=

−

∆

2
hD(j→i)
i

n∈N (i)


=

1
Nmax τ

"

f (ci ) + ḡi +

∂f (c)
∂c

#

2
2cc0

X
n∈N (i)

(ḡi + ḡn ) 

Quantifying positional information

Building on our previous work [8, 10–13], we quantify
the amount of information that the noisy output signal
g(x) carries about the position x using the mutual information I(x; g) between the input and output [57, 58], a
central quantity of Shannon’s information theory [57]:


Z
Z
P (g|x)
I(x; g) = dx Px (x) dg P (g|x) log2
(20)
Pg (g)
In the information-theoretic picture introduced here, the
information channel is defined by a set of sampling units
(cells or nuclei at a particular position) that implement
the same gene regulatory network. These sampling units
read out the input signal c with a distribution that is
jointly determined by the shape of the concentration
field, c(x), and the spatial distribution of the sampling
units, Px (x). In response to these inputs, the regulatory
networks locally express the output gene g at the corresponding level, producing an output distribution Pg (g)
across the ensemble of sampling units.
The mutual information can be rewritten as a difference between
R the entropy of the output distribution
S[Pg (g)] = − dg Pg (g) log2 Pg (g) and the average entropy of the conditional distribution of g at fixed position
x:
Z
I(x; g) = S[Pg (g)] − dx Px (x)S[P (g|x)]
(21)
When only the local distribution of outputs P (g|x) is
known, Pg (g) can be straightforwardly constructed from
P (g|x) and Px (x):
Z
Pg (g) = dx Px (x)P (g|x)
(22)
In our discrete model we assume uniform spacing of the
sampling positions xi ∈ [0, Nx δ], i.e. Px (xi ) = 1/Nx .
Equations (21) and (22) then respectively become:
Z
I(x; g) = − dg Pg (g) log2 Pg (g)
+

Pg (g) =

Nx Z
1 X
dg P (g|xi ) log2 P (g|xi )
Nx i=1

Nx
1 X
P (g|xi )
Nx i=1

(19)

(23)

(24)

I(x; g) is therefore fully characterized by the conditional
output distribution P (g|xi ). Since here we only consider
non-multiplicative white noise, P (g|xi ) is Gaussian:
!
2
1
(g − ḡ(xi ))
P (g|xi ) = q
exp −
(25)
2σg2 (xi )
2πσ 2 (x )
g

c=ci


+∆

D.

i

The information I(x; g) is therefore fully determined by
the (local) means and variances of the conditional distributions P (g|xi ).

6
In our previous work [8, 10–13], we have computed the
maximum achievable information transmission (channel
capacity) by optimizing over the distribution of input signals, relying on the “small noise approximation” to make
the problem analytically tractable. Here, in contrast, the
spatial setting has led us to choose a uniform distribution
of sampling points, Px (x). While this relieves us of the
need to use the small noise approximation, to fully specify the problem we still need to select the function c(x)
that maps the input of the regulatory network to spatial positions. Motivated by the developmental example
of the fruit fly, here we choose an exponential function
[36, 37]:
c(x) = cmax e−x/(λγ0 ) ,

(26)

where cmax controls the maximum achievable input, γ0 ≡
L/5 ≡ Nx δ/5 is the decay length of a typical exponential morphogen gradient relative to the system size L
[36, 37, 59], and λ a variable dimensionless scaling factor (the precise value of γ0 is insignificant; we could opt
for any convenient length unit). This choice generates
a family of input profiles parametrized by cmax and λ,
and we will explore various settings for these parameters
to maximize the positional information encoded by the
expression level g.
We can now assemble the different components of the
model. By inserting the regulation and noise terms
[Eqs. (12), (18) and (19)] into the steady-state solutions
of the coupled stochastic equations [Eqs. (9), (10), (11)]
we obtain two coupled linear equation systems for mean
expression levels ḡi and (co)variances Cij and σi2 which
we can solve given the selected boundary conditions. Using Eq. (23) we can then compute the mutual information
I(x; g). When computing the stochastic moments, we can
vary the parameters of the input function, the regulation
and the spatial coupling, and thus compute I(x; g) as
a function of its key determinants. The baseline set of
parameters that we used for numerical computation is
presented in Appendix D.
III.

RESULTS

In order to elucidate how spatial coupling alters the
capacity of encoding positional information in the downstream gene g, we optimized the mutual information
I(x; g) over the parameters of our model: the dissociation constant, K, and the Hill coefficient of regulation,
H; the (normalized) diffusion constant of the gene product, ∆; and the length scale of the input gradient, λ. As is
known from previous work, the key parameter that qualitatively determines the shape of the optimal solutions is
the ratio of the output to input noise, which is set by a dimensionless maximal input concentration, C = cmax /c0
[11]; in general, C  1 is the regime of dominant output
noise, while C  1 is the regime of dominant input noise,
as defined in Section II C. We thus explored the optimal
solutions as a function of C in what follows.

For computational efficiency we initially studied the
1D model with short-correlations assumption (SCA), and
later compared to the 2D models with and without SCA,
finding only minor differences (see Section III D).

A.

Spatial coupling can enhance information
transmission

We first assessed how introducing diffusive coupling
changes the information capacity of the system in the
space of regulatory parameters K and H. To establish
the baseline for comparison, we started with the case
without spatial coupling, ∆ ' 0, fixing C = 1 and input
gradient length λ = 1. Figure 2A shows the “information
plane” for this case, i.e., the mutual information I(x; g)
as a function of the Hill coefficient H and the activation threshold K. Consistently with our previous studies
[10, 11], the information plane displays a clear optimal
choice of H and K that maximizes information transmission. The optimum results from a nontrivial compromise
between evenly spreading the whole dynamic range of the
output signal along the x-axis, which ideally requires low
Hill coefficients and half-activation at the system center
(x = L/2, K = c(L/2)), and a system-wide minimization
of the noise; the latter generally favors activation at high
input concentrations (to avoid large fluctuations at low
c) and thus higher K.
Figures 2B and 2C show the same information plane,
but now at increasing values for the spatial coupling ∆.
The first observation is that with nonzero ∆ information
can be increased relative to the baseline at the optimal
choice of H and K, but that the information drops again
when the diffusive coupling is too strong, indicating that
there exists a nontrivial optimal value for ∆ that maximizes information. The second observation relates to the
concomitant change in the optimal parameters {K ∗ , H ∗ }
as the diffusive coupling is increased. In particular, increasing the diffusion constant shifts the optimum towards higher H and lower K. The third observation
is that strong diffusion also increases the capacity away
from the optimum in the regime of high H, creating a
flat plateau where the precise value of H is not crucial
for attaining high information transmission.
All these observations can be understood intuitively:
The increase in capacity for nonzero diffusion is due to
the trade-off between the ability of diffusive spatial averaging to reduce noise (thus increasing the transmission),
and smoothing out the response profile (thus decreasing
the transmission) [30, 31]. The shift in optimal regulatory parameters is a direct consequence of these two
effects: the detrimental effect of smoothing out the response profile can be partially compensated for by choosing higher optimal Hill coefficients, while noise reduction
allows the optimal K to move towards lower concentrations to better utilize the dynamic range. The plateau
in information at high diffusion results from the ability of the diffusion to flatten sharp, nearly step-like gene

7

A

B

Δ≃0

C

Δ = 10

[bits]

Δ ≃ 316

2.2

3.0
2.5

0.42
K/c0

2.0
7.9·10-2

1.5
1.0

1.5·10-2
3.1·10

0.5

-3

0.10

0.45

2.15
H

10.37

50.00

0.10

0.45

2.15
H

10.37

50.00

0.10

0.45

2.15
H

10.37

50.00

0.0

FIG. 2. Information planes for different values of the spatial coupling, ∆. Shown is the mutual information I(x; g)
as a function of the Hill coefficient H and the activation threshold K, (A) with negligible spatial coupling, ∆ ' 0; (B) with
intermediate spatial coupling, ∆ = 10; and (C) with very strong spatial coupling, ∆ ' 316. The data shown is for the 1D
model with short-correlations assumption.

activation profiles at high H (limited to at most 1 bit
of positional information for H → ∞ and ∆ → 0) into
smooth spatial gradients that can convey more positional
information.

B.

Spatial coupling is most beneficial when input
noise is dominant

After understanding the optimal behavior of information as a function of regulatory parameters H, K at fixed
C = 1, λ = 1, and ∆, we systematically varied the diffusive coupling ∆ and the input gradient length scale
λ for several different values of C. For each choice of
(∆, λ) parameters, we separately mapped out the information as a function of H and K to find the optimal
values (H ∗ , K ∗ ) and the corresponding maximal information transmission.
Figure 3 summarizes this exploration and shows the
information capacity as a function of ∆ and λ for a series
of 6 different C values. White stars mark the maximal
capacity for the given C, i.e., the capacity for jointly
optimal choice of H, K, ∆ and λ.
The panel for C = 1 demonstrates two beneficial effects of diffusion on information capacity: increasing ∆
from very low values to ∆ . 100 increases I(x; g) and
simultaneously enlarges the range of λ over which high
capacity can be reached. This effect is even more pronounced when C < 1: at very low C the beneficial values for the diffusion constant ∆ are strongly constrained
to a narrow interval, and the resulting capacity gain at
optimal ∆ with respect to low ∆ increases markedly. In
contrast, when C is high, diffusive coupling does not convey a large benefit in information transmission. This is
due to the fact that diffusion can only remove superPoissonian parts of the noise [30, 31]. In our model,
super-Poissoninan noise is the input noise, which plays

a minor role for C  1, thereby limiting the potential
role of diffusion. We note that super-Poissonian fluctuations could also occur on the output side (e.g., when
gene expression is bursty and multiple protein copies are
produced from each mRNA), in which case diffusive coupling could be beneficial even for C  1. As expected,
for all C, the information capacity drops to zero at very
high ∆ independently of all other parameters, because in
that limit all output profiles become flat and thus uninformative.

We systematically explored how diffusion affects the
optimal information transmission as a function of C in
Fig. 4, by comparing the optimally coupled spatial model
to a model where diffusion is set to zero. Because the information transmission is largely invariant to λ and for
most values of C peaks in a very broad plateau at λ = 1,
we fixed λ = 1 for this comparison, while optimizing over
all other parameters (separately for the spatially coupled
system and the system with ∆ ' 0). Clearly, in the lowC regime optimal diffusive coupling can enhance information capacity by more than a bit, while for C & 100 the
noise composition is strongly dominated by Poissonian
output noise such that diffusion cannot further improve
information throughput.

Instead of varying C by changing the maximal input
concentration cmax , we also varied C via Nmax , thus altering output noise at constant levels of input noise. In
that case we observe the same behavior, i.e. significant
capacity enhancement by diffusion in the low-C regime,
with the small difference that now the capacity increases
with decreasing C ∼ 1/Nmax , as presented in more detail
in Appendix E.

8

8

[bits]
3.5

4

3.0

C = 100

C = 10

C=1

2.5

λ

2
3.2

1

2.0
3.1

1/2

1.5

3.1

1.0

1/4
1/8

0.5
−3

10

−2

10

−1

10

0

1

10

10

2

10

3

10

4

10

−3

10

−2

10

−1

10

0

1

10

10

2

10

3

10

4

10

−3

10

−2

10

−1

10

0

1

10

10

Δ

Δ

Δ

C = 0.1

C = 0.01

C = 0.001

2

10

3

10

4

10

8

[bits]
3.5

4

3.0
2.5

2
λ

0.0

2.0

1
2.9

1/2

2.7

1.5

2.6

1.0

1/4
1/8

0.5
−3

10

−2

10

−1

10

0

1

10

10

2

10

3

10

4

10

−3

10

−2

10

−1

10

0

1

10

Δ

10
Δ

2

10

3

10

4

10

−3

10

−2

10

−1

10

0

1

10

10

2

10

3

10

4

10

0.0

Δ

FIG. 3. Information transmission as a function of the spatial coupling ∆ and the input gradient length λ for
various values of maximal input concentration, C. For comparison, the same scale is used for all contour maps. White
stars mark the overall maximum of I(x; g) in each respective panel; white boxes show the corresponding optimal amount of
transmitted information (in bits). Each datapoint was obtained by optimizing I(x; g) over the regulatory parameters H and
K for the given set of C, ∆ and λ. The data shown is for the 1D model with short-correlations assumption.

C.

Spatial coupling enables a novel regulatory
strategy at high input noise

Spatial coupling affects both the noise level of the output gene as well as the shape of its output profile. We
wondered how these two effects combine to affect the
information transmission. Figure 5 shows the optimal
mean output profile ḡ(x̂), the underlying activation profile f (x̂), and two measures of the noise in gene expression, the standard deviation σ 2 (x̂) and the Fano factor Φ(x̂) = Nmax σ̂ 2 (x̂)/ḡ(x̂), as a function of position
x̂ ≡ x/L ∈ [0, 1]. We plot these quantities for three
values of C, representative of the input-noise-dominated
regime (C = 0.01), the regime in which input and output noise are approximately balanced (C = 1), and the
output-noise-dominated regime (C = 100). In each plot
we directly compare the system in which the diffusion
constant is optimized along with all other parameters,
vs. the system that is optimal at zero spatial coupling.

For C = 100, input noise levels are so low that the
total noise is dominated by purely Poissonian output
noise throughout the whole system (Φ(x̂) ' 1). Therefore, strong spatial coupling would fail to decrease the
noise further and would merely fade out the mean output profile. Consequently, the optimal diffusion constant
∆∗ = 1 is low, and the spatially coupled system only
differs marginally from the uncoupled system.
For C = 1 in the uncoupled system, input noise becomes more prominent as a fraction of the total noise,
such that Φ(x̂) > 1 for x̂ & 0.3 (cyan colored line
in Fig. 5F); in line with this, the activation threshold is shifted towards higher input concentrations (i.e.
smaller x̂) at the expense of reducing the dynamic range.
In the coupled system the optimal diffusion constant
is markedly higher (∆∗ = 25) than at C = 100, and
the resulting spatial averaging can almost completely remove the additional non-Poissonian noise contributions
(Φ(x̂) ' 1). This allows the optimal activation threshold

9
1.0

f
ḡ, Δ=Δ*
ḡ, Δ=0

f(x̂), ḡ(x̂)

0.8

3.0

0.6
0.2
10

2.5

1
σ(x̂)

C = 0.01, Δ* = 75

f
ḡ, Δ=Δ*
ḡ, Δ=0

f
ḡ, Δ=Δ*
ḡ, Δ=0

0.4
0

I(x;g) [bits]

C = 1, Δ* = 25

C = 100, Δ* = 1

3.5

A

D

G

B

E

H

C

F

I

0.1
0.01

2.0

−3

10

100

Φ(x̂)

I*(C)

1.5

I0(C)
1 −4
10

−2

10

0

10

2

10

104

10

100

1
4

10

10
0

0.2

0.4

0.6
x̂

0.8

1 0

0.2

0.4

0.6
x̂

0.8

1 0

0.2

0.4

0.6

0.8

1

x̂

C = cmax/c0

FIG. 4. Information capacity for varying maximal input concentration, C. Shown is the optimized information
capacity as a function of C = cmax /c0 with optimal diffusive
coupling (I ∗ (C), solid blue line) and without diffusive coupling (I0 (C), dashed blue line). At small C, non-Poissonian
input noise is dominant, while Poissonian output noise dominates for large C. The blue-shaded area depicts the maximal
gain in information capacity from diffusive coupling: spatial
coupling enhances information capacity most efficiently when
input noise dominates. The dashed vertical lines mark the C
values corresponding to the three cases displayed in Fig. 5.

K to shift towards lower input concentrations in order to
attain a similarly large dynamic range as for C = 100.
At C = 0.01, when input noise is exceedingly dominant, we observe the emergence of a qualitatively new
regulatory strategy in the spatially coupled system. For
both spatially coupled and uncoupled systems, low C favors sharp activation profiles with high Hill coefficients
H. For the spatially uncoupled system, the optimal activation threshold K ∗ moves towards central positions. In
contrast, in the optimal spatially coupled system, the optimal activation threshold K ∗ moves closer towards x̂ = 0
where input noise is smaller, and the optimal Hill coefficient makes the activation nearly step-like. Without spatial coupling, this strategy could not be optimal, because
it would be limited to at most one bit—in the region
where the activation profile is flat, positions could not be
discriminated based on the gene expression level g. Optimal diffusion can, however, smooth out this step-like
activation to generate a graded gene expression profile
and restore position discriminability at essentially all positions. Simultaneously, optimal diffusion transforms the
noise in an interesting way, as can be seen in Fig. 5H and
I. The step-like activation curve suppresses the superPoissonian input noise everywhere except for the narrow
interval of x around the transition point where the superPoisson component has a very sharp and tall peak; but
this can very effectively be removed by the strong dif-

FIG. 5. Comparison of optimal output profiles for different values of the maximal input concentration, C.
(A-C) Dominant output noise, C = 100, blue lines. (DF) Balanced noise, C = 1, red lines. (G-I) Dominant input noise, C = 0.01, green lines. For every value of C, the
normalized mean output profile ḡ(x̂) (dashed lines) and the
optimal activation profile f (x̂) (faint solid lines) are shown
in the top row; the noise in gene expression is shown as the
standard deviation σ(x̂) in the middle row; and the Fano factor Φ(x̂) = Nmax σ 2 (x̂)/ḡ(x̂), is shown in the bottom row. All
profiles are shown as a function of the normalized position,
x̂ = x/L. The corresponding quantities for the optimal spatially uncoupled (∆ ' 0) system are shown in complementary
colors (see plot legends).

fusive spatial averaging. In sum, at low C, the optimal
strategy is to use very sharp activation profiles, since they
act as a “filter” for input noise (which must go to zero
at zero or saturated gene expression); the strong optimal
diffusion then smoothes out the step-like activation into
a graded response and removes much of the remaining
input noise around the very localized transition region at
c ≈ K ∗.
Usually, the effect of diffusion on information transmission is understood to be a tradeoff between the beneficial effect of noise averaging and detrimental effect of
smoothing the profile, but here it seems that smoothing
the step-like activation profile is also beneficial for the
information flow. To check that this is indeed a qualitatively different optimal regulatory strategy, we performed
a systematic study of the optimal regulatory parameters
between C = 0.1 and C = 0.01. We found that here
two regulatory strategies compete, as evidenced by two
local maxima in the (K, H) information planes for this
range of C values: one favors relatively low Hill coefficients, H ∗ ' 1, and high activation thresholds K ∗ ; the
other favors high H ∗ and lower K ∗ . For C = 0.01 and
10 . ∆ . 30 both regulatory strategies lead to almost
equal information capacities, but for ∆ & 30 steep activation combined with fast diffusion is preferable. Figure S2
in Appendix F illustrates this phenomenon.

10
D. Full solution in 2D geometry differs only
marginally from an approximate solution in 1D

All results presented in the previous sections were obtained using the 1D model with short-correlations assumption (SCA). To assess how representative they are
of the fully detailed model, we compared the 1D model
with SCA to the 2D model with SCA, and finally to the
2D model that retains more than only nearest-neighbor
correlations (see Appendix B for the formulas in the first
two cases and Appendix C for the latter case).
Figure S3 in Appendix G compares the information
planes I(∆, λ) for the three cases at C = 1. The results suggest that the influence of lateral spatial coupling
present in the 2D model is minor. Particularly in the
range of spatial couplings ∆ around the information maximum, where the system is operating close to the hard
bound set by irreducible Poissonian noise, the difference
between information capacities in 1D and 2D is almost
negligible. Inclusion of 2D couplings mainly increases
I(x; g) values away from the optimal range of parameters, thus effectively enlarging the region of parameter
space in which the system can attain close-to-optimal information transmission. This again is most prominent for
the low C regime, as expected, but still limited to a small
fraction (. 10%) of the total capacity (data not shown).
The effect of incorporating longer-ranged correlations is
minor as well: the information planes for the 2D model
with and without SCA are almost indistinguishible.
Overall, this demonstrates that the 1D model with
short-correlations assumption is a good approximation
of the fully detailed model. In the given context, the
strength of spatial coupling appears more relevant than
its topology.

IV.

DISCUSSION

We developed a generic framework to compute information flow through spatially coupled gene regulatory
networks at steady state. As the simplest example, we
considered how a spatially varying concentration field
(“input profile”) is read out collectively by a regular 1D
or 2D lattice of sampling units that are interacting by
local diffusion of the gene product. A directly applicable
example could be cells (or nuclei) in a developing multicellular organism that respond to the morphogen field
by expressing developmental genes whose products can
be exchanged between neighboring cells. We emphasize
that our framework is generic in that effects due to spatial coupling in any chosen geometry can be worked out
before assuming any particular gene regulatory function
and writing down the relevant noise power spectra, as
is evident from Eqs. (9), (10) and (11). This makes the
framework widely applicable to a broad range of biological problems in which spatially distributed information
is collectively sensed by a set of discrete sampling units
and encoded into a spatial output.

The theory presented here is a direct continuation of
our previous work on quantifying information flow in
gene regulatory networks at increasing levels of realism
[10–14]. In our previous approaches, however, we were
striving for analytical approximations that would permit computing the channel capacity, that is, performing
analytical optimization over all possible distributions of
input signals, Pc (c); this led us to adopt the “small noise
approximation.” Here, in contrast, we assumed a particular geometry (with a uniform distribution over sampling
units, Px (x)) and a particular functional form of the input concentration field, c(x); the latter can depend on
parameters which one can optimize, but we do not perform functional optimization over all possible c(x). While
these restrictions may appear stronger than in our previous work, they also allow us to move to a truly spatially
discrete setup (that has a natural minimal spatial scale of
a cell or nucleus, as is the case in reality), and permit to
relax the small noise approximation, which is no longer
assumed in this work. We also note that a parametric
choice of c(x) is not as restrictive as it might appear initially. First, one could choose a rich enough parametric
form (basis set) for c(x) that ensures spatial smoothness
but otherwise allows optimization in a full space of plausible profiles. Second, it is intuitively clear that monotonic functions encode positional information better than
non-monotonic, or even constant functions, strongly narrowing the range of functional forms over which optimization should take place. Third, while we focused on
exponential gradients which can be easily parametrized
by only two parameters, exponential profiles actually are
widespread throughout biology [23, 24, 42, 59, 60].
Several previous approaches assessed how diffusive
coupling alters the precision of spatial protein patterns driven by spatially distributed inputs [30, 31, 61].
While similar in spirit to ours, these works employed
measures of “regulatory precision” such as the output
pattern steepness and sharpness, which—unlike mutual
information—do not capture the problem in its full richness: these measures quantify precision only locally, on
parts of the output signal, and moreover, make implicit
assumptions about which feature of the output (boundary steepness, boundary position, etc.) is informative.
Information theory removes this arbitrariness [48], and
permits extensions beyond the simple cases studied here.
Similar approaches have recently been suggested for specific biological systems [34, 35, 62].
In our example application we studied how spatial
coupling alters optimal information flow in a singleinput/single-output gene regulatory network motivated
by the bicoid-hunchback system, which is a part of the
gap gene network in early fruit fly development [20, 21].
The main outcome of this analysis is that diffusive coupling enhances information capacity by removing superPoissonian components of the noise, in line with previous
work [30, 31]; this effect is large when input noise is nonnegligible (C ≤ 1). When diffusion plays a large role in
an optimal system, the activation functions can deviate

11
substantially from the resulting output gene expression
profiles. At the extreme, the activation functions can
become step-like with very high Hill coefficients, while
the gene expression profile still smoothly changes over
its full dynamic range; this strategy, optimal at low C,
where both spatial noise averaging and profile smoothing due to diffusion act jointly to increase information,
is qualitatively different from the C regime where profile smoothing is detrimental and trades off against noise
averaging.
In our setup, super-Poissoninan contributions to noise
are fully accounted for by the input noise, but in reality
this need not be the case. There are super-Poissonian
contributions to noise that arise at the output, for instance, due to bursty production of proteins when the
gene is activated. The simplest case is when mRNA expression is rate limiting, but then each mRNA can lead to
a burst in the number of translated proteins. The theory
can be simply extended to these cases by introducing a
burst size into the relevant noise power spectra. Importantly, this would imply that diffusion can be effective
at noise reduction (and thus beneficial for information
transmission) also in the regime where C ≥ 1. In support of this, recently another model linking mRNA expression and protein production with diffusion based on
stochastic branching theory has shown that deviations
from Poissonian statistics in typical biological conditions
are expected only for rather large burst sizes (& 50) [63].
Recently, the field has made progress in detailed understanding of input-side noise in gene regulation due
to stochastic diffusive arrivals of regulatory molecules
to their binding sites [64, 65]. This has led to a revision of the previously suggested functional form for the
Berg-Purcell limit [66, 67] that we use in Eq. (13). Furthermore, we have also taken the simplest (Hill-type)
regulatory function as our model for gene regulation,
rather than picking a richer and potentially more realistic choice, such as the Monod-Wyman-Changeux form.
These refinements will be included into our model in the
future, but there is no reason to expect that they could
change any qualitative outcome of our analyses.
It is interesting to speculate about the predictive power
of optimization-based approaches applied to biological

systems. In neuroscience, the principle of “efficient coding” which states that neural sensory systems devote
their limited resources to maximize the information flow,
in bits, from the naturalistic stimuli into the spiking neural representation [68], has proven enormously successful
since the end of 1950s when it was first suggested by Barlow [69]. In signaling and gene regulation, similar ideas
are much younger. On the other hand, the number of distinct genes or signaling proteins involved in the networks
of interest is much smaller than the number of neurons;
furthermore, molecular processes and the physical limits to sources of noise in gene regulation might be more
easily understood than in neuroscience, where even a single neuron is a very complex object. It appears feasible
that for small genetic networks the optimization problem
would be tractable upon combining all phenomenology
that until now we have analyzed separately: multiple,
interacting genes, driven by one or more inputs, potentially with arbitrary feedback, all major relevant sources
of noise, spatial coupling, and readout constraints [10–
14]. A major goal would also be the ability to relax the
steady-state assumptions, by considering either readout
at particular time points (out of steady state), or the information between full state trajectories [15–19]. Such a
predictive theory, from which optimal networks could be
derived mathematically, could then be realistically confronted with well-studied networks that can be quantitatively measured, e.g., the gap gene network active during Drosophila development [20, 21, 39]. It is intriguing
to think that even in the molecular world the need to
pay for abstract bits of information—in the currency of
time or energy—led nature to choose particular regulatory networks, and perhaps poised them at special operating points [70].

[1] N. G. van Kampen, Stochastic processes in physics and
chemistry (North Holland, Amsterdam, 1981).
[2] L. S. Tsimring, Rep Prog Phys 77, 026601 (2014).
[3] W.-C. Lo, S. Zhou, F. Y.-M. Wan, A. D. Lander, and
Q. Nie, J R Soc Interface 12, 20141041 (2015).
[4] L. Zhang, K. Radtke, L. Zheng, A. Q. Cai, T. F. Schilling,
and Q. Nie, Mol Syst Biol 8, 613 (2012).
[5] A. Eldar, B.-Z. Shilo, and N. Barkai, Curr Op Gen Dev
14, 435 (2004).
[6] A. Eldar, R. Dorfman, D. Weiss, H. Ashe, B.-Z. Shilo,
and N. Barkai, Nature 419, 304 (2002).

[7] G. Tkačik and A. M. Walczak, J Phys Condens Matter
23, 153102 (2011).
[8] G. Tkačik, C. G. Callan, and W. Bialek, Proc Natl Acad
Sci USA 105, 12265 (2008).
[9] J. O. Dubuis, G. Tkačik, E. F. Wieschaus, T. Gregor,
and W. Bialek, Proc Natl Acad Sci USA 110, 16301
(2013).
[10] G. Tkačik, C. G. Callan, and W. Bialek, Phys Rev E
78, 011910 (2008).
[11] G. Tkačik, A. M. Walczak, and W. Bialek, Phys Rev E
80, 031920 (2009).

V.

ACKNOWLEDGEMENTS

The authors thank A. Mugler, I. Nemenman, T. Gregor, M. Tikhonov, P.R. ten Wolde and K. Kaizu for fruitful discussions.

12
[12] A. M. Walczak, G. Tkačik, and W. Bialek, Phys Rev E
81, 041905 (2010).
[13] G. Tkačik, A. M. Walczak, and W. Bialek, Phys Rev E
85, 041903 (2012).
[14] G. Rieckh and G. Tkačik, Biophys J 106, 1194 (2014).
[15] F. Tostevin and P. R. ten Wolde, Phys Rev Lett 102,
218101 (2009).
[16] F. Tostevin and P. R. ten Wolde, Phys Rev E 81, 061917
(2010).
[17] W. H. de Ronde, F. Tostevin, and P. R. ten Wolde, Phys
Rev E 82, 031914 (2010).
[18] A. Mugler, A. M. Walczak, and C. H. Wiggins, Phys
Rev Lett 105, 058101 (2010).
[19] J. Selimkhanov, B. Taylor, J. Yao, A. Pilko, J. Albeck,
A. Hoffmann, L. Tsimring, and R. Wollman, Science
346, 1370 (2014).
[20] J. Jaeger, Cell Mol Life Sci 68, 243 (2011).
[21] J. Jaeger, Manu, and J. Reinitz, Curr Op Gen Dev 22,
533 (2012).
[22] C. A. Rushlow and S. Y. Shvartsman, Curr Op Genetics
of system biology, 22, 542 (2012).
[23] S. Restrepo, J. Zartman, and K. Basler, Curr Biol 24,
R245 (2014).
[24] O. Wartlick, A. Kicheva, and M. González-Gaitán, Cold
Spring Harb Perspect Biol 1, a001255 (2009).
[25] H. Meinhardt, Models of Biological Pattern Formation
(Academic Press, London, 1982).
[26] T. Gregor, K. Fujimoto, N. Masaki, and S. Sawai, Science 328, 1021 (2010).
[27] K. Kamino, K. Fujimoto, and S. Sawai, Dev Growth
Differ 53, 503 (2011).
[28] B. Sun, J. Lembong, V. Normand, M. Rogers, and H. A.
Stone, Proc Natl Acad Sci USA 109, 7753 (2012).
[29] B. Sun, G. Duclos, and H. Stone, Phys Rev Lett 110,
158103 (2013).
[30] T. Erdmann, M. Howard, and P. R. ten Wolde, Phys
Rev Lett 103, 258101 (2009).
[31] T. R. Sokolowski, T. Erdmann, and P. R. ten Wolde,
PLoS Comput Biol 8, e1002654 (2012).
[32] S. C. Little, M. Tikhonov, and T. Gregor, Cell 154, 789
(2013).
[33] H. Garcia, M. Tikhonov, A. Lin, and T. Gregor, Curr
Biol 23, 2140 (2013).
[34] A. Mugler, M. D. Brennan, A. Levchenko, and I. Nemenman (talk at 8th q-bio Conference, Sante Fe, New
Mexico, USA, and personal communication, 2014).
[35] M. Tikhonov, S. C. Little, T. Gregor, and W. Bialek
(talk at 8th q-bio Conference, Sante Fe, New Mexico,
USA, and personal communication, 2014).
[36] B. Houchmandzadeh, E. Wieschaus, and S. Leibler, Nature 415, 798 (2002).
[37] T. Gregor, E. F. Wieschaus, A. P. McGregor, W. Bialek,
and D. W. Tank, Cell 130, 141 (2007).
[38] T. Gregor, D. W. Tank, E. F. Wieschaus, and W. Bialek,
Cell 130, 153 (2007).
[39] J. O. Dubuis, R. Samanta, and T. Gregor, Mol Syst Biol
9, 639 (2013).
[40] M. D. Petkova, S. C. Little, F. Liu, and T. Gregor,
Current Biology 24, 1283 (2014).
[41] Manu, S. Surkova, A. V. Spirov, V. V. Gursky,
H. Janssens, A.-R. Kim, O. Radulescu, C. E. VanarioAlonso, D. H. Sharp, M. Samsonova, and J. Reinitz,
PLoS Biol 7, 591 (2009).

[42] A. M. de Lachapelle and S. Bergmann, Mol S 6, 351
(2010).
[43] L. Wolpert, J Theor Biol 25, 1 (1969).
[44] L. Wolpert, Dev Genet 15, 485 (1994).
[45] L. Wolpert, Trends in Genetics 12, 359 (1996).
[46] L. Wolpert, J Theor Biol 269, 359 (2011).
[47] K. Hironaka and Y. Morishita, Curr Op Gen Dev 22, 553
(2012).
[48] G. Tkačik, J. O. Dubuis, M. D. Petkova, and T. Gregor,
Genetics 199, 39 (2015).
[49] H. Hasegawa, J Phys Soc Jpn 75, 033001 (2006),
arXiv:cond-mat/0512429.
[50] H. Hasegawa, Physica A 374, 585 (2007).
[51] R. Rodriguez and H. C. Tuckwell, Phys Rev E 54, 5585
(1996).
[52] D. T. Gillespie, J Chem Phys 113, 297 (2000).
[53] J. Hattne, D. Fange, and J. Elf, Bioinformatics 21, 2923
(2005).
[54] J. Elf and M. Ehrenberg, Syst Biol (Stevenage) 1, 230
(2004), PMID: 17051695.
[55] G. Tkačik, T. Gregor, and W. Bialek, PLoS ONE 3,
e2774 (2008).
[56] G. Tkačik and W. Bialek, Physical Review E 79, 051901
(2009).
[57] C. E. Shannon, Bell Sys Tech J 27, 379 (1948).
[58] A. Kolmogorov, Problemy Peredachi Informatsii 1, 3
(1965).
[59] T. Bollenbach, P. Pantazis, A. Kicheva, C. Bökel,
M. González-Gaitán, and F. Jülicher, Development 135,
1137 (2008).
[60] A. Kicheva, P. Pantazis, T. Bollenbach, Y. Kalaidzidis,
T. Bittig, F. Jülicher, and M. González-Gaitán, Science
315, 521 (2007).
[61] D. M. Holloway, F. J. P. Lopes, L. da Fontoura Costa,
B. A. N. Travenolo, N. Golyandina, K. Usevich, and
A. V. Spirov, PLoS Comput Biol 7, e1001069 (2011).
[62] T. Taillefumier and N. S. Wingreen, arXiv:1412.7767
[physics, q-bio] (2014).
[63] D. Cottrell, P. S. Swain, and P. F. Tupper, Proc Natl
Acad Sci USA 109, 9699 (2012).
[64] K. Kaizu, W. de Ronde, J. Paijmans, K. Takahashi,
F. Tostevin, and P. R. ten Wolde, Biophys J 106, 976
(2014).
[65] J. Paijmans and P. R. ten Wolde, Phys Rev E 90, 032708
(2014).
[66] H. C. Berg and E. M. Purcell, Biophys J 20, 193 (1977).
[67] W. Bialek and S. Setayeshgar, Proc Natl Acad Sci USA
102, 10040 (2005).
[68] G. Tkačik and W. Bialek, arXiv:1412.8752 [cond-mat,
physics:physics, q-bio] (2014).
[69] H. B. Barlow, in Sensory Communication, edited by
W. A. Rosenbluth (MIT, Cambridge, MA, USA, 1961)
pp. 217–234.
[70] D. Krotov, J. O. Dubuis, T. Gregor, and W. Bialek, Proc
Natl Acad Sci USA , 201324186 (2014).

13
Appendix A: Calculation of stationary means and
(co)variances

Considering Eq. (2) in steady state immediately yields:
1
hF (gi , ci )i = f (ci ) − hgi i
τ
X
X
=h
hgi − gni i = 2dhhgi i − h
hgni i
ni ∈N (i)

ni ∈N (i)

(A1)
This simply reflects the steady-state balance between
production (and degradation) and diffusive in-/outflux
in volume i. Grouping hgi i terms on one side gives


X
τ
f (ci ) + h
hgni i
hgi i =
1 + 2dhτ
ni ∈N (i)
X
⇔ ḡi = T f (ci ) + Λ2
ḡni
(A2)
ni ∈N (i)

where in the last step we abbreviate ḡi ≡ hgi i, T ≡
τ / (1 + 2dhτ ), Λ2 ≡ hT , as in the main text.
To simplify the steady-state expression for the covariances resulting from Eq. (3) it is instructive to treat its
different parts separately. For the terms correlating the
fluctuations in volume i with the production/degradation
process in volume j we have (note that hδgi i = 0 by construction):
hδgi F (gj , cj )i = hδgi if (cj ) −

1
hδgi gj i
τ

1
1
= − hδgi (hgj i + δgj )i = − hδgi δgj i
τ
τ
(A3)
Hence,
2
hδgi F (gj , cj )i + hδgj F (gi , ci )i = − hδgi δgj i
τ

(A4)

because hδgi δgj i ≡ hδgj δgi i.
Similarly, we can rewrite the term that correlates δgi
with the diffusive “neighbor fluxes” of gj
*
+
X
h δgi
(gnj − gj )

and analogously for the term in which i and j are exchanged.
Reinserting (A4) and (A5) into the right side of Eq. (3),
collecting covariance terms hδgi δgj i on the left side, and
multiplying by τ /2 we obtain:
(1 + 2dhτ ) hδgi δgj i


X
hτ  X
=
hδgi δgnj i +
hδgj δgni i
2
nj ∈N (j)
ni ∈N (i)
τX
+
hΓik Γjk i
2
k


X
Λ2  X
⇔ Cij =
Cinj +
Cjni 
2
nj ∈N (j)

ni ∈N (i)

+

k

where Cij ≡ hδgi δgj i. The above equation couples the
covariance Cij to the covariances Cinj and Cjni ; these
represent the correlations between the protein number
in volume i and the neighbor volumes nj of j, and the
analogous quantity with i and j exchanged, respectively.
Hence, even if i and j are nearest neighbors on the lattice, the expressions summing Cinj and Cjni over nj and
ni , respectively, will contain correlations between nextnearest neighbor volumes. While the equation system
defined by Eq. (A6) can be solved for the whole set of
covariances Cij upon imposing suitable boundary conditions, this can be numerically expensive for larger spatial
lattices and large parameter sweeps as part of optimization runs. In this work, the quantity of interest is the
variance Cii in volume i, such that the calculation of
longer-ranged correlations is not strictly required.
Considering the cases i = j and ν ∈ N (i) (ν being one
of the nearest neighbors of i) in Eq. (A6) separately reveals the following interdependence between the variance
σi2 ≡ Cii and the nearest-neighbor covariance Ciν :
σi2 = Λ2

X

Ciν +

ν∈N (i)

Ciν


Λ2  X
=
2

T X
 2 
Γik
2

X

Cinν +

nν ∈N (ν)

= h δgi

hgnj i + δgnj − hgj i − δgj



= h


X

hδgi ihgnj i + hδgi δgnj i

nj ∈N (j)

− 2dh (hδgi ihgj i − hδgi δgj i)



= h

X

hδgi δgnj i − 2dhhδgi δgj i

nj ∈N (j)

T X
hΓik Γνk i
2

(A8)

k

nj ∈N (j)



Cνni 

ni ∈N (i)

+

+
X

(A7)

k

nj ∈N (j)

*

T X
hΓik Γjk i (A6)
2

(A5)

Next-nearest correlations now only appear in Eq. (A8),
which can be significantly simplified by an approximation
that we call the “short-correlations assumption” (SCA):
If the next-nearest-neighbor covariances are assumed to
be small compared to the nearest-neighbor covariances
and single-point variances, we can ignore them and set
Cinν = 0
Cνni = 0

∀nν 6= i
∀ni 6= ν

(A9)

14
because then the only neighbor of ν that has some significant correlation with i is i itself, and vice versa. In that
case, the only remaining terms of the sums in Eq. (A8)
are Cii = σi2 and Cνν = σν2 , respectively:
Ciν =

 T X
Λ2 2
2
σii + σνν
+
hΓik Γνk i
2
2

(A10)

k

P 
 
Specifying
further the noise powers k Γ2ik in (A7) and
P
k hΓik Γνk i in (A10) as described in Section II B yields
formulas (10) and (11).

Appendix C: Full solution without short-correlations
assumption

For completeness, here we also state the formula defining the linear system for the coupled covariances in the
full two-dimensional model without short-correlations
assumption, again indicating volumes by the twodimensional index (ij):
(
1
1
2
C(ij)(kl) =
N̂(ij)(kl)
2 1 + 4∆
h
+ ∆ C(ij)(k−1,l) + C(ij)(k+1,l)

Appendix B: Simplified variance formulae

+ C(ij)(k,l−1) + C(ij)(k,l+1)
In our framework, computation of the mutual information I(x; g) only requires the means ḡi and variances
σi2 . This enables us to reduce the number of coupled
equations to be solved by direct insertion of (11) into
(10), thus eliminating Cij . For the 1D model with
short-correlations assumption (SCA), after some algebraic steps this yields
σi2

∆2


1 2
2
σi−1 + σi−1
=
2
(1 + 2∆) − ∆2 2

1 
1 + 2∆
+
×
Nmax  (1 + 2∆)2 − ∆2
" 
# !
2
∂f
f (ci ) + ḡi
+
cc0
2
∂c
 ci

∆
1
(ḡi−1 + 2ḡi + ḡi+1 )
(B1)
+

(1 + 2∆) + ∆ 2

where we have rewritten prefactor combinations containing T and Λ2 in terms of the spatial coupling ∆.
The analogous formula for the 2D model with SCA
reads
∆2
1 X 2
2
σ(ij)
=
σn
2
(1 + 4∆) − 2∆2 2 n(ij) (ij)

1 + 4∆
1 
+
Nmax  (1 + 4∆)2 − 2∆2


" 
#
2
f (c(ij) ) + ḡ(ij)
∂f

×
+
cc0
2
∂c
c(ij)



X
∆ (1 + 3∆) 1 

4ḡ
+
ḡ
+
n(ij)
(ij)
2

(1 + 4∆) − 2∆2 2
n(ij)

(B2)
where we indicate volumes of the two-dimensional lattice
with a 2D index (ij), and the n(ij) -sums run over the
four nearest neighbor volumes of (ij).

+ C(i−1,j)(kl) + C(i+1,j)(kl)
+ C(i,j−1)(kl) + C(i,j+1)(kl)

i

)

(C1)
2
where the normalized noise term N̂(ij)(kl)
is only non-zero
if the volumes indicated by (ij) and (kl) are identical, i.e.
(ij) ≡ (kl), or nearest neighbors, i.e. (kl) ∈ N ((ij)), and
takes one of the following forms, respectively:
2
2
N̂(ij)(kl)
= N̂(ij)(ij)

X
2
2
2
= Ĝ(ij)
+
D̂[(ij)→n
+
D̂
[n(ij) →(ij)]
(ij) ]
n(ij)

if (ij) ≡ (kl)


2
2
2
N̂(ij)(kl)
= − D̂[(ij)→(kl)]
+ D̂[(kl)→(ij)]
if (kl) ∈ N ((ij))
2
N̂(ij)(kl)
≡0

else

(C2)

Here n(ij) runs over the four nearest-neighbors of volume
2
2
(ij). The normalized noise powers Ĝ(ij)
and D̂[(ij)→(kl)]
derive from the expressions presented in Section II C:


" 
#
2
1 
∂f
2

=
Ĝ(ij)
f (c(ij) ) + ḡ(ij) +
2cc0
Nmax
∂c
c(ij)

2
D̂[(ij)→(kl)]

∆
=
ḡ(ij)
Nmax

(C3)

Eq. (C1) in principle allows for calculation of covariances between volumes that are arbitrarily far apart. In
practice, because of the finiteness of the lattice, the spatial correlations still have to be truncated at a certain
distance and boundary conditions applied in order to obtain a closed system that consists of as many equations
as variables.

15

TABLE I. The standard parameter values of our model.

Appendix D: Standard parameters

In our derivations most system parameters can be combined into two natural scales, a typical concentration c0
(cf. Section II C) and a typical diffusion constant D0 (cf.
Section II B), and we measure concentrations and diffusion in these scales throughout our theory. To obtain
numerical solutions, however, concrete numbers have to
be assigned to these quantities.
Since our example application represents the bicoidhunchback system in early Drosophila development, we
opted for the following choice for the baseline values of
the parameters in Table I: First we chose lattice parameters that roughly correspond to the geometry of the
Drosophila syncytium [37, 38]; in particular, this defines
the lattice spacing δ. We then chose a typical value for
the product protein lifetime τ , which defines the typical
diffusion scale D0 = δ 2 /τ .
To set the value for c0 , we took advantage of the fact
that in the bicoid-hunchback system the activator (i.e.
Bicoid) concentration at midembryo has been measured
experimentally [36, 37]. This lead us to set c0 equal
to the extrapolated maximal value of the measured invivo gradient at its source (x = 0). In other words, at
C = cmax /c0 = 1 the input function c(x) in our model
corresponds to the experimentally measured Bicoid gradient. Finally, to define a standard value for the maximal mean output Nmax , which is a key determinant of
the noise powers and variances (cf. Eqs. (18), (19), (B1),
(B2) and (C3)) but to-date unknown, we chose typical
values for the internal activator diffusion constant Dc
and the binding site length lc ; from this, we calculated
0
the standard value Nmax
= c0 Dc lc τ . When varying C
away from the baseline setting, we changed either cmax
while holding Nmax (and thus c0 ) constant, or by varying Nmax and keeping cmax unchanged, as described in
Appendix E.
Table I demonstrates that all baseline parameter values
are well within a biologically realistic regime.

6.0
5.5

I*(C)

5.0

I0(C)

4.5
I(x;g) [bits]

Quantity
Symbol Value
Lattice spacing
δ
8.33 µm
No. of nuclei in x-direction
Nx
60
– resulting system length
L
500 µm
Internal activator diffusion constant
Dc
3.16 µm2 /s
Activator binding site length
lc
0.01 µm
Product protein lifetime
τ
240 s
0
Std. max. mean product copy no.
Nmax 444
– resulting typ. concentration
c0
58.5 µm−3
(' 35 nM )
– resulting typ. diffusion constant
D0
0.29 µm2 /s
Std. input gradient length
γ0
100 µm
Std. input gradient amplitude
cmax = c0

4.0
3.5
3.0
2.5
2.0
1.5
1.0 −4
10

−2

10

0

10

2

10

4

10

C = cmax/c0

FIG. S1. Information capacity for varying noise type
ratios, varied via Nmax . Shown is the optimized information capacity as a function of the noise type ratio C = cmax /c0
with optimal diffusive coupling (I ∗ (C), solid blue line) and
without diffusive coupling (I0 (C), dashed blue line). C was
varied via Nmax . At small C values, non-Poissonian input
noise is dominant, while Poissonian output noise dominates
for large C. The blue-shaded area depicts the maximal gain
in information capacity from diffusive coupling.

Appendix E: Varying C via Nmax

In our model, the noise type ratio C = cmax /c0 =
cmax /Nmax · (Dc lc τ ) can be varied in multiple ways. In
addition to altering the importance of non-Poissonian input noise via cmax , we also studied the case in which
the contribution of Poissonian output noise is varied via
Nmax while cmax is held constant.
The main difference to the case in which cmax is scaled
is that now information capacities decrease with increasing C, as this means decreasing Nmax and thus enhancing
output noise. The highest information capacity then is
attained in the limit C → 0, i.e. Nmax → ∞. In the
uncoupled system, I(x; g) saturates for C → 0 towards
a value dictated by the amount of (in this case) irreducible input noise, set by cmax . With spatial coupling,
optimal I(x; g) values in the low-C regime are markedly
higher, in accordance with the finding that spatial averaging can only enhance information capacity when input
noise is dominant. As expected, for C → 0, i.e. negligible output noise, and sufficiently strong spatial coupling,
i.e. strongly attenuated input noise, the capacity approaches the hard bound of the noise-free limit given by
the finite number of sampling points Nx along the x-axis,
max
IN
= log2 (Nx ).
x

16
Appendix F: Double maximum

In Fig. S2 we show three different information planes
for noise-type ratio C = 0.01 and increasing values of the
spatial coupling ∆ (∆ = 1, ∆ = 10 and ∆ = 100). The
heat maps demonstrate the emergence of distinct optimal
regulatory strategies for ∆ > 1: for sufficiently strong diffusion (∆ = 10), very steep activation curves (H  1) at
lower activation thresholds K result in similar information transmission as less steep activation curves (H ' 1)
at slightly higher K. For ∆ = 100, steep activation performs better than the other strategy. This effect is seen

most clearly in the 2D model (with SCA), but also appears in the 1D model at slightly different values of C
and ∆.

Appendix G: Model comparison

In Fig. S3 we demonstrate how including increasing
detail affects our results for a paradigmatic case (C = 1,
λ = 1). The different panels show the same information plane for the 1D model with SCA, the 2D model
with SCA and the 2D model without SCA, which retains longer-ranged correlations with next-nearest neighbor volumes.

17

A

Δ=1

B

[bits]

Δ = 10

2.2·10-2
1.5

4.2·10-3

C

[bits]

Δ = 100

[bits]

2.0

2.5

1.5

2.0

K/c0

1.0
2.14

7.9·10-4

1.6

1.5·10-4
0.10

0.49

2.63
H

75.00

0.0

2.8

2.17

0.5

14.03

1.5

1.0

1.0

0.5

0.49

0.10

2.63
H

14.03

75.00

0.0

0.5
0.10

0.49

2.63
H

14.03

75.00

0.0

FIG. S2. Emergence of a second maximum in the information plane. Here we plot for C = 0.01 and standard input
gradient length, i.e. λ = 1, the the positional information I(x; g) as a function of the regulatory parameters H and K for
increasing strength of spatial coupling: (A) ∆ = 1, (B) ∆ = 10, and (C) ∆ = 100. White stars mark local maxima, white
boxes show the corresponding amount of information in bits. The data shown is for the 2D model with SCA.

8

[bits]
3.5

4

3.0

1D w. SCA

2D full

2D w. SCA

2.5

λ

2

2.0

1
3.1

1/2

3.1

1.5

3.1

1.0

1/4
1/8

0.5
−3

10

−2

10

−1

10

0

1

10

10
Δ

2

10

3

10

4

10

−3

10

−2

10

−1

10

0

1

10

10
Δ

2

10

3

10

4

10

−3

10

−2

10

−1

10

0

1

10

10

2

10

3

10

4

10

0.0

Δ

FIG. S3. Comparison of I(x; g) for increasingly detailed versions of the spatial-stochastic model at C = 1. The
reference plot for the 1D model with SCA (left) is identical to the information plane for C = 1 in Fig. 3. The same information
plane is shown for the 2D model with SCA (middle), and for the full 2D model that retains next-nearest neighbor correlations
(right).

