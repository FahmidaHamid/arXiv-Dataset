Estimating Information-Theoretic Quantities
	  
Robin	  A.A.	  Ince1,	  Simon	  R.	  Schultz2	  and	  Stefano	  Panzeri1,3	  
1

	  Institute	  of	  Neuroscience	  and	  Psychology,	  58	  Hillhead	  Street,	  University	  of	  Glasgow,	  Glasgow	  G12	  8QB,	  UK	  	  

2

	  Department	  of	  Bioengineering,	  Imperial	  College	  London,	  South	  Kensington,	  London	  SW7	  2AZ,	  UK	  

3

	   Center	   For	   Neuroscience	   and	   Cognitive	   Systems,	   Italian	   Institute	   of	   Technology,	   Corso	   Bettini	   31	   –	   38068	   Rovereto	  

(Tn)	  Italy	  
	  

	  
16	  pages	  5724	  words.	  

Definition
Information	  theory	  is	  a	  practical	  and	  theoretical	  framework	  developed	  for	  the	  study	  of	  communication	  over	  
noisy	  channels.	  Its	  probabilistic	  basis	  and	  capacity	  to	  relate	  statistical	  structure	  to	  function	  make	  it	  ideally	  
suited	   for	   studying	   information	   flow	   in	   the	   nervous	   system.	   It	   has	   a	   number	   of	   useful	   properties:	   it	   is	   a	  
general	  measure	  sensitive	  to	  any	  relationship,	  not	  only	  linear	  effects;	  it	  has	  meaningful	  units	  which	  in	  many	  
cases	   allow	   direct	   comparison	   between	   different	   experiments;	   and	   it	   can	   be	   used	   to	   study	   how	   much	  
information	   can	   be	   gained	   by	   observing	   neural	   responses	   in	   single	   trials,	   rather	   than	   in	   averages	   over	  
multiple	  trials.	  A	  variety	  of	  information	  theoretic	  quantities	  are	  in	  common	  use	  in	  neuroscience	  –	  (see	  entry	  
“Summary	  of	  Information-­‐Theoretic	  Quantities”).	  Estimating	  these	  quantities	  in	  an	  accurate	  and	  unbiased	  
way	  from	  real	  neurophysiological	  data	  frequently	  presents	  challenges,	  which	  are	  explained	  in	  this	  entry.	  

Detailed Description
Information theoretic quantities
Information	   theory	   provides	   a	   powerful	   theoretical	   framework	   for	   studying	   communication	   in	   a	  
quantitative	  way.	  Within	  the	  framework	  there	  are	  many	  different	  quantities	  to	  assess	  different	  properties	  
of	   systems,	   many	   of	   which	   have	   been	   applied	   fruitfully	   to	   analysis	   of	   the	   nervous	   system	   and	   neural	  
communication.	  These	  include	  the	  entropy	  (H;	  which	  measures	  the	  uncertainty	  associated	  with	  a	   stochastic	  
variable),	   mutual	   information	   (I;	   which	   measures	   the	   dependence	   relationship	   between	   two	   stochastic	  
variables),	   and	   several	   more	   general	   divergence	   measures	   for	   probability	   distributions	   (Kullbeck-­‐Liebler,	  
Jenson-­‐Shannon).	   For	   full	   definitions	   and	   details	   of	   these	   quantities,	   see	   the	   "Summary	   of	   Information-­‐
Theoretic	  Quantities"	  entry.	  	  

The	  Finite	  Sampling	  Problem	  	  
A	   major	   difficulty	   when	   applying	   techniques	   involving	   information	   theoretic	   quantities	   to	   experimental	  
systems	  is	  that	  they	  require	  measurement	  of	  the	  full	  probability	  distributions	  of	  the	  variables	  involved.	  If	  
we	   had	   an	   infinite	   amount	   of	   data,	   we	   could	   measure	   the	   true	   stimulus-­‐response	   probabilities	   precisely.	  
However,	  any	  real	  experiment	  only	  yields	  a	  finite	  number	  of	  trials	  from	  which	  these	  probabilities	  must	  be	  
estimated.	  The	  estimated	  probabilities	  are	  subject	  to	  statistical	  error	  and	  necessarily	  fluctuate	  around	  their	  
true	  values.	  The	  significance	  of	  these	  finite	  sampling	  fluctuations	  is	  that	  they	  lead	  to	  both	  statistical	  error	  
(variance)	   and	   systematic	   error	   (called	   limited	   sampling	   bias)	   in	   estimates	   of	   entropies	   and	   information.	  
This	   bias	   is	   the	   difference	   between	   the	   expected	   value	   of	   the	   quantity	   considered,	   computed	   from	  
probability	   distributions	   estimated	   with	   N	   trials	   or	   samples,	   and	   its	   value	   computed	   from	   the	   true	  
probability	   distribution.	   This	   is	   illustrated	   in	   Figure	   1,	   which	   shows	   histogram	   estimates	   of	   the	   response	  
distribution	   for	   two	   different	   stimuli	   calculated	   from	   40	   trials	   per	   stimulus.	   While	   the	   true	   probabilities	   are	  
uniform	   (dotted	   black	   lines)	   the	   calculated	   maximum	   likelihood	   estimates	   show	   some	   variation	   around	   the	  
true	   values.	   This	   causes	   spurious	   differences	   –	   in	   this	   example	   the	   sampled	   probabilities	   indicate	   that	  
obtaining	   a	   large	   response	   suggests	   stimulus	   1	   is	   presented	   –	   which	   results	   in	   a	   positive	   value	   of	   the	  
information.	   Figure	   1C	   shows	   a	   histogram	   of	   information	   values	   obtained	   from	   many	   simulations	   of	   this	  
system.	  The	  bias	  constitutes	  a	  significant	  practical	  problem,	  because	  its	  magnitude	  is	  often	  of	  the	  order	  of	  
the	  information	  values	  to	  be	  evaluated,	  and	  because	  it	  cannot	  be	  alleviated	  simply	  by	  averaging	  over	  many	  
neurons	  with	  similar	  characteristics.	  
Direct	  estimation	  of	  information	  theoretic	  quantities	  
The	   most	   direct	   way	   to	   compute	   information	   and	   entropies	   is	   to	   estimate	   the	   response	   probabilities	   as	   the	  
experimental	  histogram	  of	  the	  frequency	  of	  each	  response	  across	  the	  available	  trials,	  and	  then	  plug	  these	  
empirical	  probability	  estimates	  into	  Eqs.	  (1-­‐3).	  We	  refer	  to	  this	  as	  the	  “plug-­‐in”	  method.	  
The	   plug-­‐in	   estimate	   of	   entropy	   is	   biased	   downwards	   (estimated	   values	   are	   lower	   than	   the	   true	   value)	  
while	  the	  plug-­‐in	  estimate	  of	  information	  shows	  an	  upward	  bias.	  An	  intuitive	  explanation	  for	  why	  entropy	  is	  
biased	   downwards	   comes	   from	   the	   fact	   that	   entropy	   is	   a	   measure	   of	   variability.	   As	   we	   saw	   in	   Figure	   1,	  
variance	   in	   the	   maximum	   likelihood	   probability	   estimates	   introduces	   extra	   structure	   in	   the	   probability	  
distributions;	   this	   additional	   variation	   (which	   is	   dependent	   on	   the	   number	   of	   trials	   from	   the	   asymptotic	  
normality	  of	  the	  ML	  estimate)	  always	  serves	  to	  make	  the	  estimated	  distribution	  less	  uniform	  or	  structured	  
than	  the	  true	  distribution.	  Consequently,	  entropy	  estimates	  are	  lower	  than	  their	  true	  values,	  and	  the	  effect	  

of	  finite	  sampling	  on	  entropies	  is	  a	  downward	  bias.	  For	  information,	  an	  explanation	  for	  why	  bias	  is	  typically	  
positive	   is	   that	   finite	   sampling	   can	   introduce	   spurious	   stimulus-­‐dependent	   differences	   in	   the	   response	  
probabilities,	  which	  make	  the	  stimuli	  seem	  more	  discernible	  and	  hence	  the	  neuron	  more	  informative	  than	  
it	  really	  is.	  Alternatively,	  viewing	  the	  information	  as	  a	  difference	  of	  unconditional	  and	  conditional	  entropies,	  
(first	   two	   expressions	   of	   Eq.	   in	   “Summary	   of	   Information	   Theoretic	   Quantities”)	   the	   conditional	   entropy	   for	  
each	  stimulus	  value	  is	  estimated	  from	  a	  reduced	  number	  of	  trials	  compared	  to	  the	  noise	  entropy	  (only	  the	  
trials	   corresponding	   to	   that	   stimulus)	   and	   so	   its	   bias	   is	   considerably	   larger.	   Since	   entropy	   is	   biased	   down	  
and	  the	  conditional	  entropy	  term	  appears	  with	  a	  negative	  sign,	  this	  causes	  the	  upward	  bias	  in	  information.	  	  
In	   the	   above	   explanations	   for	   the	   source	   of	   the	   bias,	   the	   source	   is	   the	   variability	   in	   estimates	   of	   the	  
probability	   distributions	   considered.	   Variance	   in	   the	   maximum	   likelihood	   histogram	   estimators	   of	   the	  
probabilities	  induces	  additional	  “noise”	  structure	  affecting	  the	  entropy	  and	  information	  values.	  	  
Asymptotic	  estimates	  of	  the	  limited	  sampling	  bias	  
To	   understand	   the	   sampling	   behaviour	   of	   information	   and	   entropy	   better,	   it	   is	   useful	   to	   find	   analytical	  
approximations	   to	   the	   bias.	   This	   can	   be	   done	   in	   the	   so-­‐called	   “asymptotic	   sampling	   regime”.	   Roughly	  
speaking	   this	   is	   when	   the	   number	   of	   trials	   is	   “large”.	   More	   rigorously,	   the	   asymptotic	   sampling	   regime	   is	  
defined	   as	   N	   being	   large	   enough	   that	   every	   possible	   response	   occurs	   many	   times:	   that	   is,	   Ns	   P(r|s)	   >>	   1	   for	  
each	   stimulus-­‐response	   pair	   s,r	   such	   that	   P(r|s)	   >	   0.	   In	   this	   regime,	   the	   bias	   of	   the	   entropies	   and	  
information	   can	   be	   expanded	   in	   inverse	   powers	   of	   1/N	   and	   analytical	   approximations	   obtained	   (Miller,	  
1955;	  Panzeri	  and	  Treves,	  1996).	  The	  leading	  terms	  in	  the	  biases	  are	  respectively:	  

−1
⎡ R − 1⎤
⎦
2 N ln(2) ⎣
−1
BIAS [ H ( R | S ) ] =
∑ ⎡ Rs − 1⎤⎦
2 N ln(2) s ⎣
BIAS [ H ( R)] =

	  

BIAS [ I ( S ; R)] =

1
⎧
⎫
⎨∑ ⎡⎣ Rs − 1⎤⎦ − ⎡⎣ R − 1⎤⎦ ⎬
2 N ln(2) ⎩ s
⎭ 	  	  

(1)	  

Here	   Rs denotes	   the	   number	   of	   relevant	   responses	   for	   the	   stimulus	   conditional	   response	   probability	  
distribution	   P(r|s)	   –	   i.e.	   the	   number	   of	   different	   responses	   r	   with	   non-­‐zero	   probability	   of	   being	   observed	  
when	  stimulus	  s	  is	  presented.	   R 	  denotes	  the	  number	  of	  relevant	  responses	  for	   P(r)	  –	  i.e.	  the	  number	  of	  
different	   responses	   r	   with	   	   non-­‐zero	   probability	   of	   being	   observed	   across	   all	   stimuli.	   In	   practice,	   R 	  is	  
usually	  going	  to	  be	  equal	  to	  the	  number	  of	  elements	  constituting	  the	  response	  space	  R.	  If	  a	  response	  never	  
happens	  across	  all	  stimuli,	  it	  can	  be	  removed	  from	  the	  sum	  over	  r	  in	  the	  calculation	  of	  each	  entropy	  term,	  
and	   thus	   removed	   from	   the	   response	   set	   R.	   However,	   Rs may	   be	   different	   from R 	  if	   some	   responses	   occur	  
only	  with	  particular	  stimuli.	  
Although	  valid	  only	  in	  the	  asymptotic	  regime,	  Eq.	  (1)	  sheds	  valuable	  light	  on	  the	  key	  factors	  that	  control	  the	  
bias.	  First,	  Eq.	  (1)	  shows	  that	  the	  bias	  of	   H(R | S) 	  is	  approximately	  S	  times	  bigger	  than	  that	  of	   H(R) .	  This	  
means	   that,	   in	   the	   presence	   of	   many	   stimuli,	   the	   bias	   of	   I(S;R) 	  is	   similar	   to	   that	   of	   H(R | S) .	   However,	  

I(S;R) 	  is	   a	   difference	   of	   entropies,	   and	   its	   typical	   values	   are	   much	   smaller	   than	   those	   of	   H(R | S) .	   This	  
implies	  that	  bias	  correction	  methods	  must	  be	  validated	  on	  the	  performance	  of	  information	  and	  not	  only	  on	  

entropies,	   because,	   in	   many	   cases,	   the	   bias	   may	   be	   proportionally	   negligible	   for	   entropies	   but	   not	   the	  
information.	   Second,	   Eq.	   (1)	   shows	   that	   the	   bias	   is	   small	   when	   the	   ratio	   Ns/ R 	  is	   big,	   i.e.	   more	   trials	   per	  
stimulus	   than	   possible	   responses.	   This	   is	   because,	   assuming	   that	   the	   number	   of	   trials	   per	   stimulus	   is	  
approximately	   constant	   and	   Rs is	   approximately	   equal	   to R ,	   the	   bias	   of	   H(R | S) 	  is	   approximately	   – R
/[2Nsln(2)].	  Thus,	  Ns/ R 	  is	  the	  crucial	  parameter	  for	  the	  sampling	  problem.	  For	  example,	  in	  the	  simulations	  
of	   Fig.	   2,	   with	   R =28	   the	   bias	   of	   I(S;R) 	  became	   negligible	   for	   Ns	   ≥	   213	   (i.e.	   Ns/ R 	  ≥	   32).	   	   Second,	   Eq.	   (1)	  
shows	  that,	  even	  if	  Ns	  is	  constant,	  the	  bias	  increases	  with	  the	  number	  of	  responses	   R .	  This	  has	  important	  
implications	   for	   comparing	   neural	   codes.	   For	   example,	   a	   response	   consisting	   of	   a	   given	   number	   of	   spikes	  
can	   arise	   from	   many	   different	   possible	   temporal	   patterns	   of	   spikes.	   Thus,	   R 	  is	   typically	   much	   greater	   for	   a	  
spike	  timing	  code	  than	  for	  a	  spike	  count	  code,	  and	  it	  follows	  from	  Eq.	  (1)	  that	  the	  estimate	  of	  information	  
conveyed	  by	  a	  spike	  timing	  code	  is	  more	  biased	  than	  that	  measured	  for	  the	  same	  neurons	  through	  a	  spike	  
count	   code.	   	   If	   bias	   is	   not	   eliminated,	   there	   is	   therefore	   a	   danger	   of	   concluding	   that	   spike	   timing	   is	  
important	  even	  when	  it	  is	  not.	  	  	  	  	  	  
A	   further	   important	   feature	   of	   Eq.	   (1)	   is	   that,	   although	   the	   bias	   is	   not	   the	   same	   for	   all	   probability	  
distributions,	   in	   the	   asymptotic	   sampling	   regime	   it	   depends	   on	   some	   remarkably	   simple	   details	   of	   the	  
response	   distribution	   (the	   number	   of	   trials	   and	   the	   number	   of	   relevant	   responses).	   	   Thus	   Eq.	  (1)	   makes	   it	   is	  
possible	  to	  derive	  simple	  rules	  of	  thumb	  for	  estimating	  the	  bias	  magnitude	  and	  compare	  the	  relative	  bias	  in	  
different	  situations.	  As	  detailed	  in	  the	  next	  section,	  the	  simplicity	  of	  Eq.	  (1)	  can	  also	  be	  exploited	  in	  order	  to	  
correct	  effectively	  for	  the	  bias	  (Panzeri	  and	  Treves,	  1996).	  	  

Bias	  Correction	  Methods	  
A	  number	  of	  techniques	  have	  been	  developed	  to	  address	  the	  issue	  of	  bias,	  and	  allow	  much	  more	  accurate	  
estimates	   of	   information	   theoretic	   quantities	   than	   the	   “plug-­‐in”	   method	   described	   above.	   (Panzeri	   et	   al.,	  
2007)	  and	  (Victor,	  2006)	  provide	  a	  review	  of	  such	  methods,	  a	  selection	  of	  which	  are	  briefly	  outlined	  here.	  	  
Panzeri–Treves	  (PT)	  
In	   the	   so-­‐called	   asymptotic	   sampling	   regime,	   when	   the	   number	   of	   trials	   is	   large	   enough	   that	   every	   possible	  
response	  occurs	  many	  times,	  an	  analytical	  approximation	  for	  the	  bias	  (i.e.	  the	  difference	  between	  the	  true	  
value	   and	   the	   plug-­‐in	   estimate)	   of	   entropies	   and	   information	   can	   be	   obtained	   (Miller,	   1955;	   Panzeri	   and	  
Treves,	  1996)	  (Eq.	   (1)).	  The	  value	  of	  the	  bias	  computed	  from	  the	  above	  expressions	  is	  then	  subtracted	  from	  
the	   plug-­‐in	   estimate	   to	   obtain	   the	   corrected	   value.	   This	   requires	   an	   estimate	   of	   the	   number	   of	   relevant	  
responses	   for	   each	   stimulus,	   Rs .	   The	   simplest	   approach	   is	   to	   approximate	   Rs 	  by	   the	   count	   of	   responses	  
that	  are	  observed	  at	  least	  once	  –	  this	  is	  the	  “naive”	  count.	  However	  due	  to	  finite	  sampling	  this	  will	  be	  an	  
underestimate	  of	  the	  true	  value.	  A	  Bayesian	  procedure	  (Panzeri	  and	  Treves,	  1996)	  can	  be	  used	  to	  obtain	  a	  
more	  accurate	  value.	  
Quadratic	  Extrapolation	  (QE)	  
In	  the	  asymptotic	  sampling	  regime,	  the	  bias	  of	  entropies	  and	  information	  can	  be	  approximated	  as	  second	  
order	  expansions	  in	  1/N,	  where	  N	  is	  the	  number	  of	  trials	  (Treves	  and	  Panzeri,	  1995;	  Strong	  et	  al.,	  1998).	  For	  
example,	  for	  information:	  

	  

I plugin ( R; S ) = I true ( R; S ) +

a
b
+ 2
N N 	  	  

(2)	  

This	  property	  can	  be	  exploited	  by	  calculating	  the	  estimates	  with	  subsets	  of	  the	  original	  data,	  with	  N/2	  and	  
N/4	  trials	  and	  fitting	  the	  resulting	  values	  to	  the	  polynomial	  expression	  above.	  This	  allows	  an	  estimate	  of	  the	  
parameters	   a	   and	   b	   and	   hence	   Itrue(S;	   R).	   To	   use	   all	   available	   data,	   estimates	   of	   two	   subsets	   of	   size	   N/2	   and	  
four	   subsets	   of	   size	   N/4	   are	   averaged	   to	   obtain	   the	   values	   for	   the	   extrapolation.	   Together	   with	   the	   full	  
length	  data	  calculation,	  this	  requires	  seven	  different	  evaluations	  of	  the	  quantity	  being	  estimated.	  
Nemenman–Shafee–Bialek	  (NSB)	  
The	  NSB	  method	  (Nemenman	  et	  al.,	  2002,	  2004)	  utilises	  a	  Bayesian	  inference	  approach	  and	  does	  not	  rely	  
on	  the	  assumption	  of	  the	  asymptotic	  sampling	  regime.	  It	  is	  based	  on	  the	  principle	  that	  when	  estimating	  a	  
quantity,	  the	  least	  bias	  will	  be	  achieved	  when	  assuming	  an	  a	  priori	  uniform	  distribution	  over	  the	  quantity.	  
This	   method	   is	   more	   challenging	   to	   implement	   than	   the	   other	   methods,	   involving	   a	   large	   amount	   of	  
function	   inversion	   and	   numerical	   integration.	   However,	   it	   often	   gives	   a	   significant	   improvement	   in	   the	  
accuracy	   of	   the	   bias	   correction	   (Montani	   et	   al.,	   2007,	   2007;	   Montemurro	   et	   al.,	   2007;	   Nemenman	   et	   al.,	  
2008).	  
Shuffled	  Information	  Estimator	  (Ish)	  
Recently,	  an	  alternative	  method	  of	  estimating	  the	  mutual	  information	  has	  been	  proposed	  (Montemurro	  et	  
al.,	  2007;	  Panzeri	  et	  al.,	  2007).	  Unlike	  the	  methods	  above,	  this	  is	  a	  method	  for	  calculating	  the	  information	  
only,	   and	   is	   not	   a	   general	   entropy	   bias	   correction.	   However,	   it	   can	   be	   used	   with	   the	   entropy	   corrections	  
described	   above	   to	   obtain	   more	   accurate	   results.	   In	   brief,	   the	   method	   uses	   the	   addition	   and	   subtraction	   of	  
different	  terms	  (in	  which	  correlations	  given	  a	  fixed	  stimulus	  are	  removed	  either	  by	  empirical	  shuffling	  or	  by	  
marginalizing	  and	  then	  multiplying	  response	  probabilities)	  that	  do	  not	  change	  the	  information	  value	  in	  the	  
limit	  of	  an	  infinite	  number	  of	  trials,	  but	  do	  remove	  a	  large	  part	  of	  the	  bias	  for	  finite	  number	  of	  trials.	  This	  
greatly	  reduces	  the	  bias	  of	  the	  information	  estimate,	  at	  the	  price	  of	  only	  a	  marginal	  increase	  of	  variance.	  
Note	   that	   this	   procedure	   works	   well	   for	   weakly	   correlated	   data,	   which	   is	   frequently	   the	   case	   for	  
simultaneously	  recorded	  neurons.	  	  	  
Examples	  of	  bias	  correction	  performance	  
Figure	  2A	  reports	  the	  results	  of	  the	  performance	  of	  bias	  correction	  procedures,	  both	  in	  terms	  of	  bias	  and	  
Root	   Mean	   Square	   (RMS)	   error,	   on	   a	   set	   of	   simulated	   spike	   trains	   from	   eight	   simulated	   neurons.	   Each	   of	  
these	  neurons	  emitted	  spikes	  with	  a	  probability	  obtained	  from	  a	  Bernoulli	  process.	  The	  spiking	  probabilities	  
were	   set	   equal	   to	   those	   measured,	   in	   the	   10–15	   ms	   post-­‐stimulus	   interval,	   from	   eight	   neurons	   in	   rat	  
somatosensory	  cortex	  responding	  to	  13	  stimuli	  consisting	  of	  whisker	  vibrations	  of	  different	  amplitude	  and	  
frequency	   (Arabzadeh	   et	   al.,	   2004).	   The	   10–15	   ms	   interval	   was	   chosen	   since	   it	   was	   found	   to	   be	   the	   interval	  
containing	   highest	   information	   values.	   Figure	   2A	   shows	   that	   all	   bias	   correction	   procedures	   generally	  
improve	   the	   estimate	   of	   I(S;R)	   with	   respect	   to	   the	   plug-­‐in	   estimator,	   and	   the	   NSB	   correction	   is	   especially	  
effective.	  	  
Figure	   2B	   shows	   that	   the	   bias-­‐corrected	   estimation	   of	   information	   (and	   RMS	   error;	   lower	   panel)	   is	   much	  
improved	  by	  using	  Ish(R;S)	  rather	  than	  I(R;S).	  The	  use	  of	  Ish(R;S)	  makes	  the	  residual	  errors	  in	  the	  estimation	  
of	   information	   much	   smaller	   and	   almost	   independent	   from	   the	   bias	   correction	   method	   used.	   Taking	   into	  
account	   both	   bias	   correction	   performance	   and	   computation	   time,	   for	   this	   simulated	   system	   the	   best	  
method	   to	   use	   is	   the	   shuffled	   information	   estimator	   combined	   with	   the	   Panzeri–Treves	   analytical	  

correction.	   Using	   this,	   an	   accurate	   estimate	   of	   the	   information	   is	   possible	   even	   when	   the	   number	   of	  
samples	  per	  stimulus	  is	  R	  where	  R	  is	  the	  dimension	  of	  the	  response	  space.	  
It	   should	   be	   noted	   that	   while	   bias	   correction	   techniques	   such	   as	   those	   discussed	   above	   are	   essential	   if	  
accurate	   estimation	   of	   the	   information	   is	   required,	   whether	   to	   employ	   them	   depends	   upon	   the	   question	  
being	   addressed.	   If	   the	   aim	   is	   quantitative	   comparison	   of	   information	   values	   between	   different	  
experiments,	  stimuli	  or	  behaviours,	  they	  are	  essential.	  If	  instead	  the	  goal	  is	  simply	  to	  detect	  the	  presence	  of	  
a	   significant	   interaction,	   the	   statistical	   power	   of	   information	   as	   a	   test	   of	   independence	   is	   greater	   if	   the	  
uncorrected	  plug-­‐in	  estimate	  is	  used	  (Ince	  et	  al.,	  2012).	  This	  is	  because	  all	  the	  bias	  correction	  techniques	  
introduce	   additional	   variance;	   for	   a	   hypothesis	   test	   which	   is	   unaffected	   by	   underlying	   bias,	   this	   variance	  
reduces	  the	  statistical	  power.	  

Information	  Component	  Analysis	  Techniques	  	  
The	   principal	   use	   of	   Information	   Theory	   in	   neuroscience	   is	   to	   study	   the	   neural	   code	   –	   and	   one	   of	   the	  
commonly	   studied	   problems	   in	   neural	   coding	   is	   to	   take	   a	   given	   neurophysiological	   dataset,	   and	   to	  
determine	   how	   the	   information	   about	   some	   external	   correlate	   is	   represented.	   One	   way	   to	   do	   this	   is	   to	  
compute	  the	  mutual	  information	  that	  the	  neural	  responses	  convey	  on	  average	  about	  the	  stimuli	  (or	  other	  
external	  correlate),	  under	  several	  different	  assumptions	  about	  the	  nature	  of	  the	  underlying	  code	  (e.g.	  firing	  
rate,	   spike	   latency,	   etc).	   The	   assumption	   is	   that	  if	   one	   code	   yields	   substantially	   greater	   mutual	   information,	  
then	  downstream	  detectors	  are	  more	  likely	  to	  be	  using	  that	  code	  (the	  Efficient	  Coding	  Hypothesis).	  
A	   conceptual	   improvement	   on	   this	   procedure,	   where	   it	   can	   be	   done,	   is	   to	   take	   the	   total	   information	  
available	   from	   all	   patterns	   of	   spikes	   (and	   silences),	   and	   to	   break	   it	   down	   (mathematically)	   into	   components	  
reflecting	   different	   encoding	   mechanisms,	   such	   as	   firing	   rates,	   pairwise	   correlations,	   etc	   (Panzeri	   et	   al.,	  
1999;	  Panzeri	  and	  Schultz,	  2001).	  One	  way	  to	  do	  this	  is	  to	  perform	  an	  asymptotic	  expansion	  of	  the	  mutual	  
information,	  grouping	  terms	  in	  such	  a	  way	  that	  they	  reflect	  meaningful	  coding	  mechanisms.	  
Taylor	  series	  expansion	  of	  the	  mutual	  information	  
A	   taylor	   series	   expansion	   of	   the	   mutual	   information	   is	   one	   such	   approach.	   For	   short	   time	   windows	   (and	   we	  
will	  discuss	  presently	  what	  “short”	  means),	  the	  mutual	  information	  can	  be	  approximated	  as	  
	  

I (R;S) = TI t +

T2
I tt + ... 	  	  
2

(3)	  

where	   the	   subscript	   t	   indicates	   the	   derivative	   with	   respect	   to	   the	   time	   window	   length	  T.	   For	   time	   windows	  
sufficiently	   short	   that	   only	   a	   pair	   of	   spikes	   are	   contained	   within	   the	   time	   window	   (either	   from	   a	   population	  
of	   cells	   or	   from	   a	   single	   spike	   train),	   the	   first	   two	   terms	   are	   all	   that	   is	   needed.	   If	   the	   number	   of	   spikes	  
exceeds	  two,	  it	  may	  still	  be	  a	  good	  approximation,	  but	  higher	  order	  terms	  would	  be	  needed	  to	  capture	  all	  
of	   the	   information.	   One	   possibility	   is	   that	   Equation	   (3)	   could	   be	   extended	   to	   incorporate	   higher	   order	  
terms,	   however	   we	   have	   instead	   found	   it	   better	   in	   practice	   to	   take	   an	   alternative	   approach	   (see	   next	  
section).	  
With	  only	  a	  few	  spikes	  to	  deal	  with,	  it	  is	  possible	  to	  use	  combinatorics	  to	  write	  out	  the	  expressions	  for	  the	  
probabilities	  of	  observing	  different	  spike	  patterns.	  This	  was	  initially	  done	  for	  the	  information	  contained	  in	  
the	   spikes	   fired	   by	   a	   small	   population	   of	   cells	   (Panzeri	   et	   al.,	   1999),	   and	   then	   later	   extended	   to	   the	  
information	  carried	  by	  the	  spatiotemporal	  dynamics	  of	  a	  small	  population	  of	  neurons	  over	  a	  finite	  temporal	  

wordlength	   (Panzeri	   and	   Schultz,	   2001).	   In	   the	   former	   formulation,	   we	   define ri (s) 	  to	   be	   the	   mean	  
response	  rate	  (number	  of	  spikes	  in	  T	  divided	  by	  T)	  of	  cell	  i	  (of	  C	  cells)	  to	  stimulus	  s	  over	  all	  trials	  where	  s	  
was	  presented.	  We	  then	  define	  the	  signal	  cross-­‐correlation	  density	  to	  be	  

ri (s)rj (s)

ν ij =

	  

ri (s)

s

− 1 	  .	  

s

rj (s)

(4)	  

s

This	   quantity	   captures	   the	   correlation	   in	   the	   mean	   response	   profiles	   of	   each	   cell	   to	   different	   stimuli	   (e.g.	  
correlated	  tuning	  curves).	  Analogously,	  we	  define	  the	  noise	  cross-­‐correlation	  density	  to	  be	  

γ ij (s) =

	  

ri (s)rj (s)
− 1 	  .	  
ri (s)rj (s)

(5)	  

The	  mutual	  information	  I(R;S)	  can	  then	  be	  written	  as	  the	  sum	  of	  four	  components,	  

I = I lin + I sig-sim + I cor-ind + I cor-dep

	  

	  ,	  

(6)	  

	  	  

(7)	  

with	  the	  first	  component	  
C

I lin = T ∑ ri (s)log 2

	  

i=1

ri (s)
ri (s ') s '

s

capturing	   the	   rate	   component	   of	   the	   information,	   i.e.	   that	   which	   survives	   when	   there	   is	   no	   correlation	  
between	  cells	  (even	  of	  their	  tuning	  curves)	  present	  at	  all.	  This	  quantity	  is	  positive	  semi-­‐definite,	  and	  adds	  
linearly	   across	   neurons.	   It	   is	   identical	   to	   the	   “information	   per	   spike”	   approximation	   calculated	   by	   a	   number	  
of	   authors	   (Skaggs	   et	   al.,	   1993;	   Brenner	   et	   al.,	   2000;	   Sharpee	   et	   al.,	   2004).	   Isig-­‐sim	   is	   the	   correction	   to	   the	  
information	  required	  to	  take	  account	  of	  correlation	  in	  the	  tuning	  of	  individual	  neurons,	  or	  signal	  similarity:	  

I sig-sim =

	  

T2 C C
∑ ∑ ri (s)
2 ln 2 i=1 j=1

s

⎡
⎛ 1 ⎞⎤
rj (s) ⎢ν ij + (1+ ν ij )ln ⎜
⎟ ⎥ 	  	  
s
⎝ 1+ ν ij ⎠ ⎥⎦
⎢⎣

(8)	  

This	   is	   negative	   semi-­‐definite.	   Icor-­‐ind	   is	   the	   effect	   on	   the	   transmitted	   information	   of	   the	   average	   level	   of	  
noise	  correlation	  (correlation	  at	  fixed	  stimulus)	  between	  neurons:	  
	  

I cor-ind

⎛ 1 ⎞
T2 C C
=
ri (s)rj (s)γ ij (s) log 2 ⎜
∑
∑
⎟ 	  .	  
s
2 i=1 j=1
⎝ 1+ ν ij ⎠

(9)	  

Icor-­‐ind	  can	  take	  either	  positive	  or	  negative	  values.	  Icor-­‐dep	  is	  the	  contribution	  of	  stimulus-­‐dependence	  in	  the	  
correlation	   to	   the	   information	   –	   as	   would	   be	   present,	   for	   instance,	   if	   synchrony	   was	   modulated	   by	   a	  
stimulus	  parameter:	  

	  

I cor-dep

(

)

⎡ r (s ')r (s ') 1+ γ (s) ⎤
T2 C C
i
j
ij
s'
⎥
=
ri (s)rj (s) 1+ γ ij (s) log 2 ⎢
∑
∑
⎢ ri (s ')rj (s ') 1+ γ ij (s ') ⎥
2 i=1 j=1
⎣
s' ⎦

(

)

(

)

	  	  
s

(10)	  

An	   application	   of	   this	   approach	   to	   break	   out	   components	   reflecting	   rate	   and	   correlational	   coding	   is	  
illustrated	   in	   Figure	   3,	   by	   application	   to	   simulated	   spike	   trains	   with	   controlled	   correlation.	   This	   approach	  
has	  been	  used	  by	  a	  number	  of	  authors	  to	  dissect	  out	  contributions	  to	  neural	  coding	  (e.g.	  Scaglione	  et	  al.,	  
2008).	  
This	  approach	  extends	  naturally	  to	  the	  consideration	  of	  temporal	  correlations	  between	  spike	  times	  within	  a	  
spike	  train	  (Panzeri	  and	  Schultz,	  2001).	  Note	  that	  the	  Taylor	  series	  approach	  can	  be	  applied	  to	  the	  entropy	  
as	   well	   as	   the	   mutual	   information	   –	   this	   was	   used	   to	   break	   out	   the	   effect	   of	   spatiotemporal	   correlations	   on	  
the	   entropy	   of	   a	   small	   population	   of	   neural	   spike	   trains	   (Schultz	   and	   Panzeri,	   2001).	   While	   the	   Taylor	   series	  
approach	   can	   be	   extremely	   useful	   in	   teasing	   out	   contributions	   of	   different	   mechanisms	   to	   the	   transmission	  
of	  information,	  it	  is	  not	  recommended	  as	  a	  method	  for	  estimation	  of	  the	  total	  information,	  as	  the	  validity	  of	  
the	   approximation	   can	   break	   down	   quickly	   as	   the	   time	   window	   grows	   beyond	   that	   sufficient	   to	   contain	  
more	  than	  a	  few	  spikes	  from	  the	  population.	  It	  is	  however	  useful	  as	  an	  additional	  inspection	  tool	  after	  the	  
total	   information	   has	   been	   computed,	   which	   allows	   the	   information	   to	   be	   broken	   down	   into	   not	   only	  
mechanistic	   components	   but	   also	   their	   contributions	   from	   individual	   cells	   and	   time	   bins	   (for	   instance	   by	  
visualizing	  the	  quantity	  after	  the	  summations	  in	  Equation	  (10)	  as	  a	  matrix).	  
A	  more	  general	  information	  component	  analysis	  approach	  
A	   limitation	   of	   the	   Taylor	   series	   approach	   is	   that	   it	  is	   restricted	   to	   the	   analysis	   of	   quite	   short	   time	   windows	  
of	   neural	   responses.	   However,	   an	   exact	   breakdown	   approach	   allowed	   a	   very	   similar	   information	  
component	   approach	   to	   be	   used	   (Pola	  et	  al.,	  2003).	   In	   this	   approach,	   we	   consider	   a	   population	   response	  
(spike	  pattern)	  r,	  and	  define	  the	  normalized	  noise	  cross-­‐correlation	  to	  be	  

	  

⎧ P(r | s)
− 1 if Pind (r | s) ≠ 0
⎪
γ (r | s) = ⎨ Pind (r | s)
	  .	  
⎪
0
if Pind (r | s) = 0
⎩

(11)	  

	  where	  the	  marginal	  distribution	  
C

Pind (r | s) = ∏ P(rc | s) .

(12)	  	  

c=1

Compare	  the	  expressions	  in	  Equation	  (5)	  and	  (12).	  Similarly,	  the	  signal	  correlation	  becomes	  

	  

⎧
⎪
⎪
ν (r) = ⎨
⎪
⎪⎩

Pind (r)
− 1 if ∏ c P(rc ) ≠ 0
∏ P(rc )
c

0

	  .	  

(13)	  

if ∏ c P(rc ) = 0

Using	   these	   definitions,	   the	   information	   components	   can	   now	   be	   written	   exactly	   (without	   the	  
approximation	  of	  short	  time	  windows)	  as	  
	  

I lin = ∑ ∑ P(rc | s)log 2
c

rc

P(rc | s)
P(rc )

	  	  
s

(14)	  

	  

I sig-sim =

(15)	  

⎛ 1 ⎞
	  	  
I cor-ind = ∑ Pind (r | s)γ (r | s) s log 2 ⎜
⎝ 1+ ν (r) ⎟⎠
r

	  

	  

⎛
⎞⎡
⎛ 1 ⎞⎤
1
	  	  
P(rc )⎟ ⎢ν (r) + (1+ ν (r))ln ⎜
∑
∏
⎜
⎝ 1+ ν (r) ⎟⎠ ⎥⎦
⎠⎣
ln 2 r ⎝ c

I cor-dep = ∑ Pind (r | s)(1+ γ (r | s))log 2
r

(16)	  

Pind (r | s ') s ' (1+ γ (r | s))

Pind (r | s ')(1+ γ (r | s '))

s'

	  .	  

(17)	  

s

This	  latter	  component	  is	  identical	  to	  the	  quantity	  “ ΔI ”	  introduced	  by	  Latham	  and	  colleagues	  (Nirenberg	  et	  
al.,	   2001)	   to	   describe	   the	   information	   lost	   due	   to	   a	   decoder	   ignoring	   correlations.	   It	   is	   zero	   if	   and	   only	   if	  

P(s | r) = Pind (s | r) 	  for	  every	  s	  and	  r.	  	  
The	   expressions	   shown	   above	   are	   perhaps	   the	   most	   useful	   description	   for	   obtaining	   insight	   into	   the	  
behavior	  of	  the	  information	  components	  under	  different	  statistical	  assumptions	  relating	  to	  the	  neural	  code,	  
however	   they	   are	   not	   necessarily	   the	   best	   way	   to	   estimate	   the	   individual	   components.	   However,	   the	  
components	   can	   also	   be	   written	   as	   a	   sum	   of	   entropies	   and	   entropy-­‐like	   quantities,	   which	   can	   then	   be	  
computed	   using	   the	   entropy	   estimation	   algorithms	   described	   earlier	   in	   this	   chapter	   (Pola	   et	   al.,	   2003;	  
Montani	  et	  al.,	  2007;	  Schultz	  et	  al.,	  2009).	  Note	  that,	  as	  shown	  by	  Scaglione	  and	  colleagues	  (Scaglione	  et	  al.,	  
2008,	  2010)	  the	  components	  in	  Eq.	  (14-­‐17)	  can,	  under	  appropriate	  conditions,	  be	  further	  decomposed	  to	  
tease	  apart	  the	  relative	  role	  of	  autocorrelations	  (spikes	  from	  the	  same	  cells)	  and	  cross-­‐correlations	  (spikes	  
from	  different	  cells).	  	  
Maximum	  entropy	  approach	  to	  information	  component	  analysis	  
The	  conceptual	  basis	  of	  the	  information	  component	  approach	  is	  to	  make	  an	  assumption	  that	  constrains	  the	  
statistics	  of	  the	  response	  distribution	  P(r|s),	  compute	  the	  mutual	  information	  subject	  to	  this	  assumption,	  
and	  by	  evaluating	  the	  difference	  between	  this	  and	  the	  “full”	  information,	  calculate	  the	  contribution	  to	  the	  
information	   of	   relaxing	   this	   constraint.	   By	   making	   further	   assumptions,	   the	   contributions	   of	   additional	  
mechanisms	   can	   in	   many	   cases	   be	   dissected	   out	   hierarchically.	   As	   an	   example,	   by	   assuming	   that	   the	  
conditional	  distribution	  of	  responses	  given	  stimuli	  is	  equal	  to	  the	  marginal	  distribution	   P(r | s) = Pind (r | s) ,	  
and	   substituting	   in	   to	   the	   mutual	   information	   equation,	   one	   can	   define	   an	   information	   component	   Iind.	   This	  
component	  can	  then	  be	  further	  broken	  up	  
	  

I ind = I lin + I sig-sim 	  ,	  

(18)	  

with	   Ilin	   and	   Isig-­‐sim	   as	   defined	   in	   the	   previous	   section.	   The	   correlational	   component,	   Icor,	   is	   then	   just	   the	  
difference	  between	  Iind	  and	  the	  total	  mutual	  information.	  This	  can	  also	  be	  further	  broken	  up,	  as	  
	  

I cor = I cor-ind + I cor-dep 	  .	  

(19)	  

This	   approach	   can	   be	   extended	   further.	   For	   instance,	   the	   assumption	   of	   a	   Markov	   approximation	   can	   be	  
made,	  with	  a	  memory	  extending	  back	  q	  timesteps,	  and	  the	  information	  computed	  under	  this	  assumption	  
(Pola	   et	   al.,	   2005).	   More	   generally,	   any	   simplified	   model	   can	   be	   used,	   although	   the	   maximum	   entropy	  
models	  are	  of	  special	  interest	  (Montemurro	  et	  al.,	  2007;	  Schaub	  and	  Schultz,	  2012)	  

	  

Psimp (r | s) =

m
⎧
⎫
1
exp ⎨λ0 − 1+ ∑ λi gi (r) ⎬ 	  	  
Z
i=1
⎩
⎭

(20)	  

with	   parameters	   λi 	  implementing	   a	   set	   of	   constraints	   reflecting	   assumptions	   made	   about	   what	   are	   the	  
important	   (non-­‐noise)	   properties	   of	   the	   empirical	   distribution,	   and	   the	   partition	   function	   Z	   ensuring	  
normalisation.	   An	   example	   of	   this	   is	   the	   Ising	   model,	   which	   has	   been	   used	   with	   some	   success	   to	   model	  
neural	  population	  response	  distributions	  (Schneidman	  et	  al.,	  2006;	  Shlens	  et	  al.,	  2006;	  Schaub	  and	  Schultz,	  
2012).	   Estimation	   of	   the	   Ising	   model	   for	   large	   neural	   populations	   can	   be	   extremely	   computationally	  
intensive	   if	   brute	   force	   methods	   for	   computing	   the	   partition	   function	   are	   employed,	   however	   mean	   field	  
approximations	   can	   be	   employed	   in	   practice	   with	   good	   results	   (Roudi	   et	   al.,	   2009;	   Schaub	   and	   Schultz,	  
2012).	  

Binless	  methods	  for	  estimating	  information	  
In	   applications	   in	   neuroscience,	   typically	   at	   least	   one	   of	   the	   random	   variables	   (stimuli	   or	   responses)	   is	  
discrete,	  and	  thus	  the	  approach	  of	  discretizing	  one	  or	  more	  of	  the	  variables	  is	  often	  taken.	  However,	  where	  
stimuli	  and	  responses	  are	  both	  continuous	  (an	  example	  might	  be	  local	  field	  potential	  responses	  to	  a	  white	  
noise	   sensory	   stimulus),	   it	   may	   be	   advantageous	   to	   take	   advantages	   of	   techniques	   better	   suited	   to	  
continuous	   signals,	   such	   as	   kernel	   density	   estimators	   (Moon	   et	   al.,	   1995),	   nearest	   neighbor	   estimators	  
(Kraskov	   et	   al.,	   2004)	   or	   binless	   metric	   space	   methods	   (Victor,	   2002).	   We	   refer	   to	   the	   entry	   “Bin-­‐Less	  
Estimators	  for	  Information	  Quantities”	  for	  an	  in-­‐depth	  discussion	  of	  these	  techniques.	  	  

Calculation	  of	  information	  theoretic	  quantities	  from	  parametric	  models	  
An	  alternative	  to	  measuring	  information-­‐theoretic	  quantities	  directly	  from	  observed	  data	  is	  to	  fit	  the	  data	  
to	   a	   model,	   and	   then	   to	   either	   analytically	   or	   numerically	   (depending	   upon	   the	   complexity	   of	   the	   model)	  
compute	   the	   information	   quantity	   from	   the	   model.	   Examples	   include	   analytical	   calculations	   of	   the	  
information	  flow	  through	  models	  of	  neural	  circuits	  with	  parameters	  fit	  to	  anatomical	  and	  physiological	  data	  
(Treves	   and	   Panzeri,	   1995;	   Schultz	   and	   Treves,	   1998;	   Schultz	   and	   Rolls,	   1999),	   and	   parametric	   fitting	   of	  
probabilistic	   models	   of	   neural	   spike	   firing	   (Paninski,	   2004;	   Pillow	   et	   al.,	   2005,	   2008),	   of	   spike	   count	  
distributions	   (Gershon	   et	   al.,	   1998;	   Clifford	   and	   Ibbotson,	   2000),	   or	   of	   neural	   mass	   signals	   (Magri	   et	   al.,	  
2009).	  It	  should	  come	  as	  no	  surprise	  that	  “there	  is	  no	  free	  lunch”,	  and,	  although	  in	  principle	  information	  
quantities	  can	  be	  computed	  exactly	  under	  such	  circumstances,	  the	  problem	  is	  moved	  to	  one	  of	  assessing	  
model	  validity	  –	  an	  incorrect	  model	  can	  lead	  to	  a	  bias	  in	  either	  direction	  in	  the	  information	  computed.	  

Acknowledgements	  
Research	   supported	   	  by	   the	   SI-­‐CODE	   (FET-­‐Open,	   FP7-­‐284533)	   project	   and	   by	   the	   	  ABC	   and	   NETT	   (People	  
Programme	   	  Marie	  	   Curie	  	   Actions	  PITN-­‐GA-­‐2011-­‐290011	   and	   PITN-­‐GA-­‐2011-­‐289146)	  	   projects	  
of	  	  the	  	  European	  	  Union's	  Seventh	  Framework	  	  Programme	  	  FP7	  2007-­‐2013.	  

References	  
Arabzadeh	   E,	   Panzeri	   S,	   Diamond	   ME	   (2004)	   Whisker	   Vibration	   Information	   Carried	   by	   Rat	   Barrel	   Cortex	  
Neurons.	  J	  Neurosci	  24:6011–6020.	  

Brenner	   N,	   Strong	   SP,	   Koberle	   R,	   Bialek	   W,	   Steveninck	   RRR	   (2000)	   Synergy	   in	   a	   neural	   code.	   Neural	   Comput	  
12:1531–1552.	  
Clifford	  CW	  g.,	  Ibbotson	  MR	  (2000)	  Response	  variability	  and	  information	  transfer	  in	  directional	  neurons	  of	  
the	  mammalian	  horizontal	  optokinetic	  system.	  Vis	  Neurosci	  17:207–215.	  
Gershon	   ED,	   Wiener	   MC,	   Latham	   PE,	   Richmond	   BJ	   (1998)	   Coding	   Strategies	   in	   Monkey	   V1	   and	   Inferior	  
Temporal	  Cortices.	  J	  Neurophysiol	  79:1135–1144.	  
Ince	  RAA,	  Mazzoni	  A,	  Bartels	  A,	  Logothetis	  NK,	  Panzeri	  S	  (2012)	  A	  novel	  test	  to	  determine	  the	  significance	  of	  
neural	   selectivity	   to	   single	   and	   multiple	   potentially	   correlated	   stimulus	   features.	   J	   Neurosci	  
Methods	  210:49–65.	  
Ince	  RAA,	  Mazzoni	  A,	  Petersen	  RS,	  Panzeri	  S	  (2010)	  Open	  source	  tools	  for	  the	  information	  theoretic	  analysis	  
of	  neural	  data.	  Front	  Neurosci	  4:62–70.	  
Kennel	   MB,	   Shlens	   J,	   Abarbanel	   HDI,	   Chichilnisky	   E	   (2005)	   Estimating	   entropy	   rates	   with	   Bayesian	  
confidence	  intervals.	  Neural	  Comput	  17:1531–1576.	  
Kraskov	  A,	  St\ögbauer	  H,	  Grassberger	  P	  (2004)	  Estimating	  mutual	  information.	  Phys	  Rev	  E	  69:66138.	  
Magri	  C,	  Whittingstall	  K,	  Singh	  V,	  Logothetis	  NK,	  Panzeri	  S	  (2009)	  A	  toolbox	  for	  the	  fast	  information	  analysis	  
of	  multiple-­‐site	  LFP,	  EEG	  and	  spike	  train	  recordings.	  BMC	  Neurosci	  10:81.	  
Miller	  G	  (1955)	  Note	  on	  the	  bias	  of	  information	  estimates.	  Inf	  Theory	  Psychol	  Probl	  Methods:95–100.	  
Montani	  F,	  Kohn	  A,	  Smith	  MA,	  Schultz	  SR	  (2007)	  The	  Role	  of	  Correlations	  in	  Direction	  and	  Contrast	  Coding	  
in	  the	  Primary	  Visual	  Cortex.	  J	  Neurosci	  27:2338.	  
Montemurro	  MA,	  Senatore	  R,	  Panzeri	  S	  (2007)	  Tight	  Data-­‐Robust	  Bounds	  to	  Mutual	  Information	  Combining	  
Shuffling	  and	  Model	  Selection	  Techniques.	  Neural	  Comput	  19:2913–2957.	  
Moon	   YI,	   Rajagopalan	   B,	   Lall	   U	   (1995)	   Estimation	   of	   mutual	   information	   using	   kernel	   density	   estimators.	  
Phys	  Rev	  E	  52:2318.	  
Nemenman	  I,	  Bialek	  W,	  de	  Ruyter	  van	  Steveninck	  R	  (2004)	  Entropy	  and	  information	  in	  neural	  spike	  trains:	  
Progress	  on	  the	  sampling	  problem.	  Phys	  Rev	  E	  69:56111.	  
Nemenman	  I,	  Lewen	  GD,	  Bialek	  W,	  de	  Ruyter	  van	  Steveninck	  RR	  (2008)	  Neural	  Coding	  of	  Natural	  Stimuli:	  
Information	  at	  Sub-­‐Millisecond	  Resolution.	  PLoS	  Comput	  Biol	  4:e1000025.	  
Nemenman	   I,	   Shafee	   F,	   Bialek	   W	   (2002)	   Entropy	   and	   Inference,	   Revisited.	   Adv	   Neural	   Inf	   Process	   Syst	   14	  
Proc	  2002	  Sic	  Conf	  14:95–100.	  
Nirenberg	   S,	   Carcieri	   SM,	   Jacobs	   AL,	   Latham	   PE	   (2001)	   Retinal	   ganglion	   cells	   act	   largely	   as	   independent	  
encoders.	  Nature	  411:698–701.	  
Paninski	  L	  (2004)	  Estimating	  Entropy	  on	  Bins	  Given	  Fewer	  Than	  Samples.	  IEEE	  Trans	  Inf	  Theory	  50:2201.	  
Panzeri	   S,	   Schultz	   SR	   (2001)	   A	   unified	   approach	   to	   the	   study	   of	   temporal,	   correlational,	   and	   rate	   coding.	  
Neural	  Comput	  13:1311–1349.	  

Panzeri	   S,	   Schultz	   SR,	   Treves	   A,	   Rolls	   ET	   (1999)	   Correlations	   and	   the	   encoding	   of	   information	   in	   the	   nervous	  
system.	  Proc	  Biol	  Sci	  266:1001–1012.	  
Panzeri	   S,	   Senatore	   R,	   Montemurro	   MA,	   Petersen	   RS	   (2007)	   Correcting	   for	   the	   Sampling	   Bias	   Problem	   in	  
Spike	  Train	  Information	  Measures.	  J	  Neurophysiol	  98:1064–1072.	  
Panzeri	   S,	   Treves	   A	   (1996)	   Analytical	   estimates	   of	   limited	   sampling	   biases	   in	   different	   information	  
measures.	  Netw	  Comput	  Neural	  Syst	  7:87–107.	  
Pillow	   JW,	   Paninski	   L,	   Uzzell	   VJ,	   Simoncelli	   EP,	   Chichilnisky	   E	   (2005)	   Prediction	   and	   decoding	   of	   retinal	  
ganglion	  cell	  responses	  with	  a	  probabilistic	  spiking	  model.	  J	  Neurosci	  25:11003–11013.	  
Pillow	   JW,	   Shlens	   J,	   Paninski	   L,	   Sher	   A,	   Litke	   AM,	   Chichilnisky	   E,	   Simoncelli	   EP	   (2008)	   Spatio-­‐temporal	  
correlations	  and	  visual	  signalling	  in	  a	  complete	  neuronal	  population.	  Nature	  454:995–999.	  
Pola	   G,	   Petersen	   RS,	   Thiele	   A,	   Young	   MP,	   Panzeri	   S	   (2005)	   Data-­‐robust	   tight	   lower	   bounds	   to	   the	  
information	  carried	  by	  spike	  times	  of	  a	  neuronal	  population.	  Neural	  Comput	  17:1962–2005.	  
Pola	  G,	  Thiele	  A,	  Hoffmann	  KP,	  Panzeri	  S	  (2003)	  An	  exact	  method	  to	  quantify	  the	  information	  transmitted	  
by	  different	  mechanisms	  of	  correlational	  coding.	  Netw	  Comput	  Neural	  Syst	  14:35–60.	  
Roudi	   Y,	   Aurell	   E,	   Hertz	   J	   (2009)	   Statistical	   physics	   of	   pairwise	   probability	   models.	   Arxiv	   Prepr	  
ArXiv09051410.	  
Scaglione	  A,	  Foffani	  G,	  Scannella	  G,	  Cerutti	  S,	  Moxon	  K	  (2008)	  Mutual	  information	  expansion	  for	  studying	  
the	  role	  of	  correlations	  in	  population	  codes:	  How	  important	  are	  autocorrelations?	  Neural	  Comput	  
20:2662–2695.	  
Scaglione	   A,	   Moxon	   KA,	   Foffani	   G	   (2010)	   General	   Poisson	   Exact	   Breakdown	   of	   the	   Mutual	   Information	   to	  
Study	  the	  Role	  of	  Correlations	  in	  Populations	  of	  Neurons.	  Neural	  Comput	  22:1445–1467.	  
Schaub	   MT,	   Schultz	   SR	   (2012)	   The	   Ising	   decoder:	   reading	   out	   the	   activity	   of	   large	   neural	   ensembles.	   J	  
Comput	  Neurosci	  32:101–118.	  
Schneidman	  E,	  Berry	  II	  MJ,	  Segev	  R,	  Bialek	  W	  (2006)	  Weak	  pairwise	  correlations	  imply	  strongly	  correlated	  
network	  states	  in	  a	  neural	  population.	  Nature	  440:1007–1012.	  
Schultz	   S,	   Treves	   A	   (1998)	   Stability	   of	   the	   replica-­‐symmetric	   solution	   for	   the	   information	   conveyed	   by	   a	  
neural	  network.	  Phys	  Rev	  E	  57:3302–3310.	  
Schultz	   SR,	   Kitamura	   K,	   Post-­‐Uiterweer	   A,	   Krupic	   J,	   Häusser	   M	   (2009)	   Spatial	   Pattern	   Coding	   of	   Sensory	  
Information	   by	   Climbing	   Fiber-­‐Evoked	   Calcium	   Signals	   in	   Networks	   of	   Neighboring	   Cerebellar	  
Purkinje	  Cells.	  J	  Neurosci	  29:8005–8015.	  
Schultz	   SR,	   Panzeri	   S	   (2001)	  Temporal	  Correlations	  and	  Neural	  Spike	  Train	  Entropy.	  Phys	  Rev	  Lett	  86:5823–
5826.	  
Schultz	   SR,	   Rolls	   ET	   (1999)	   Analysis	   of	   information	   transmission	   in	   the	   Schaffer	   collaterals.	   Hippocampus	  
9:582–598.	  
Sharpee	  T,	  Rust	  NC,	  Bialek	  W	  (2004)	  Analyzing	  Neural	  Responses	  to	  Natural	  Signals:	  Maximally	  Informative	  
Dimensions.	  Neural	  Comput	  16:223–250.	  

Shlens	  J,	  Field	  GD,	  Gauthier	  JL,	  Grivich	  MI,	  Petrusca	  D,	  Sher	  A,	  Litke	  AM,	  Chichilnisky	  EJ	  (2006)	  The	  Structure	  
of	  Multi-­‐Neuron	  Firing	  Patterns	  in	  Primate	  Retina.	  J	  Neurosci	  26:8254–8266.	  
Shlens	   J,	   Kennel	   MB,	   Abarbanel	   HDI,	   Chichilnisky	   E	   (2007)	   Estimating	   information	   rates	   with	   confidence	  
intervals	  in	  neural	  spike	  trains.	  Neural	  Comput	  19:1683–1719.	  
Skaggs	   WE,	   McNaughton	   BL,	   Gothard	   KM	   (1993)	   An	   Information-­‐Theoretic	   Approach	   to	   Deciphering	   the	  
Hippocampal	   Code.	   In:	   Advances	   in	   Neural	   Information	   Processing	   Systems	   5,	   [NIPS	   Conference],	  
pp	   1030–1037.	   San	   Francisco,	   CA,	   USA:	   Morgan	   Kaufmann	   Publishers	   Inc.	   Available	   at:	  
http://dl.acm.org/citation.cfm?id=645753.668057	  [Accessed	  January	  17,	  2014].	  
Strong	  SP,	  Koberle	  R,	  de	  Ruyter	  van	  Steveninck	  RR,	  Bialek	  W	  (1998)	  Entropy	  and	  Information	  in	  Neural	  Spike	  
Trains.	  Phys	  Rev	  Lett	  80:197–200.	  
Treves	  A,	  Panzeri	  S	  (1995)	  The	  Upward	  Bias	  in	  Measures	  of	  Information	  Derived	  from	  Limited	  Data	  Samples.	  
Neural	  Comput	  7:399–407.	  
Victor	  J	  (2006)	  Approaches	  to	  information-­‐theoretic	  analysis	  of	  neural	  activity.	  Biol	  Theory	  1:302–316.	  
Victor	   JD	   (2002)	   Binless	   strategies	   for	   estimation	   of	   information	   from	   neural	   data.	   Exp	   Brain	   Res	   Phys	   Rev	   E	  
66:051903.	  
	  
	  

	  

Figures	  and	  Figure	  Captions	  
	  

	  
Figure	   1:	   The	   origin	   of	   the	   limited	   sampling	   bias	   in	   information	   measures.	   	   (A,	   B)	   Simulation	   of	   a	   toy	  
uninformative	  neuron,	  responding	  on	  each	  trial	  with	  a	  uniform	  distribution	  of	  spike	  counts	  ranging	  from	  0	  
to	   9,	   regardless	   of	   which	   of	   two	   stimuli	   (S	   =	   1	   in	   (A)	   and	   S	   =	   2	   in	   (B))	   are	   presented.	   The	   black	   dotted	  
horizontal	   line	   is	   the	   true	   response	   distribution,	   solid	   red	   lines	   are	   estimates	   sampled	   from	   40	   trials.	   The	  
limited	  sampling	  causes	  the	  appearance	  of	  spurious	  differences	  in	  the	  two	  estimated	  conditional	  response	  
distributions,	   leading	   to	   an	   artificial	   positive	   value	   of	   mutual	   information.	   (C)	   The	   distribution	   (over	   5000	  
simulations)	  of	  the	  mutual	  information	  values	  obtained	  (without	  using	  any	  bias	  correction)	  estimating	  Eq.	  1	  
from	  the	  stimulus–response	  probabilities	  computed	  with	  40	  trials.	  The	  dashed	  green	  vertical	  line	  indicates	  
the	   true	   value	   of	   the	   mutual	   information	   carried	   by	   the	   simulated	   system	   (which	   equals	   0	   bits);	   the	  
difference	   between	   this	   and	   the	   mean	   observed	   value	   (dotted	   green	   line)	   is	   the	   bias.	   Redrawn	   with	  
permission	  from	  (Ince	  et	  al.,	  2010).	  
	  

	  

Ish

I
1.4
plugin
nsb
pt
qe

1.2
1

Information (bits)

Information (bits)

1.4

0.8
0.6
0.4

1.2
1
0.8
0.6
0.4

4

6

8
10
12
log2 trials/stim

14

4

6

0.8

0.6

0.6

0.4
0.2
0

14

Ish

0.8

RMS error

RMS error

I

8
10
12
log2 trials/stim

0.4
0.2

4

6

8

10
12
log2 trials/stim

14

0

4

6

8
10
12
log2 trials/stim

14

	  

Figure	  2:	   Performance	   of	   various	   bias	   correction	   methods.	   Several	   bias	   correction	   methods	   were	   applied	   to	  
spike	   trains	   from	   eight	   simulated	   somatosensory	   cortical	   neurons.	   The	   information	   estimates	   (upper	  
panels)	  and	  root	  mean	  square	  (RMS)	  error	  (lower	  panels)	  are	  plotted	  as	  a	  function	  of	  the	  simulated	  number	  
of	  trials	  per	  stimulus.	  (A)	  Mean	  +/-­‐	  SD	  (upper	  panel;	  over	  50	  simulations)	  and	  RMS	  error	  (lower	  panel)	  of	  
I(S;R).	  (B)	  Mean	  +/-­‐	  SD	  (upper	  panel;	  over	  50	  simulations)	  and	  RMS	  error	  (lower	  panel)	  of	  Ish(S;R).	  
	  

	  

Figure	   3.	   Information	   component	   analysis	   of	   simulated	   data	   (for	   a	   five-­‐cell	   ensemble).	   (a)	   Poisson	   cells,	  
with	   the	   only	   difference	   between	   the	   stimuli	   being	   firing	   rate.	   (b)	   Integrate-­‐and-­‐fire	   cells,	   with	   common	  
input	  due	  to	  sharing	  of	  one	  third	  of	  connections,	  resulting	  in	  a	  cross-­‐correlogram	  as	  depicted,	  leads	  to	  (c)	  
contribution	  to	  the	  information	  from	  Icor-­‐ind.	  (d)	  Integrate-­‐and-­‐fire	  cells	  with	  two	  of	  the	  five	  cells	  increasing	  
their	  correlation	  due	  to	  increased	  shared	  input,	  for	  one	  of	  the	  stimuli,	  where	  the	  others	  remain	  randomly	  
correlated,	   leading	   to	   cross-­‐correlograms	   shown	   in	   panel	   (e).	   Firing	   rates	   are	   approximately	   balanced	  
between	   the	   two	   stimuli.	   This	   results	   in	   a	   substantial	   contribution	   to	   the	   information	   from	   the	   stimulus-­‐
dependent	  correlation	  component,	  Icor-­‐dep.	  From	  (Panzeri	  et	  al.,	  1999)	  with	  permission.	  
	  

