Assessing node risk and vulnerability in epidemics on networks
T. Rogers

arXiv:1502.00901v1 [physics.soc-ph] 3 Feb 2015

Centre for Networks and Collective Behaviour - University of Bath, Bath, BA2 7AY, UK
Which nodes are most vulnerable to an epidemic spreading through a network, and which carry
the highest risk of causing a major outbreak if they are the source of the infection? Here we show
how these questions can be answered to good approximation using the cavity method. Several
curious properties of node vulnerability and risk are explored: some nodes are more vulnerable than
others to weaker infections, yet less vulnerable to stronger ones; a node is always more likely to be
caught in an outbreak than it is to start one, except when the disease has a deterministic lifetime;
the rank order of node risk depends on the details of the distribution of infectious periods.

I.

INTRODUCTION

Network structure has a profound influence over disease dynamics. There is growing acknowledgement of this
fact in the epidemiology literature (see [10] for a review),
where the question of how best to quantify and predict
network effects is becoming a central challenge [21]. At
the same time, network epidemic models are of considerable interest to the theoretical physics community [19],
serving as a canonical example of a non-equilibrium process, and providing fertile ground for the application of
statistical mechanics techniques to new and interesting
problems. One such technique is the cavity method: invented to tackle problems in statistical inference [20] and
condensed matter physics [17], this simple and versatile
method has found application in areas as diverse as computer science [18] and random matrix theory [23, 24].
The cavity method was first applied to epidemiology in
[9] (using the alternative moniker of ‘message-passing’),
to calculate the expected time development of a network
epidemic. The principle advance provided by the method
in that work was the ability to model non-Markov epidemics, in which the time that a node remains infective
(the lifetime distribution, or infectious period) is not a
simple memoryless exponential distribution. Under a second alias of ‘belief-propagation’, it has also been applied
to the problem of tracing the most likely source of a disease outbreak [1]. This work points to another advantage
offered by the cavity method; that it is not restricted to
calculating macroscopic quantities, but can provide information about the behaviour of individual nodes. Indeed,
it is now well-recognised that population heterogeneity
can play a very important role in disease outbreaks [14].
In this article, we show how to calculate a measure
of the infection risk that a particular node poses to the
network, as well as the risk posed by the network to the
node. These quantities are manifested in two different
realisations of the cavity method, one with ‘upstream’
cavities, the other ‘downstream’. The derivation of the
cavity equations for the risk and vulnerability measures
is given in the next section, followed by a discussion of
their numerical solution. We then address the role of the
lifetime distribution of the disease, which controls the
probability of an outbreak occurring, but paradoxically
has no effect on its final size. Finally, we show how the

Upstream:
Risk of causing
an oubreak

Network Bulk
Downstream:
Vulnerability to
ongoing outbreaks

FIG. 1: Imagining the progress of the disease as a flow through
the network, (6) considers the onward spread after removing
an upstream neighbour (i.e. closer to the source of the infection), whilst (8) considers the chance of infection with a
downstream neighbour removed. In both cases the tree approximation amounts to assuming that the up- and downstream neighbours are uniquely defined.

cavity method can be used to rank nodes according to
their risk or vulnerability, and how these rankings exhibit
curious dependencies on the disease dynamics.

II.

CAVITY METHOD FOR RISK AND
VULNERABILITY

Consider the spread of a disease over the nodes of a
network. In a small period of time dt each infected node
has a chance β dt of transmitting the infection to an uninfected neighbour, and a chance γ(t) dt of recovering from
the disease. Recovered nodes cannot be reinfected. This
is an SIR epidemic with Poisson rate infections (β is a
positive constant) and general disease lifetime distribution γ(t).
Write ri for the risk that a major outbreak occurs if
node i is the sole initial infective. Thinking about the
limit of very large networks, we make an artificial distinction between the local area around node i, and the
rest of the network, which we call the ‘bulk’. We will say
a major outbreak occurs if node i succeeds in transmitting the infection a to non-zero fraction of the bulk. To
compute an approximation to this quantity, we examine
the spread of the disease away from the initial infection.

2
We begin by calculating the probability that i infects
all the vertices in some subset J of its neighbours N (i),
and no others. The fates of these nodes are correlated by
their joint exposure to the random length of the infectious
period of i; a long infectious period implies that nearly
all neighbours will catch the disease, and the opposite
holds if i is infectious only for a very short time. If the
infectious period has probability density γ(t), then we
may write
Z ∞
Y
Y
e−βt dt
P(i → J) =
γ(t)
(1 − e−βt )
0

=

Z

j∈J

j∈N (i)\J

∞

γ(t)(1 − e

−βt |J| −βt(|N (i)|−|J|)

)

e

(1)

dt .

0

After i has infected some of its neighbours, the continued survival of the disease depends on those neighbours
propagating the infection away from i. Summing over all
possible collections of infected neighbours we find
X
(i)
P(i → J) (1 − rJ ) ,
(2)
ri = 1 −
J⊂N (i)

(i)

where rJ is the probability of a major outbreak in a
network where each j ∈ J is initially infected, and node i
has been removed. In words, this equation says that the
disease starting at i dies out if, whenever i infects a set
J, the disease starting at J also dies out.
(i)
(i)
The task now is to express rJ in terms of the rj .
If the network contains cycles, then some nodes will be
reachable from two or more members of J, yet only at
most one can succeed in passing the infection. This gives
rise to the inequality
Y
(i)
(i)
1 − rJ ≥
(3)
(1 − rj ) .
j∈J

To compute a lower bound on ri it will therefore suffice
to assume equality in (3). This approximation is equivalent to assuming that the network is large and tree-like.
As we will see, the results remain surprisingly accurate
for networks which do not fit this assumption very well.
Indeed the “unreasonable effectiveness” of tree approximations appears to be a quite general phenomenon for
network processes [16].
Inserting (1) and (3) into (2) and assuming equality
we can compute
Z ∞
Y 
 (i) 
dt
1 − 1 − e−βt rj
ri = 1 −
γ(t)
0

=1−

X

j∈N (i)

(−1)|J| T|J|

Y

(i)

(4)

rj ,

j∈J

J⊂N (i)

where
Tn =

Z

0

∞

γ(t)(1 − e−βt )n dt .

(5)

The problem of computing the risk to the network
posed by node i has thus been transformed in to that
of computing the risk posed by the neighbours of i in the
(i)
cavity graph. Repeating the same calculations for rj
allows us to derive a closed set of equations
Y (j)
X
(i)
(−1)|L| T|L|
rl ,
∀i, j. (6)
rj = 1 −
l∈L

L⊂N (j)\i

These are the upstream cavity equations. The derivation
requires the additional assumption that the risk posed
by l in the network with i and j both removed is well(j)
approximated by rl , that is, we ignore any alternative
path between l and i. If we are able to solve these equations (more on this later), the results can be fed into
equation (4) to provide us with an estimate of the probability of any given node causing a major outbreak.
We may also ask how vulnerable node i is to an outbreak that starts somewhere else in the network. Write
vi for the probability that i is eventually infected in the
event of a major outbreak. To compute the cavity approximation for vulnerability, we trace the possible path
of the disease downstream from the bulk to node i. The
calculation is somewhat easier in this case, since each
neighbour of i has an independent chance to attempt to
infect it. This means that the detail of the distribution
of infectious periods no longer matters, only the overall
chance of an infection, T1 (known as the transmissibility).
The result, previously derived in [9], is
Y
(i)
(7)
(1 − T1 vj ) ,
vi = 1 −
j∈N (i)

where the downstream cavity equations are
Y
(j)
(i)
(1 − T1 vl ) ,
∀i, j.
vj = 1 −

(8)

l∈N (j)\i

The distinction between the up- and downstream cavity equations should hopefully be clear: see Figure 1 for a
cartoon illustration. It should also be noted that there is
a close relationship between the cavity equations, and the
equation for survival probability of a multi-type branching process [2]. This should not be surprising as the
cavity equations are derived from considerations of the
early development of the epidemic, where the branching
process approximation is known to apply [3].

III.

ITERATION AND PERCOLATION

Typically, non-trivial solutions to the cavity equations
in either direction cannot be found by hand. Fortunately,
for general networks the cavity equations are stable under
iteration and can be numerically solved to high accuracy
with little computational cost. To do this efficiently, it is
helpful to map to a new network encoding the relations
between edges in the cavity equations. Each undirected

3

FIG. 2: Illustration of the non-backtracking network (dark,
directed network) for a simple four-node network (pale, undirected network). Each edge in the underlying network spawns
a pair of new nodes, one for each possible direction of infection, which are linked if they appear in the cavity equations.

edge (i, j) spawns two nodes, (i → j) and (j → i). Between two nodes e = (i → j) and e′ = (i′ → j ′ ) in the
(i′ )
new network, we draw a directed edge from e to e′ if rj ′
(i)

is involved in the cavity equation for rj , that is, if i′ = j
and j ′ ∈ N (j) \ i.
The adjacency matrix B of this network is known as
the non-backtracking, or Hashimoto [7], matrix. It has
recently been shown to be of use in spectral clustering
[12], and occurs in the calculation of the percolation
threshold in sparse networks [6, 8]. Using this construction, the upstream and downstream cavity equations can
be rewritten as
r = U (r) and v = D(v) ,
where U and D are the vector functions
Y
X
(−1)|E| T|E|
xe′ ,
Ue (x) = 1 −
E⊂N (e)

De (x) = 1 −

Y

e′ ∈E

(1 − T1 xe′ ) .

(9)

That is, rather than having the computer loop through
the subsets E ⊂ N (e) during each iteration step, an explicit iteration function can be procedurally generated
from (10) before starting the main loop.
Notice that the upstream and downstream equations
(9) both admit zero as a solution, since it is always possible that the disease fails to spread. For some parameter values, the zero solution is unstable and the cavity
equations admit a solution in (0, 1) corresponding to disease outbreak. The regimes of extinction and outbreak
are separated by a percolation phase transition, and the
critical parameter values can be determined by examining the stability of the maps U and D around zero. From
(10) we compute
X
∂Ue
I{e′ ∈E} (−1)|E| T|E|
=−
′
∂xe
E⊂N (e)

∂De
= T1 I{e′ ∈N (e)}
∂xe′

Y

Y

e′′ ∈E\e′

xe′′ ,
(11)

(1 − T1 xe′′ ) ,

e′′ ∈N (e)\e′

where I is the indicator function giving one for true arguments and zero for false. At the zero fixed point (xe = 0
for all e) we find that the Jacobian matrix is the same
for both systems,


∂Ue 
∂De 
(12)
=
= T1 Be,e′ ,
∂xe′ x=0 ∂xe′ x=0

where B is the non-backtracking matrix. Major outbreaks are therefore only possible if T1 > Tc =
1/|λmax (B)|, where Tc is the critical value for the percolation transition. Note that the transition point is the
same for all nodes, regardless of any heterogeneity in the
network. As shown in [6, 8], the role of λmax (B) is a general result for percolation processes on sparse networks.
IV.

THE ROLE LIFETIME DISTRIBUTION

(10)

e′ ∈N (e)

Starting from the initial vector xe = 1 for all e, solutions
to (9) can be found by repeatedly applying the maps U or
n
D. For n ≥ 1, the quantity D(i→j)
(1) describes the risk
that the disease spreads at least distance n from node j
n
(1) gives the
in the absence of node i. Similarly, U(i→j)
risk that j is infected if all nodes in the cavity network of
distance greater than n are themselves infected. Clearly
these quantities are decreasing with n and bounded from
below by zero, hence the iteration scheme is guaranteed
to converge.
For efficient numerical implementation, the integrals
(5) should of course be precomputed (indeed this can be
accomplished analytically whenever the Laplace transform of γ is known). It is possibly less obvious that often
a substantial speed-up can be gained by also precomputing the explicit form of cavity equations themselves.

As briefly mentioned earlier, although the probability
of a major outbreak occurring depends on the detail of
the lifetime distribution of the disease, the chance of a
particular node catching the disease does not. Two different diseases may have the same transmissibility T1 , but
one may be more dangerous than the other by virtue of
the fact that it is more likely to cause a major outbreak.
For fixed transmissibility, which lifetime distribution γ(t)
is the most dangerous?
To maximise the chance of an outbreak occurring, the
disease must guard against the possibility of it dying out
in the early stages of its spread. This is achieved by
having a deterministic infectious period



1
1
γ(t) = δ t − log
.
(13)
β
1 − T1
Mathematically, this follows from Jensen’s inequality.
Moving the power of n outside the integral in equation

4
1

1

0.8

0.8

0.6

0.6

vi

0.4

0.4

0.2
0
−2
10

0.2
−1

10

0

10
κ

1

0
0.25

2

10

10

0.5

0.75

1

1.25

1.5

1.75

β

FIG. 3: Outbreak probability and final size for epidemics
with β = 1 and Weibull-distributed lifetimes, on a random
4-regular network with N = 500 nodes. Thin dark lines show
the results of simulations for the fraction of outbreaks affecting more than 10% of the populations always (lower, purple)
and the average final size of those outbreaks (upper, green).
Fat pale lines correspond to the risk and vulnerability predictions of the cavity method. The dashed line shows the theoretical lower bound for risk, computed using equation (15).
The centre line κ = 1 corresponds to Markov dynamics.

n

(5) we find that for n ≥ 2 we have Tn ≥ (T1 ) . From the
cavity equations (6) we then deduce

Y 
(j)
(i)
,
1 − T1 rl
rj ≤ 1 −
(14)
l∈N (j)\i

with equality if and only if γ(t) is a delta function. This
result was mentioned in [25], and goes back to older work
using percolation theory [5].
We may also ask how low the probability of an outbreak can get when T1 is fixed. It follows immediately
from the definition (5) that the sequence {Tn } is positive
and decreasing. Thus


Y 
(j)
(i)
.
1 − rl
rj ≥ T1 1 −
(15)
l∈N (j)\i

This rough bound gives the intuition that the risk is minimal when the decay rate of {Tn } is also minimal. To
achieve this requires a lifetime distribution that is sharply
peaked at zero and has a heavy tail.
The Weibull family of distributions [26] describe the
time to failure in systems depending on several components, and are a natural choice to model non-Markov disease lifetime distributions (as used in [4], for example).
In fact, they nicely illustrate the full range of behaviours
between the upper and lower bounds given above. Figure 3 shows the results of simulations of epidemics
with
κ
Weibull-distributed lifetimes, γ(t) = κe−t t(κ−1) , where
the parameter κ controls the shape of the distribution.
The infection rate was held constant at β = 1 and the
same random 4-regular random network was used for
each sample. Small values of κ correspond to the hazard
rate of the disease getting smaller as it survives longer.
This makes the decay of {Tn } slower, and the outbreak
probability approaches its theoretical minimum. The

FIG. 4: node vulnerability as a function of β in a random network of N = 103 nodes with degrees five and three (in 50/50
ratio), generated by the configuration model, with Markov
(γ(t) = e−t ) disease dynamics. Grey lines show the result
of the cavity equations, with nodes number 10 and 75 highlighted in solid green and dashed blue, respectively. Circles
and diamonds show the results of stochastic simulations for
these two nodes, averaged over 104 samples.

special case κ = 1 corresponds to Markov disease dynamics (i.e. exponential lifetime distribution). For large
κ the Weibull distribution approaches a delta function
and risk is maximised.
Finally, we point out that the line for risk in Figure (3)
stays below the line for vulnerability. This is a general
fact. Notice that the right-hand-side of equation (14) exactly corresponds to the form of the downstream cavity
equations (8). We can conclude that vi provides an upper bound for ri . That is to say, the probability that
node i will cause a major outbreak if they are the source
is always less than their chance of being infected by an
outbreak that starts elsewhere.

V.

VULNERABILITY AND RISK RANKING

We know from the previous section that the vulnerability of a node always exceeds its risk, but how do the
risks and vulnerabilities of different nodes in the same
network compare? For a given network and choice of β
and γ(t), the cavity equations can be used to determine
ri and vi for every node, and this information may be
used to rank the nodes according to the risk they pose to
the network, or the risk the network poses to them. As
we will see, these rankings depend in detail on the nature
of the disease.
Let us begin by examining vulnerability ranking. node
vulnerability depends on the disease specification only
through T1 , so for simplicity we consider Markov dynamics, fixing γ(t) = e−t . To generate Figure 4, a single random network of N = 103 nodes was created using the
configuration model, and the vulnerability of its nodes
computed for various β using the cavity method. Two
things are immediately noticeable from the plot: (i) there
is a great deal of heterogeneity between nodes, and (ii)
the rank order of vulnerability is not preserved as β is

5

l∈N (i)\j

j∈N (i)

where ∂ is used as short-hand for ∂/∂T1 . Now, as T1 → 1
(i)
we have vj → 1 also, therefore the product above gives
zero unless it is empty. That is, ∂vi → 0 as T1 → 1 unless
i has only one neighbour. In general, the first non-zero
derivative of vi at T1 = 1 is
Y
(i) 
(17)
1 + ∂vj .
∂ |N (i)| vi = |N (i)|!
j∈N (i)

Similarly, we differentiate the downstream cavity equa(i)
tions (8) to find that, at T1 = 1, ∂vj is only nonzero if j has exactly one other neighbour l 6= i, in
(j)
(i)
which case ∂vj = 1 + ∂vl . Tracing a path away
from i in the direction of j we must eventually, after
Lij steps reach a node with degree not equal to two (recall that we ignore the possibility of cycles), whose cavity
derivative in eitherQcase will be zero. We conclude that
∂ |N (i)| vi = |N (i)|! j∈N (i) Lij .
Turning attention now to the percolation transition,
(j)
we set T1 = Tc , where we have vi = vi = 0. Therefore,
from (16),
X
X
X
(j)
(i)
T1 ∂vl = . . . .
T1
T1 ∂vj =
∂vi =
j∈N (i)

j∈N (i)

l∈N (j)\i

(18)
To make progress, let us suppose that there is some bulk
network B, which we assume has no special structure and
we have solved the cavity equations for that network. To
find the value of ∂vi , we must carry out the expansion
above for all paths p from i to the bulk B. We may write
X
∂vi ≈
Tc|p| ∂vB ,
(19)
p:i→B

where vB is the mean cavity vulnerability in the bulk.
Bringing the above results together, we have for each
node i a pair of expansions,
vi ≈ 1 − (1 − T1 )|N (i)|

Y

Lij ,

j∈N (i)

vi ≈ (T1 − Tc )

X

0.9

0.9

0.8
0.89

0.7
Relavtive Risk

0.6
Risk

varied. In particular, node 10 is more vulnerable than
node 75 to less virulent diseases, yet is less vulnerable to
more virulent ones.
To help explain this counter-intuitive finding, we explore the behaviour of the cavity equations near the limits of strongly infectious (T1 = 1) and weakly infectious (T1 = Tc ) diseases. Differentiating the vulnerability
equation (7) with respect to T1 , we have
Y
X
(i) 
(i) 
(i)
1 − T1 vl , (16)
vj + T1 ∂vj
∂vi =

0.5
0.4

0.88

0.87

0.3
0.2

0.86

0.1
0
−1
10

0

10

κ

1

10

0.85
−1
10

0

10

κ

1

10

FIG. 5: Left: node risk as a function of κ, with β varied so as
to hold constant T1 = 1/2. Each solid line corresponds to a
different node, shaded according to degree (lighter shades are
higher degree); the dashed line gives the mean risk r̄. Right:
close up of relative risk ri /r̄ for several nodes; crossing lines
correspond to changes in the risk ranking.

is mainly controlled by the number of neighbours a node
has, whereas vulnerability to weakly infectious diseases
depends more subtly on the number and length of paths
connecting the node to the infected bulk. The puzzling
case of nodes 10 and 75 in Figure 4 is explained thus:
node 75 has higher degree (five, compared to three), yet
is the source of just 91 paths of length three, compared
to 136 for node 10. We can therefore expect node 10 to
more vulnerable close to Tc , but less vulnerable for large
T1 .
As one might expect in light of the above, the ranking
of nodes according to their risk ri is also not preserved
under varying β. More interestingly, risk rankings are
additionally sensitive to the memory characteristics of
the disease. Figure 5 shows the result of the cavity equations in a random network with maximum degree five,
for Weibull distributed infectious periods with κ varying
across two orders of magnitude. This time β has also
been varied simultaneously in order to keep T1 fixed. Although node risk is broadly correlated with degree, this
is not a hard rule: there is considerable variation, and
many changes to the risk ranking occur as κ is varied
(even though node vulnerability does not change since
T1 is held constant). Curiously, Markov dynamics κ = 1
appear to represent an extreme case, with most nodes
experiencing either their highest or lowest relative risk
at that point.

VI.

CONCLUSION

(20)

Tc|p| ∂vB .

p:i→B

The qualitative insight provided by these equations is
the following: vulnerability to highly infectious diseases

In the work presented above we have seen how the
cavity method can be used to calculate measures of vulnerability and risk in network epidemic models. The vulnerability of a node to an ongoing outbreak is recovered
from the solution of the downstream cavity equations (8),

6
while the risk of an outbreak occurring with a given starting node is found by the upstream cavity equations (6).
Node vulnerability was found to be independent of the
details of the disease lifetime distribution, however, some
nodes are more vulnerable than others to weaker infections, yet less vulnerable to stronger ones. This fact can
be understood by an analysis of cavity equations with parameters in the neighbourhood of percolation and complete infection.
The story for node risk is even more complex, as it
depends on the memory characteristics of the disease
in a non-trivial way. In particular, we saw how risk is
maximised by diseases with deterministic lifetime distributions. This result suggests that real-world diseases,
which are subject to evolutionary pressure to optimise
their chance of spreading, should have infectious periods
that are much less variable than the equivalent exponential distribution, and indeed this appears to be the case
[13]. This dependence on disease memory also carries
over to the node risk rankings, as seen in Figure 5.
The main drawback of the method is, of course, the
reliance on a tree approximation. Although the method
has performed well for all the networks considered in this
article (despite most of them containing many cycles),
accurate predictions cannot be made for networks with
specific structure that favours the existence of cliques or
short cycles. This is a common problem in the study
of epidemics on networks, which is usually tackled via

‘moment closure’ methods for differential equations [11,
22]. Indeed an explicit link has been made between the
cavity method and a particular moment closure scheme
[27].
Looking to the future, three interesting questions remain unanswered: (i) why do node risk rankings depend
on the memory properties of the disease? (ii) why do
Markov dynamics extremise relative risk? (iii) how might
the results described here be modified in networks with
high local clustering? Beyond these problems, several
straightforward extensions to the work described here are
possible. One may choose to study non-Markov infection
rates, although this only has the effect of changing the
definition of Tn . More interestingly, fully time-dependent
cavity equations can be derived to give a more detailed
view of the disease progression (as was originally done for
vulnerability in [9]), and recent work has shown how the
method may be used to infer the origin of an outbreak
[15]. For added realism in applications, further heterogeneity can be introduced by allowing β and γ to vary
across the network. More generally, the cavity method
is widely applicable to other models of cascades on networks, for example, meme spread in social networks or
systemic risk in financial markets.
Acknowledgements
The author acknowledges funding from the Royal Society, and thanks Dick James, Nick Britton, Thomas House
and Reimer Kühn for useful discussions.

[1] Fabrizio Altarelli, Alfredo Braunstein, Luca Dall’Asta,
Alejandro Lage-Castellanos, and Riccardo Zecchina.
Bayesian inference of epidemics on networks via belief
propagation. Physical review letters, 112(11):118701,
2014.
[2] Krishna B Athreya and Peter E Ney. Branching processes. Springer, 1972.
[3] Frank Ball and Peter Donnelly. Strong approximations
for epidemic models. Stochastic processes and their applications, 55(1):1–21, 1995.
[4] Simon Cauchemez, Achuyt Bhattarai, Tiffany L Marchbanks, Ryan P Fagan, Stephen Ostroff, Neil M Ferguson,
David Swerdlow, Samir V Sodha, Mària E Moll, Frederick J Angulo, et al. Role of social networks in shaping disease transmission during a community outbreak of 2009
h1n1 pandemic influenza. Proceedings of the National
Academy of Sciences, 108(7):2825–2830, 2011.
[5] JT Cox and Richard Durrett. Limit theorems for the
spread of epidemics and forest fires. Stochastic processes
and their applications, 30(2):171–191, 1988.
[6] Kathleen E. Hamilton and Leonid P. Pryadko. Tight
lower bound for percolation threshold on an infinite
graph. Phys. Rev. Lett., 113:208701, 2014.
[7] K. Hashimoto. Zeta functions of finite graphs and representations of p-adic groups. Advanced Studies in Pure
Mathematics, 15:211280, 1989.
[8] Brian Karrer, M. E. J. Newman, and Lenka Zdeborová. Percolation on sparse networks. Phys. Rev. Lett.,
113:208702, 2014.

[9] Brian Karrer and MEJ Newman. Message passing approach for general epidemic models. Physical Review E,
82(1):016101, 2010.
[10] Matt J Keeling and Ken TD Eames. Networks and epidemic models. Journal of the Royal Society Interface,
2(4):295–307, 2005.
[11] Matthew J Keeling. The effects of local spatial structure on epidemiological invasions. Proceedings of the
Royal Society of London. Series B: Biological Sciences,
266(1421):859–867, 1999.
[12] Florent Krzakala, Cristopher Moore, Elchanan Mossel,
Joe Neeman, Allan Sly, Lenka Zdeborová, and Pan
Zhang. Spectral redemption in clustering sparse networks. Proceedings of the National Academy of Sciences,
110(52):20935–20940, 2013.
[13] Alun L Lloyd. Realistic distributions of infectious periods
in epidemic models: changing patterns of persistence and
dynamics. Theoretical population biology, 60(1):59–71,
2001.
[14] James O Lloyd-Smith, Sebastian J Schreiber, P Ekkehard Kopp, and WM Getz. Superspreading and the effect of individual variation on disease emergence. Nature,
438(7066):355–359, 2005.
[15] Andrey Y Lokhov, Marc Mézard, Hiroki Ohta, and Lenka
Zdeborová. Inferring the origin of an epidemic with a
dynamic message-passing algorithm. Physical Review E,
90:012801, 2014.
[16] Sergey Melnik, Adam Hackett, Mason A Porter, Peter J
Mucha, and James P Gleeson. The unreasonable effec-

7

[17]

[18]
[19]

[20]

[21]

[22]

tiveness of tree-based theory for networks with clustering.
Physical Review E, 83(3):036112, 2011.
Marc Mézard, Georgio Parisi, and M. A. Virasoro. Spin
Glass Theory and Beyond. Singapore: World Scientific,
1987.
Marc Mézard, Giorgio Parisi, and Riccardo Zecchina.
Analytic and algorithmic solution of random satisfiability
problems. Science, 297(5582):812–815, 2002.
Romualdo Pastor-Satorras, Claudio Castellano, Piet
Van Mieghem, and Alessandro Vespignani.
Epidemic processes in complex networks. arXiv preprint
arXiv:1408.2701, 2014.
Judea Pearl. Reverend bayes on inference engines: A
distributed hierarchical approach. In AAAI, pages 133–
136, 1982.
Lorenzo Pellis, Frank Ball, Shweta Bansal, Ken Eames,
Thomas House, Valerie Isham, and Pieter Trapman.
Eight challenges for network epidemic models. Epidemics, 2014.
Tim Rogers. Maximum-entropy moment-closure for
stochastic systems on networks. Journal of Statistical

[23]

[24]

[25]
[26]

[27]

Mechanics: Theory and Experiment, 2011(05):P05007,
2011.
Tim Rogers and Isaac Pérez Castillo. Cavity approach
to the spectral density of non-hermitian sparse matrices.
Physical Review E 79, 012101, 2009.
Tim Rogers, Isaac Pérez Castillo, Reimer Kühn, and
Koujin Takeda. Cavity approach to the spectral density
of sparse symmetric random matrices. Physical Review
E, 78(3):031116, 2008.
Pieter Trapman. On analytical approaches to epidemics
on networks. Theoretical population biology, 71(2):160–
173, 2007.
W Weibull. A statistical distribution function of wide
applicability. J. Appl. Mech.-Trans. ASME, 18(3):293–
297, 1951.
Robert R Wilkinson and Kieran J Sharkey. Message
passing and moment closure for susceptible-infectedrecovered epidemics on finite networks. Physical Review
E, 89(2):022808, 2014.

