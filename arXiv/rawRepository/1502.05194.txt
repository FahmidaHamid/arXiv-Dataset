Partitioning, duality, and linkage disequilibria in
the Moran model with recombination
Mareike Esser ∗ – Sebastian Probst † – Ellen Baake ‡

arXiv:1502.05194v1 [math.PR] 18 Feb 2015

Faculty of Technology, Bielefeld University, Box 100131, 33501 Bielefeld, Germany

Abstract The Moran model with recombination is considered, which describes the evolution of the genetic
composition of a population under recombination and resampling. There are n sites (or loci), a finite
number of letters (or alleles) at every site, and we do not make any scaling assumptions. In particular,
we do not assume a diffusion limit. We consider the following marginal ancestral recombination process.
Let S = {1, . . . , n} and A = {A1 , . . . , Am } be a partition of S. We concentrate on the joint probability
of the letters at the sites in A1 in individual 1, . . . , at the sites in Am in individual m, where the
individuals are sampled from the current population without replacement. Following the ancestry of
these sites backwards in time yields a process on the set of partitions of S, which, in the diffusion limit,
turns into a marginalised version of the n-locus ancestral recombination graph. With the help of an
inclusion-exclusion principle, we show that the type distribution corresponding to a given partition may
be represented in a systematic way, with the help of so-called recombinators and sampling functions. The
same is true of correlation functions (known as linkage disequilibria in genetics) of all orders.
We prove that the partitioning process (backward in time) is dual to the Moran population process
(forward in time), where the sampling function plays the role of the duality function. This sheds new light
on the work of Bobrowski et al. (2010). The result also leads to a closed system of ordinary differential
equations for the expectations of the sampling functions, which can be translated into expected type
distributions and expected linkage disequilibria.
Keywords: Moran model with recombination, ancestral recombination process, linkage disequilibria,
Möbius inversion, duality
MSC 2010 Subject classification: 92D10, 60J28.

1 Introduction
Models that describe the evolution of finite populations under recombination are among the
major challenges in population genetics. This article is devoted to the Moran model with
recombination (in continuous time), which is briefly described as follows (see Durrett 2008;
Bobrowski et al. 2010). A chromosome is identified with a linear arrangement (or sequence)
of n discrete positions called sites, which are collected in the set S = {1, . . . , n}. A site may
be understood as a nucleotide site or a gene locus. We will throughout consider chromosomes
as (haploid) individuals, that is, we think at the level of gametes (rather than that of diploid
individuals that carry two copies of the genetic information). Site i is occupied by letter xi ∈ Xi ,
where Xi is a finite set, 1 6 i 6 n. If sites are nucleotide sites, a natural choice for each
∗

E-mail: messer@techfak.uni-bielefeld.de
E-mail: sprobst@techfak.uni-bielefeld.de
‡
E-mail: ebaake@techfak.uni-bielefeld.de
†

-1-

Xi is the nucleotide alphabet {A, G, C, T}; if sites are gene loci, Xi is the set of alleles that
can occur at locus i. The genetic type of each individual is thus described by the sequence
x = (x1 , x2 , . . . , xn ) ∈ X1 × · · · × Xn =: X, where X is the type space. Recombination means that
a new individual is formed as a ‘mixture’ of an (ordered) pair of parents, say x and y. We will
restrict ourselves to single-crossover recombination, that is, the offspring inherits the leading
segment (up to site i, for some 1 6 i < n) from the first and the trailing segment (after site
i) from the second parent. The recombined type thus is (x6i , y>i ) := (x1 , . . . , xi , yi+1 , . . . , yn );
we say that a crossover has happened between sites i and i + 1. The sites that come from the
paternal and the maternal sequence, respectively, define a partition A of S into two parts (we
need not keep track of which part was ‘maternal’ and which was ‘paternal’). All partitions of S
into two ordered (or contiguous) parts (A = {{1, 2, . . . , i}, {i + 1, . . . , n}}, i ∈ S \ {n}) can be
realised, via a single crossover event. Altogether, whenever an offspring is created,
its sites are
P
partitioned between parents according to A with probability rA , where rA > 0, A∈O2 (S) rA 6 1,
and O2 (S) is the set of all ordered partitions of S into two parts. Let us note that, due to the
one-to-one correspondence between elements of S \ {n} and those of O2 (S), the specification of
the
P rA simply means that a crossover probability is associated with each site in S \{n}. The sum
A∈O2 (S) rA is the probability
P that some recombination event takes place during reproduction.
With probability r{S} = 1 − A∈O2 (S) rA , there is no recombination, in which case the offspring
is the full copy of a single parent. We write O62 (S) := O2 (S) ∪ {S} for the set of ordered
partitions into at most two parts. The collection {rA }A∈O62 (S) is known as the recombination
distribution (Bürger 2000, p. 55).
Consider now a population of a constant number of N haploid individuals (that is, gametes),
which evolves as follows (see Figure 1). Each individual has an exponential lifespan with
parameter 1 (this choice of the parameter is without loss of generality; it simply sets the time
scale). When an individual dies, it is replaced by a new one as follows. First draw a partition A
according to the recombination distribution. Then draw |A| parents from the population (the
parents may include the individual that is about to die), uniformly and with replacement, where
|A| is the number of parts in A. If |A| = 2, the offspring inherits the leading segment of A
from the first and the trailing segment from the second parent, as described above. If |A| = 1
(and thus A = {S}), the offspring is a full copy of a single parent (again chosen uniformly from
among all individuals); this is called a (pure) resampling event. All events are independent of
each other.
Note that it may seem biologically more realistic to draw two parents without replacement.
However, assuming sampling with replacement entails significant simplifications, and yields
the same process as sampling without replacement with a slight change in the recombination
distribution. More precisely, since drawing the same individual twice means that the offspring
is a full copy of this single parent, our process agrees (in distribution) with the analogous
process without replacement if rA is replaced by rA (N − 1)/N for all A ∈ O2 (S) (and r{S} is set
accordingly).
The model will be described more formally later. For now, let us summarise the two main
lines of research in this context. On the one hand, there has been considerable interest in how
the composition of the population evolves over time, and, in particular, how the correlations
between sites (known as linkage disequilibria) will develop; see the overviews in Hein et al.
(2005, Chap. 5.4), Durrett (2008, Chap. 3.3 and 8.2), or Wakeley (2009, Chap. 7.2.4). Since
there is no mutation, a single type will go to fixation in the long run, that is, the entire
population will ultimately consist of this single type. In the absence of recombination, this
will be one of the types initially present, and it is well known that the fixation probability for a
given type equals its initial frequency. If there is recombination, the type that ultimately wins
can also be a newly-composed type, but little is known about the fixation probabilities of the
many possible types. The explicit development over time is even more challenging, due to an
-2-

1

111111111
000000000
000000000
111111111
000000000
111111111

2

3

4

5

111111111
000000000
000000000
111111111

11
00
00
11
00
11

t

111
000
000
111
000
111

111111
000000
000000
111111

T

111111
000000
000000
111111

11
00
00
11

111
000
000
111

Figure 1: Snapshot of a Moran model realisation with N = 5 individuals. For example, in the first event,
individual 3 dies and is replaced by a recombined copy of individuals 2 and 3. The last line shows the composition
of the population at the final timepoint, T .

intricate interplay of resampling and recombination. It is usually approached forwards in time
e.g., Ohta and Kimura (1969), Song and Song (2007), Baake and Herms (2008), Durrett (2008,
Chap. 8.2), or Bobrowski et al. (2010). In the deterministic limit, which emerges when N → ∞
without rescaling of the rA or of time, the population is described by a system of ordinary
differential equations, again forwards in time. This system has an explicit solution, both for
the type distribution and for correlation functions of all orders, for an arbitrary number of sites
(Baake and Baake 2003; Baake 2005). This also provides a decent approximation for large but
finite populations (Baake and Herms 2008), but dealing appropriately with the stochasticity of
finite populations remains a major challenge.
The second line of research is concerned with genealogical aspects and sampling formulae. Here,
one starts from a sample taken from the present population and traces back the ancestry of the
various segments the individuals are composed of. A major challenge lies in the calculation of the
probabilities for the type distribution of a random sample, that is, one aims at so-called sampling
formulae, see Durrett (2008, Chap. 3.6). These questions are naturally approached backwards
in time. Usually, one employs the diffusion (or weak recombination) limit, that is, time is sped
up by a factor of N , followed by N → ∞ such that N rA → ̺A , A ∈ O2 (S). Obtaining sampling
formulae is tied to the situation in which the population has reached a stationary state; even
this case is very hard to treat, and coping with time dependence seems to be hopeless.
The aim of this article is to build a bridge between these two lines of research. We will explore
the type distribution and the correlations over time, in the stochastic setting. A starting point
will be a recent paper by Bobrowski, Wojdyła, and Kimmel (2010), who approach this question.
Their setting is entirely forwards in time, which effectively hides some of the underlying structure.
In contrast, we will proceed backwards in time and provide a genealogocial approach for the
analysis of correlations. The crucial notion in this context will be that of duality between the
original Moran model forward in time and a suitable ancestral process that follows back the
ancestry of selected segments from today’s population. This will also shed new light on the
results of Bobrowski et al. (2010). In order to keep the approach as general as possible, we will
throughout adhere to the original (finite N ) model, without taking any limit, but will discuss
the various scalings and limits where appropriate.
The paper is organised as follows. In Section 2, we start by collecting some important facts about
partitions and Möbius functions. We then introduce the model more formally and motivate
our genealogical approach in Section 3, which may be considered a marginal version of the
usual ancestral process with recombination. In Section 4, we describe our ancestral process,
which is a partitioning process that keeps track of how the ancestral material is partitioned
between individuals. In Section 5, we introduce a systematic description via recombinators,
which describe the action of recombination on a population and have proved very useful in the
-3-

deterministic setting. We complement them here by sampling functions, which are additionally
required for finite populations. The collection of sampling functions will be crucial since it
will also serve as duality function in Section 6, where the duality between the Moran model
forward in time and the partitioning process backward in time is proved. This proof, at the
same time, yields a differential equation system for the expectations of the sampling functions,
which are the building blocks for the linkage disequilibria. In Section 7, we apply our results to
the cases of two and three sites. We will see that the expected linkage disequilibria (of second
and third order) decay exponentially even in the presence of resampling, and identify further
linear combinations of expected sampling functions that decay exponentially. For two sites, we
also obtain the explicit time course for the expected composition of the population, and, at the
same time, the fixation probabilities of the various types.

2 Preliminaries: Partitions and Möbius functions
Working with partitions will be essential to our approach, and we will rely throughout on the
powerful concept of Möbius functions and Möbius inversion. Let us briefly collect the basic
notions and standard results; more background material as well as the proofs may be found in
Rota (1964), Berge (1971, Chap. 3.2), Aigner (1979, Chap. I,II,IV) and Stanley (1986, Chap. 3).
Partitions. Let W be a finite, nonempty, totally ordered set, such as a finite subset of N; later,
W will be S or a subset thereof. Let P = P(W ) be the set of partitions of W . We write such a
partition as A = {A1 , . . . , Am }, where Aj 6= ∅ for all j and Aj ∩ Ak = ∅ for all j 6= k together
with A1 ∪ · · · ∪ Am = W . We call Aj a block (or part) of A and m = |A| is the number of blocks
in A.
We say that a partition A = {A1 , . . . , Am } of W is ordered (or contiguous, or an interval
partition) if every Aj is ordered in W , that is, Aj = {x ∈ W | min Aj 6 x 6 max Aj }. For
example, if W = {1, 2, 5, 7, 9}, then {{1, 2, 5}, {7, 9}} is ordered, but {{1, 2, 7}, {5, 9}} is not.
The set of all ordered partitions of W is denoted by O(W ), the set of all ordered partitions of
W into (exactly) two parts is O2 (W ), and the set of all ordered partitions of W into at most
two parts is O62 (W ).
For a given partition A = {A1 , . . . , Am } of W , let M := {1, 2, . . . , m} = M (A) and, for J ⊆ M ,
we define AJ := {Aj }j∈J and AJ := ∪j∈J Aj . AJ is a partition of AJ . In particular, AM = A,
AM = W , A{j} = {Aj }, and AM \{j} = A \ {Aj }, for any j ∈ M . Note that M depends on
A, but we suppress this dependence when there is no risk of confusion. We will throughout
abbreviate J \ j := J \ {j} and J ∪ k := J ∪ {k}.
The natural ordering relation on P(W ) is denoted by 4, where A 4 B means that A is a
refinement of B, that is, every block of A is a subset of a block of B; equivalently, B is a
coarsening of A. A ≺ B means that A 4 B and A 6= B. Together with the resulting partial
order, P(W ) is a poset and, in particular, a finite lattice. P(W ) has a unique minimal or finest
partition, which is denoted as 0 = {{x} | x ∈ W }; likewise, there is a unique maximal or coarsest
one, namely 1 = {W }.
When U and V are disjoint (finite) sets, two partitions A ∈ P(U ) and B ∈ P(V ) can be joined
into A ∪ B to form an element of P(U ∪˙ V ). Furthermore, if U ⊆ W , a partition A ∈ P(W ),
with A = {A1 , . . . , Am } say, defines a unique partition of U by restriction. The latter is denoted
by A|U , and its parts are precisely all non-empty sets of the form Ai ∩ U with 1 6 i 6 m. In
particular, 1|U is the coarsest element in P(U ). For two partitions A and B, the least upper
bound will be denoted by A ∨ B, namely the finest partition C for which A 4 C and B 4 C.
Analogously define the greatest lower bound of A and B by A ∧ B.
-4-

Example 1. Consider the two partitions A = {{1, 3, 4}, {2, 5}} and B = {{1, 4}, {2, 3}, {5}} of
W = {1, . . . , 5} together with a subset U = {1, 2, 4} of W . Then A ∧ B = {{1, 4}, {2}, {3}, {5}},
A ∨ B = {{1, . . . , 5}}, and A|U = {{1, 4}, {2}}.
♦
Möbius functions on the poset of partitions and Möbius inversion. The Möbius function
of a poset is a general and powerful tool in discrete mathematics. It may be considered as
a systematic way of implementing the inclusion-exclusion principle. We rely on it in two
contexts in this article: First, we use it to turn sampling without replacement into sampling
with replacement, and vice versa. Second, we need it to turn type frequencies into linkage
disequilibra.
For background material, we refer the reader to Rota (1964), Berge (1971, Chap. 3.2), Aigner
(1979, Chap. IV) and Stanley (1986, Chap. 3). Let us only summarise here that the Möbius
function µ is defined inductively for all A 4 B ∈ P(W ) via
X
µ(A, A) = 1 and µ(A, B) = −
µ(A, C),
(1)
A4C ≺B
˙

where the underdot indicates the summation variable. Let A 4 B ∈ P(W ), with m = |B| the
number of blocks in B, and nj the number of blocks of A within block Bj of B, that is, nj is the
number of blocks in A|Bj , 1 6 j 6 m. The Möbius function of the pair (A, B) is then given by
µ(A, B) =

m
Y



µ A|Bj , 1|Bj =

j=1

m
Y

(−1)nj −1 (nj − 1)! .

j=1

The following identity for sums of Möbius functions
(
X
1, A = C,
µ(A, B) =
0, otherwise,
A4B4C

(2)

˙

follows immediately from the definition (1) and will be used frequently in what follows.
We can now state the fundamental Möbius inversion principle. Let f and g be mappings from
P(W ) to C which are, for all A ∈ P(W ), related via
X
f (B).
(3)
g(A) =
B<A
˙

Then, this can be solved for f via the inversion formula
X
f (A) =
µ(A, B) g(B).

(4)

B<A
˙

More precisely, this is inversion from above. An analogous formula applies for inversion from
below ; this relies on refinements rather than coarsenings, with ‘<’ replaced by ‘4’ in (3) and (4).
It is important to note that Möbius inversion is not restricted to functions; it also applies to
bounded operators.

3 The model and the genealogical approach
In this section, we define the model formally and motivate our genealogical approach.
-5-

3.1 The Moran model with single-crossover recombination
We identify the population at time t by a (random) counting measure Zt on X.PNamely, Zt ({x})
denotes the number of individuals of type x ∈ X at time t, and Zt (A) := x∈A Zt ({x}) for
A ⊆ X; we abbreviate Zt ({x}) as Zt (x). If we P
define δx as the point measure on x (i.e.,
δx (y) = δx,y for x, y ∈ X), we can also write Zt = x∈X Zt (x) δx . Since
P our Moran population
has constant size N , we have kZt k = N for all times, where kZt k := x∈X Zt (x) = Zt (X) is the
norm (or total variation) of Zt .
So, {Zt }t>0 is a Markov process in continuous time with values in

	
E := z ∈ {0, . . . , N }|X| | kzk = N ,

(5)

where |X| is the number of elements in X. We will describe the action of recombination on
(positive) measures with the help of so-called recombinators as introduced by Baake and Baake
(2003); see also Baake and Herms (2008) for a pedestrian introduction. Let M+ (X) be the set
of all positive, finite measures on X and we understand M+ (X) to include the zero measure.

Define the canonical projection πI : X → i∈I Xi =: XI , for I ⊆ S, by πI (x) = (xi )i∈I as usual.
For ω ∈ M+ (X), the shorthand πI .ω := ω ◦ πI−1 indicates the marginal measure with respect to
the sites in I ⊆ S, where πI−1 is the preimage of πI . The operation . (where the dot is on the
line and should not be confused with a multiplication sign) is known as the pushforward of ω
w.r.t. πI . In terms of coordinates, the definition may be spelled out as
 


πI .ω xI = ω ◦ πI−1 xI = ω {x ∈ X | πI (x) = xI } , xI ∈ XI .
Note that π∅ .ω = kωk and πS .ω = ω.

Consider now A = {{1, 2, . . . , i}, {i + 1, . . . , n}} ∈ O2 (S) and ω ∈ M+ (X) \ 0, and define the
projective recombinator as
p

RA (ω) :=
p



1
π{1,...,i} .ω ⊗ π{i+1,...,n} .ω .
2
kωk

(6)

p

Moreover, we set R1 (ω) := ω/kωk. RA (ω) is a probability measure for all ω ∈ M+ (X) \ 0, where
p
the zero measure is excluded to make it well-defined. In words, RA turns ω into the (normalised)
tensor product (or product measure) of its marginals with respect to the blocks in A. Writing
out (6) in terms of coordinates gives




1
π{1,...,i} .ω x{1,...,i} π{i+1,...,n} .ω x{i+1,...,n}
2
kωk
1
ω(x1 , . . . , xi , ∗, . . . , ∗) ω(∗, . . . , ∗, xi+1 , . . . , xn ),
=
kωk2


p
RA (ω) (x) =

where ‘∗’ means marginalisation. If ω = z is the current population, then RAp (z) is the type
distribution that results when a new individual is created by drawing a leading and (possibly) a
trailing segment (as encoded by A ∈ O62 (S)) from the current population, uniformly and with
replacement.
p

Remark 1. RA is a projective version of the recombinator defined by Baake and Baake (2003);
it differs from the latter by a factor of 1/kωk. Clearly, both versions agree on the set of probability
measures. As we shall see, the projective version is more suitable in the stochastic setting, while
the original recombinators are better adapted to the deterministic situation. Since recombinators
will only appear in the projective version in this article, we will drop the superscript and the
p
specification ‘projective’ and call RA := RA a recombinator by slight abuse of language.
♦
-6-

In Section 5, we will generalise the recombinators and learn more about their probabilistic
meaning and mathematical properties. For the moment, let us use them to reformulate the
Moran model with recombination in a compact way. Namely, since all individuals die at rate 1,
the population loses type-y individuals at rate Zt (y). Each loss is replaced by a new individual,
which is sampled uniformly from RA (Zt ) with probability rA , A ∈ O62 (S). Therefore, when
Zt = z, the transition to z + δx − δy occurs with rate
X

λ(z; y, x) :=
rA RA (z) (x) z(y).
(7)
A∈O62 (S)

The summand for A = 1 corresponds to pure resampling, whereas all other summands include
recombination. Note that λ includes ‘silent transitions’ (x = y).
Remark 2. We would like to mention that the model may alternatively be formulated in
terms of reproducing individuals rather than dying individuals, as follows. Each individual
reproduces at rate 1 and picks an A ∈ O62 (S) according to the recombination distribution. If
A ∈ O2 , the reproducing individual contributes the sites in one of the blocks in A and picks
a random partner that contributes the sites in the other block to the offspring. If A = 1,
the reproducing individuals contributes all sites. The offspring pieced together in this way
replaces a uniformly chosen individual from the population. In this formulation, which is closer
in spirit to the deterministic single-crossover model, offspring of type x are created at rate
N rA (RA (Zt ))(x) and replace an individual of type y with probability Zt (y)/N . This explains the
different normalisation of the original recombinator, whereas the additional factor of N = kZt k
is absorbed in its definition in Baake and Baake (2003). The resulting transition rates, however,
are again those in Eq. (7). Here, we stay with the formulation that led to Eq. (7) in the first
place, since it seems more natural for finite populations.
♦
Let us summarise our model as follows:
Definition 1 (Moran model with single crossovers). The Moran model with single crossovers
is the Markov chain in continuous time {Zt }t>0 with state space E of Eq. (5) and generator
matrix Λ with nondiagonal elements
X
λ(z; y, x), w 6= 0,
Λ(z, z + w) =
x,y∈X:
δx −δy =w

for z ∈ E, w ∈ E − z (where E − z := {v | z + v ∈ E}) and Λ(z, z) = −

P

Λ(z, z + v).

v∈E−z:
v6=0

(N )

Limits of the forward model. Consider now the family of processes {Zt }t>0 , N = 1, 2, . . . ,
where we add the upper index to indicate dependence on population size. Also consider the
(N )
(N )
normalised version {Zt /N }t>0 ; Zt /N is a random probability measure on X. For N → ∞
(N )
and without any rescaling of the rA or of time, the sequence {Zt }t>0 converges to the solution
of the deterministic single-crossover equation
X

(8)
ω̇t =
rA RA (ωt ) − ωt
A∈O2 (S)

(N )

with initial value ω0 , ω0 a probability measure, and we assume that limN →∞ Z0 /N = ω0 .
This is a law of large numbers and due to Ethier and Kurtz (1985, Thm. 11.2.1). The precise
statement as well as the proof are perfectly analogous to Proposition 1 in Baake and Herms
(2008), which assumes a slightly different sampling scheme for recombination. We therefore
-7-

leave out the details here. The deterministic single-crossover equation (8) was investigated by
Baake and Baake (2003) and Baake (2005). For comparison, note that, in view of Remark 2,
the probability rA in (8) is multiplied by the unit rate at which each individual reproduces, and
this way turns into a recombination rate.
The Moran model with recombination also has a well-known diffusion limit, which emerges when
N → ∞ under N rA → ̺A , A ∈ O2 (S), after a speedup of time by a factor of N . In the case
of two loci and two alleles, this goes back to Ohta and Kimura (1969); see also Durrett (2008,
Chap. 8.2) for a modern exposition. Two loci with an arbitrary (but finite) number of alleles are
treated by Jenkins et al. (2015). This can be readily generalised to the case of a finite number
of loci with a finite number of alleles, but we do not spell it out here, since we will not draw on
the diffusion limit of the forward process later.
3.2 The ancestral recombination process (ARP) and its marginal version
In line with standard population-genetic thinking, we employ a genealogical approach by tracing
back the ancestry of (parts of) the genetic material from a population at present that evolved
according to the Moran model with single-crossover recombination. The standard genealogical
approach for models with recombination is the ancestral recombination graph (ARG) first
formulated by Hudson (1983). Today, many different notions of ‘ARG’ are in use. We stick to the
usual convention here that the ARG assumes the diffusion limit. Hudson’s original version was
for two loci, but multilocus generalisations (Griffiths and Marjoram 1996; Bhaskar and Song
2012) and continuous sequence versions (n → ∞, see, e.g., Durrett 2008, Chap. 3.4) are
immediate.

1

2

3

Figure 2: A realisation of the full ancestral recombination
process, starting from m = 3 individuals; ancestral material
is shaded, non-ancestral material is indicated by thin
horizontal lines. The mixed recombination-coalescence
event indicated by dashed lines can only appear in the finite
population recombination process (ARP). In the diffusion
limit, and thus in the ARG, recombination and coalescence
act in isolation.

The ARG starts from a sample of individuals from the present population and follows their
ancestry backwards. When a sequence (or a part of a sequence) experiences a recombination
event, it branches into a leading and a trailing segment; when two (parts of) sequences go back to
a common ancestor, there is a coalescence event. For overviews see Hein et al. (2005, Chap. 5),
Durrett (2008, Chap. 3.4), or Wakeley (2009, Chap. 7.2). Mutation can be independently
superimposed on the ARG, but will not be considered in this article. One is then interested in
the full information on the sample, namely, the probabilities for all possible type distributions
of the sample. The stationary state of the ARG may be characterised by a collection of
so-called sampling recursions; they may be solved analytically for tiny samples (leading to
explicit sampling formulae), or numerically for larger ones, see Golding (1984), or Durrett
(2008, Chap. 3.6). But feasibility is limited due to the enormous state space, even for small
samples. Alternatively, one resorts to computationally intensive Monte-Carlo or importance
sampling methods to simulate the ARG (Griffiths and Marjoram 1996; Wang and Rannala 2008;
Jenkins and Griffiths 2011). Recently, Song and coworkers discovered structural properties of
the ARG that allow for an efficient combination of analytical and simulation techniques in the
-8-

1

2

3

1

2

3

Figure 3: The marginalised version corresponding to the ARP in Figure 2, in which we only follow blocks of the
partition (shaded), that is, block Ai is sampled in individual number i, 1 6 i 6 m. Material that is ancestral to
the sampled individuals, but not to the blocks considered, is shown as open rectangles (left). But since this is
not traced back, it can be treated in the same way as material non-ancestral to the sampled individuals (right).
Consequently, the sample will finally consist of the blocks of the partition only.

regime of strong recombination (Jenkins and Song 2010); more precisely, they work in terms of
expansions in 1/̺ as ̺ → ∞, where all ̺A , with A ∈ O2 (S), are assumed to scale linearly with
the common factor ̺.
In contrast, we will work in the setting of both finite n and finite N . The corresponding ancestral
recombination process (ARP), which is illustrated in Figure 2, is a finite-population version of
the multilocus ARG. We then simplify matters by only aiming at reduced information. Namely,
we consider a partition A = {A1 , A2 , . . . , Am } of S (with m 6 N ). Now sample m individuals
from the present population and follow back the ancestry of the sites in A1 in the first individual,
in A2 in the second individual, . . . , in Am in the m’th individual, without considering any other
sites and any other individuals, as in Figure 3. That is, each locus is considered in one individual
only. The result may be viewed as a marginalised version of the ancestral recombination process,
and, in the diffusion limit, turns into a marginal version of the multilocus ARG starting from a
sample of size m. We will see that this information is sufficient to characterise the time evolution
of the expected linkage disequilibria of all orders. We will not employ any scaling or limit, in
order to allow for arbitrary strengths of recombination. It will turn out that the approach of
Bobrowski et al. (2010) actually corresponds to this marginal ancestral recombination process,
although this is not apparent from their formulation forward in time.
More precisely, the letters at the loci considered at present, together with their ancestry, can
be constructed by a three-step procedure (see Figure 4). First we run a partitioning process
{Σt }t>0 on P(S), backward in time, starting at a given initial partition Σ0 with |Σ0 | = m. Σt
describes the partitioning of sites into parental individuals at time t; sites in the same block
(in different blocks) belong to the same (to different) individuals. Clearly, |Σt | is the number
of ancestral individuals at time t. The process {Σt }t>0 is independent of the types and will
be described in detail in the next section. In the second step, a letter is assigned to each site
of S at time t (i.e. in the past) in the following way. For every part of Σt , pick an individual
from the initial population (without replacement) and copy its letters to the sites in the block
considered. For illustration, also assign a colour to each block, thus indicating different parental
individuals. In the last step, the letters and colours are propagated downwards (i.e. forward in
time) according to the realisation of {Σt }t>0 laid down in the first step. A similar construction
was used in the ancestral process by Baake and von Wangenheim (2014), but restricted to a
sample of size 1 (i.e. start with Σ0 = 1), and in discrete time in the deterministic limit. Let us
-9-

now describe the partitioning process in detail.

Σt = {{1, 2}, {3}, {4, 5}}
t

Σ0 = {{1}, {2, 4}, {3, 5}}

x1 x2

⋆ ⋆

⋆ ⋆ ⋆

x3

⋆ ⋆

⋆ ⋆ ⋆

x4 x5
Σt = {{1, 2}, {3}, {4, 5}}

t
⋆

x1

⋆ ⋆ ⋆ ⋆

x2

⋆ ⋆ ⋆

⋆

x2

⋆ ⋆

⋆

x4

x3 x4 x5

⋆

⋆ ⋆

x3

⋆

x5

Σ0 = {{1}, {2, 4}, {3, 5}}

Figure 4: Construction of one possible ancestry of a collection of sites that correspond to the initial partition
A0 = {{1}, {2, 4}, {3, 5}}. The upper panel shows the partitioning process (backwards in time). In the lower
panel, letters and colours are assigned to each block of Σt and propagated downwards (forward in time).

4 The partitioning process
The partitioning process {Σt }t>0 is a Markov process on P(S), which describes how the sites are
partitioned into different individuals backward in time. Since there is a one-to-one relationship
between the individuals and the blocks of the partition, we may identify individuals with the
ancestral material they carry.
The process {Σt }t>0 consists of a mixture of splitting (S) and coalescence (C) events. It can
be constructed independently of the types. In this section, we describe the process by arguing
on the grounds of the underlying Moran model; in Section 6, we will formally prove that this is
indeed the correct dual process for it.
Since we trace back sites in subsets U ⊆ S (rather than complete sequences), we need the
corresponding marginal recombination probabilities
X
rBU :=
rAS
(9)
A∈O62 (S)
A|U =B

for any B ∈ O62 (U ), where rAS = rA . Note that, for |U | = 1, the only recombination parameter
6 1|U , then
is r1U = 1. If U is ordered in S (i.e. U = {x ∈ S : min(U ) 6 x 6 max(U )}) and B =
rBU is simply the probability of crossover after the (unique) site that leads to partition B. If U is
not ordered in S, then rBU is the sum of the probabilities of all crossovers that lead to partition
B, as illustrated in Figure 5.
Assume now that U is an unordered block of Σt . This means there is so-called trapped material,
that is, non-ancestral sites enclosed between ancestral regions. All crossover events within a
given trapped segment contribute to the separation of the adjacent ancestral segments – in
- 10 -

contrast to crossovers in flanking non-ancestral regions to the left or the right of U , which do
not affect the genealogy. Note finally that the upper index in rBU can, in principle, be omitted
|B|
since U = ∪i=1 Bi , and we will do so when appropriate.

+

+

Figure 5: Let S = {1, . . . , 5} and U = {1, 4, 5} ⊂ S. For the partition B = {{1}, {4, 5}}, there are three
recombination events that partition U into B, thus rBU = r{{1},{2,3,4,5}} + r{{1,2},{3,4,5}} + r{{1,2,3},{4,5}} .

Now start with the initial partition Σ0 . Suppose that the current state is Σt = A = {A1 , . . . , Am }
and denote by ∆ the waiting time to the next event. ∆ is exponentially distributed with
parameter m, since each block corresponds to an individual, and each individual is independently
affected at rate 1. When the bell rings, choose a block uniformly. If Aj is picked, then Σt+∆ is
obtained as follows (see Figure 6 for an example).
A
In the splitting step, block Aj turns into an intermediate state A′j = J with probability rJ j ,
J ∈ O62 (Aj ). In detail:
A

(S1 ) With probability r1 j , the block Aj remains unchanged. The resulting intermediate
state (of this block) is A′j = Aj .
A

(S2 ) With probability rJ j , J ∈ O2 (Aj ), block Aj splits into two parts, A′j = J = {Aj1 , Aj2 },
A

which are ordered in Aj , but not necessarily in S. Recall that, via (9), rJ j takes into
account all recombination probabilities that lead to J , including those within trapped
material.
Now, each block of J chooses out of N parents, uniformly and with replacement. Among
these, there are m − 1 parents that carry one block of AM \j = A \ Aj each; the remaining
N − (m − 1) parents are empty, that is, they do not carry ancestral material available for
coalescence. Coalescence happens if the choosing block picks a parent that carries ancestral
material; otherwise, the choosing block becomes an ancestral block of its own, which is available
for coalescence from then onwards. The possible outcomes are certain coarsenings of AM \j ∪ J ,
namely:
If J = {Aj } (case (S1 )), then either
(C1,1 ) With probability (N − (m − 1))/N , block Aj does not coalesce with any block of AM \j .
As a result, Σt+∆ = Σt = A.
(C1,2 ) With probability 1/N , block Aj coalesces with block Ak , k ∈ M \ j. This results in
Σt+∆ = AM \{j,k} ∪ A{j,k} .
If J = {Aj1 , Aj2 } (case (S2 )), we get the following possibilities:
(C2,1 ) With probability (N − (m − 1))(N − m)/N 2 , no block of J coalesces with a block of
AM \j , so Σt+∆ = AM \j ∪ J .
(C2,2 ) With probability (N − (m − 1))/N 2 , one block of J coalesces with block Ak , k ∈ M \ j,
while the other block of J chooses an empty individual. This ends up in the state
Σt+∆ = AM \{j,k} ∪ {A{j1 ,k} , Aj2 } or Σt+∆ = AM \{j,k} ∪ {A{j2 ,k} , Aj1 }. That is, in going
from Σt to Σt+∆ , either block Aj1 or Aj2 is moved from Aj to Ak .
- 11 -

(C2,3 ) With probability (N − (m − 1))/N 2 , the blocks Aj1 and Aj2 coalesce with each other,
but choose an empty individual, which gives Σt+∆ = A.
(C2,4 ) With probability 1/N 2 , the block Aj1 coalesces with Ak and Aj2 coalesces with Aℓ ,
k, ℓ ∈ M \ j. This yields either Σt+∆ = AM \{j,k,ℓ} ∪ {A{j1 ,k} , A{j2 ,ℓ} } if k 6= ℓ, or
Σt+∆ = AM \{j,k} ∪ A{j,k} if k = ℓ.

Σt+∆
(C2,2 )
(Σt \ A2 ) ∪ J

(S2 )

Σt
Figure 6: One step of the partitioning process with cuexitrrent state Σt = {A1 , A2 , A3 } = {{1}, {2, 4}, {3}}. In
this example, A2 is chosen and splits into J = {{2}, {4}}. In the following step (C2,2 ), the leading part coalesces
with A1 , whereas the trailing part remains separate, so that we end up in Σt+∆ = {{1, 2}, {3}, {4}}.

Summarising, we see that a transition from A to B, via partitioning of block Aj into J , j ∈ M ,
J ∈ O62 (Aj ), is possible whenever B < AM \j ∪ J and B|AM \j = AM \j , or, equivalently,
whenever
B|Aj < J and B|AM \j = AM \j .
Each block of J coalesces into every block currently available with probability 1/N , and remains
separate with probability (N − k)/N if there are currently k blocks available; in the latter case,
the block considered becomes number k + 1. We can therefore summarise the rate of the said
transition as

r Aj 1|J | (N −(m−1))! , if B|A < J , B|A
= AM \j ,
J N
(N −|B|)!
j
M \j
(10)
ϑj,J ;A,B =
0,
otherwise.

Note that this includes silent events where B = A. Thus, the partitioning process {Σt }t>0 is a
continuous-time Markov chain on P(S) characterised by the generator Θ := (ΘAB )A,B∈P(S) with
nondiagonal elements
X
X
ΘAB =
ϑj,J ;A,B
j∈M J ∈O62 (Aj )

=

 A
−(m−1))!

rJ j N12 (N(N

−|B|)! ,


2

N2




0,

+

N −1
N2

A

Ak 

r1 j + r1

if B|Aj = J , B|AM \j = AM \j , for some j ∈ M, J ∈ O2 (Aj ),
, if B = AM \{j,k} ∪ A{j,k} for some j 6= k ∈ M,
for all other B =
6 A,
(11)

P
and ΘAA = − B∈P(S)\A ΘAB . Note that, for J ∈ O2 (Aj ) we have distinguished between
B|Aj = J and B|Aj = 1|Aj ≻ J . The latter corresponds to k = ℓ in (C2,4 ) and leads to the
same transition as a pure coalescence event in (C1,2 ). More precisely, the total coalescence rate
of j and k is
 X

X

N − 1 Aj
1
2
1 Aj
Aj
Ak
Ak 
rJ +
rK
r1 + r1Ak
r1 + r1 + 2
= 2+
2
N
N
N
N
J ∈O2 (Aj )

K∈O2 (Ak )

P
as stated, since J ∈O2 (U ) rJU = 1 − r1U , U ⊆ S. Note also that transitions to partitions B with
|B| > N are impossible, as it must be.
- 12 -

Remark 3. In fact, this generator Θ coincides with the generator Θ worked out by Bobrowski and Kimmel
(2003) and Bobrowski et al. (2010) with a very different approach, forward in time. For n 6
3, they state the generator matrices explicitly, and the identity with (11) is easily checked
by elementwise comparison. For n > 3, they provide an algorithm, which runs through all
individuals and all sites and builds up the matrix Θ incrementally, in the following manner. For
every given individual, leading and trailing segments (for the split after site i, for all i ∈ S \n) are
taken into account, irrespective of whether the segments contain ancestral material. This way,
the algorithm does not distinguish between transitions induced by recombination events within
ancestral (or trapped) material and recombination events that are invisible in the genealogical
perspective, that is, events that are effectively pure coalescence events. Instead, a case distinction
is performed that is based on whether or not one or both segments coalesce with individuals
that do or do not carry ancestral material. A detailed investigation of this approach, which
involves expanding the cases into 11 subcases and rearranging these according to the emerging
partitions of the complete ancestral material, leads precisely to our cases (C2,1 ) to (C2,4 ) (here,
both emerging segments contain ancestral material) and (C1,1 ) and (C1,2 ) (here one segment
is empty). Since this approach somehow disguises or mixes the various partitions of ancestral
material that may arise due to a transition, it does not lead to a closed expression for Θ. In
contrast, our approach yields the matrix elements explicitly for arbitrary n, and gives them a
natural and plausible meaning in terms of the partitioning process in backward time.
♦
Limits of the partitioning process. We now examine how the partitioning process behaves in
the two limiting cases mentioned in Section 3, namely, the deterministic limit and the diffusion
limit. Recall that, in the deterministic limit, we let N → ∞ without rescaling the recombination
(N )
probabilities or time. Consider, therefore, the family of processes {Σt }t>0 , N = 1, 2, . . . ,
(N
)
generated by Θ , where we again make the dependence on population size explicit through
the upper index. In the limit, only the pure splitting events (C2,1 ) survive, more precisely:
Proposition 1 (Deterministic limit). In the deterministic limit, the sequence of partitioning
(N )
(N )
processes {Σt }t>0 with initial states Σ0 ≡ σ converges in distribution to the process {Σt′ }t>0
with initial state Σ0′ = σ and generator Θ′ defined by its nondiagonal elements

r Aj , if B = A
J
M \j ∪ J for some j ∈ M and J ∈ O2 (Aj ),
′
ΘAB =
0,
for all other B 6= A.

Hence, {Σt′ }t>0 is a process of progressive refinements, that is, Στ′ 4 Σt′ for all τ > t. In
particular, if Σ0′ ∈ O(S), then Σt′ ∈ O(S) for all times.
Proof. Inspecting the N -dependence of the elements of Θ = Θ(N ) in Eq. (11) gives the following
order of magnitude for the nondiagonal elements:


Aj
1
1

1
+
O
r
, if B|Aj = J , B|AM \j = AM \j for j ∈ M , J ∈ O2 (Aj ),

m+1−|B|
J
N

N


(N )
ΘAB = N1 r1Aj + r1Ak + O N12 ,
if B = AM \{j,k} ∪ A{j,k} for some j 6= k ∈ M,




0,
for all other B 6= A.
(12)

Obviously, Θ(N ) = Θ ′ + O(1/N ), which proves convergence of the sequence of generators
(N )
of {Σt }t>0 to that of {Σt′ }t>0 . This entails convergence of the corresponding sequence of
semigroups. By Theorem 4.9.10 of Ethier and Kurtz (1985), this guarantees convergence of
(N )
{Σt }t>0 to {Σt′ }t>0 in distribution.
- 13 -

The remainder of the statement is obvious since, under Θ ′ , the only transitions are those that
involve the refinement of a single block, say Aj , into two blocks ordered in Aj . If Σ0 is ordered in
S, then all its blocks are ordered in S, and all blocks of Σt will be ordered in S for all times.
Remark 4. Obviously, in this limit, there are no coalescence events, so that ancestral material
that has been separated once will never come together again in one individual. When starting
with Σ0′ = {S}, the genealogy may be represented by a binary tree, which successively branches
into smaller segments; for other initial conditions, one gets a corresponding collection (i.e. a
forest) of binary trees. We call these trees ancestral recombination trees or ART s; a discrete-time
analogue was studied by Baake and von Wangenheim (2014).
♦
We now turn to the diffusion limit and use the factor N rather than (the more common) 2N
since our N is the haploid population size. Here, one considers a sequence of processes in which
time is sped up by a factor of N and the recombination probabilities rA are rescaled such that
limN →∞ N rA → ̺A , ̺A a constant, for A ∈ O2 (S); consequently, r1 → 1 as N → ∞. Note that
the ̺A are rates rather than probabilities. The corresponding ARG is the obvious generalisation
of Hudson’s original ARG to n loci, which we formulate here in our framework for the sake of
completeness, as follows. Every ordered pair of lines coalesces at rate 1; every line splits into
two at rate ̺A for every A ∈ O2 (S), and the ancestral material is distributed between the new
lines according to A.
In this formulation, however, certain silent events are included, namely those events that happen
in non-ancestral material flanking the ancestral parts. These events do not affect the partitioning
of ancestral material and may be removed by working with the marginalised recombination rates
instead. That is, if a sequence currently carries a set U of ancestral sites, then the relevant
recombination rates (in the diffusion limit) are ̺ BU , with B ∈ O2 (U ), which are defined as in (9)
but with r replaced by ̺. If we now restrict attention to the ancestry of n loci partitioned
between m individuals, we obtain the marginal version of the ARG, which may be formulated
as follows.
Definition 2 (Marginalised n-locus ARG). Start with the set of n sites distributed across m 6 n
individuals (or lines) according to a partition Σ0′′ with m parts. Throughout the process, every
line is identified with the ancestral material it carries. If it currently carries ancestral sites
U ⊆ S, it splits into J ∈ O2 at rate ̺JU . Every ordered pair of lines coalesces at rate 1, and
so do the ancestral sites they carry. That is, the marginalised ARG is the partitioning process
{Σt′′ }t>0 defined by the generator Θ ′′ with nondiagonal elements
 A

̺ j , if B = AM \j ∪ J for some j ∈ M, J ∈ O2 (Aj ),


 J
′′
ΘAB
= 2,
if B ≻ A and |B| = |A| − 1,




0,
for all other B 6= A.

Proposition 2 (Diffusion limit of the partitioning process). In the diffusion limit, the sequence
(N )
(N )
of partitioning processes {ΣN t }t>0 with initial states Σ0 ≡ σ converges in distribution to the
process {Σt′′ }t>0 with initial state Σ0′′ = σ and generator Θ ′′ .
(N )

(N )

Proof. Due to the rescaling of time, the generator of {ΣN t }t>0 has nondiagonal elements N ΘAB .
(N )
′′ , since we have r U → 1 and
Referring back to (12), they converge to limN →∞ N ΘAB = ΘAB
1
N rJU → ̺JU for J ∈ O2 (U ). With the same argument as in the proof of Proposition 1, one
obtains convergence in distribution as claimed.
As was to be expected, only pure splitting events and pure coalescence events survive in the
diffusion limit. The ‘mixed transitions’, which involve both splitting and coalescence (i.e. the
dashed lines in Figure 2) vanish under the rescaling; see also Hein et al. (2005, Fig. 5.11).
- 14 -

5 Recombinators and sampling functions
In this section, we will have a closer look at three operators associated with recombination and
how they are related to each other. We start by generalising our recombinators, then introduce
closely related sampling functions and finally multilocus correlation functions, known as linkage
disequilibria.
Recombinators. We have already met RA for A ∈ O62 (S); we now need the generalisation
to arbitrary A ∈ P(S). For ω ∈ M+ (X) \ 0, we first define the non-normalised recombinator via


(13)
RA (ω) = : πA1.ω ⊗ · · · ⊗ πAm.ω : ,

where the symbol : . . . : means ‘site ordering’ and is used to indicate that the product measure
refers to the ordering of the sites as specified by the set S. When the meaning is clear, we drop
these extra symbols. In words, RA turns ω into the product of its marginals with respect to
the blocks in A. We will throughout denote non-normalised mappings by an overbar. Clearly,
R∅ (ω) = kωk, R1 (ω) = ω and kRA (ω)k = kωk|A| . The corresponding normalised version is
RA (ω)

RA (ω) := 
RA (ω) ,

(14)

which is well-defined since ω 6= 0. Obviously, RA (ω) = RA (ω/kωk) and RA (ω) is a probability
measure on X, which coincides with (6) for A ∈ O62 (S).
Let us now give a probabilistic interpretation for the case that a recombinator RA acts on a
certain population described by a counting measure z ∈ E. For the moment, attach labels
1, 2, . . . , N to the N individuals in the population, and let these individuals
PN have (random)
1
2
N
types Xt , Xt , . . . , Xt ∈ X at time t. The type distribution then is Zt = k=1 δX k . For U ⊆ S
t
k := π (X k ), and consider the following procedure. Let a partition
and k ∈ {1, . . . , N }, let Xt,U
t
U
A = {A1 , . . . , Am } of S together with a collection of labels ℓ = (ℓ1 , . . . , ℓm ) ∈ {1, . . . , N }m
associated with the blocks be given, i.e., (A, ℓ) := {(A1 , ℓ1 ), . . . , (Am , ℓm )}. Then, piece together
a sequence by taking the sites in A1 from individual ℓ1 , the sites in A2 from individual ℓ2 , . . .
ℓ1
ℓm
ℓ
the sites in Am from individual ℓm . The resulting sequence is Xt,A
:= (Xt,A
, . . . , Xt,A
). We
m
1
are now interested in the event


	

Xt,A = x :=

.
[

ℓ∈{1,...,N }m

 ℓ
	
Xt,A = x

and the corresponding counting measure |{Xt,A = x}|. Clearly, this counts how often one obtains
sequence x when performing the above procedure on a population Zt and all combinations of
individuals are included. Let us emphasise that individuals are combined with replacement, that
is, two or more blocks may come from the same individual. Therefore, the event {Xt,A = x}
may also be understood as the union of the independent events {Xt,Aj = xAj }, j ∈ M , where

	
Xt,Aj = xAj :=

.
[

 ℓj
	
Xt,Aj = xAj .

(15)

ℓj ∈{1,...,N }

Therefore,
Y 
Y


	

	
 Xt,A = x  =
 Xt,A = xA  =
πAj .Zt (xAj ) = RA (Zt ) (x).
j
j
j∈M

j∈M

- 15 -

(16)

Clearly, RA (Zt ), the corresponding normalised version, is the type distribution that results when
a sequence is created by taking the letters for the blocks in A from individuals drawn uniformly
and with replacement from the population Zt . So



RA (z) (x) = P Xt,A = x | Zt = z ,
where P denotes probability. Note that the left-hand side depends on time only through the
value of Zt .

Sampling function. For A ∈ P(S) and ω ∈ M+ (X) \ 0, we now define our sampling function
X
HA (ω) :=
µ(A, B) RB (ω),
(17)
B<A
˙

where µ is the Möbius function in Eq. (2). HA (ω) is not a positive measure in general; but it
will turn out as positive for the important case where ω ∈ E with kωk > |A|, see Lemma 1.
We will therefore postpone the normalisation step. In any case, Möbius inversion (compare (3)
and (4)) immediately yields the inverse of (17):
Fact 1. For every A ∈ P(S),
RA (ω) =

X

HB (ω).

B<A
˙

We can now give HA a meaning by reconsidering the procedure that led to (16) but, this time,
individuals are not replaced. That is, for |A| 6 N , we now look at the events
.
[

	
 ℓ
	
et,A = x :=
X
Xt,A = x
(18)
ℓ∈{1,..., N }m
ℓi 6=ℓj ∀ i6=j

et,A = x}|. Since individuals are not replaced, the
and the corresponding counting measure |{X
e
e are now dependent; an
events {Xt,Aj = xAj }, j ∈ M (defined as in (15) with X replaced by X)
et,A = x}| analogous to (16) is therefore not immediate. Instead, we resort to
expression for |{X
an inclusion-exclusion argument and prove
Proposition 3. For A ∈ P(S) with |A| 6 N and Zt ∈ E, we have


	
 X
et,A = x  = HA (Zt ) (x).

Proof. Fix a given partition A ∈ P(S) with |A| = m 6 N . For every ℓ ∈ {1, 2, . . . , N }m , the
pair (A, ℓ) uniquely defines a pair (B, ℓ̃), where ℓ̃ ∈ {ℓ ∈ {1, 2, . . . , N }|B| : ℓj 6= ℓk ∀ j 6= k}
and B < A, as follows. Join all blocks of A that have the same label, and attach that label
to the new block. The result is (B, ℓ̃). The other way round, every (B, ℓ̃) with B < A and
ℓ̃ ∈ {ℓ ∈ {1, 2, . . . , N }|B| : ℓj 6= ℓk ∀ j 6= k} uniquely defines the labelling ℓ of the blocks of A
(keep in mind that A is fixed): block Ak ∈ A receives the label of that block Bj ∈ B in which
it is contained. We can therefore identify the set {(A, ℓ) : ℓ ∈ {1, 2, . . . , N }m } with the set
S
|B| : ℓ 6= ℓ ∀ j 6= k}. With (16) and (18) in mind, we can
j
k
B <A {(B, ℓ̃) : ℓ̃ ∈ {ℓ ∈ {1, 2, . . . , N }
˙
Ṡ
et,B = x}, which entails
therefore decompose the event {Xt,A = x} = B<A {X
˙


	
	 X 
et,B = x .
 X
 Xt,A = x  =
B<A
˙

By (16), the left-hand side equals (RA (Zt ))(x). Due to the Möbius inversion principle (applied
et,B = x}| on the right-hand side must equal (H (Zt ))(x), as claimed.
backwards), |{X
B
- 16 -

Lemma 1. For A ∈ P(S) with |A| = m 6 N and z ∈ E, HA (z) is a positive measure with


H (z) = N (N − 1) · · · (N − m + 1) > 0.
A

et,A = x | Zt = z}| > 0 for all x by
Proof. Since, under the given assumptions, (HA (z))(x) = |{X
Proposition 3, it is a positive measure, and its norm can be evaluated via

 X 
	
HA (z) =
 X
et,A = x | Zt = z .
x∈X

By means of (18), this equals the number of possibilities of how to choose m labelled individuals
out of N ones without replacement, where the order is respected; this is N (N −1) · · · (N −m+1),
which is positive since m 6 N .
Under the assumptions of Proposition 3, we can therefore define the normalised version of HA (z):
(N − m)!
HA (z)
 =
HA (z) := 
HA (z).
HA (z)
N!

(19)

HA (z) is the type distribution that results when a sequence is created by taking the letters for
the blocks as encoded by A from individuals drawn uniformly and without replacement from the
population z, hence



et,A = x | Zt = z .
HA (z) (x) = P X

HA will later serve as duality function. The situation described here is exactly what happens
when a sample is taken in our marginal ancestral recombination process: either the initial sample
(according to Σ0 , from the present population Zt ) or the ancestral one (according to Σt , from
the initial population Z0 ) – hence our name sampling function. In this light, Fact 1 expresses
counting with replacement in terms of counting without replacement, provided ω is a counting
measure.
It is also instructive to express the normalised sampling functions in terms of the normalised
recombinators. For z ∈ E and |A| 6 N , this gives, via (14),
HA (z) =

X (N − |A|)! N |B|
µ(A, B) RB (z).
N!

B<A
˙

Note that (N − |A|)! N |B| /N ! = O(N |B|−|A| ). This illustrates how the inclusion of coarser
partitions yields higher-order correction terms. The other way round, using (14), Fact 1,
and (19), one gets
X
N!
H (z).
(20)
RA (z) =
|A|
N (N − |B|)! B
B<A
˙

Restriction to subsystems. Recall that we write the restriction of a measure ω ∈ M+ (X)
to a subspace XU := ×i∈U Xi of X as πU .ω := ω ◦ πU−1 , which corresponds to marginalisation.
Clearly we can also define recombinators for any non-empty subset U ⊆ S and any partition
U
S
A = {A1 , . . . , Am } ∈ P(U ) as RA (πU .ω), in perfect analogy with RA (ω) for A ∈ P(S), which
U
U
U
is RA (ω); and likewise for RA , HA , and HA (if ω 6= 0). For clarity, we sometimes denote the
subsystem by a superscript. However, as in the case of the marginal recombination probabilities,
|A|
it can be dispensed with since U = ∪j=1 Aj if A ∈ P(U ). The interpretation in terms of sampling,
as well as Fact 1, carry over.
Let us collect some basic properties of recombinators:
- 17 -

Fact 2. For A, B ∈ P(S) and U, V ⊆ S with S = U ∪˙ V one has
(A) RA RB = RA∧B .
U
(B) πU .RAS (ω) = RA|
(πU .ω).
U

S

U

V

(C) If in addition A 4 {U, V }, then RA = RA|U ⊗ RA|V . Explicitly, this reads


S
U
V 
U
V
RA (ω) = RA|U ⊗ RA|V (ω) = RA|U (πU .ω) ⊗ RA|V (πV .ω) .

Here and in what follows, we may omit the argument when the meaning is clear.
Proof of Fact 2. Property (A) is Proposition 2 and property (B) is Lemma 1 of Baake et al.
(2015) (they both remain true in our normalisation). Property (C) is an obvious generalisation
of Proposition 2 of von Wangenheim et al. (2010). It is easily seen by using first property (A),
then (13), then (B) and finally (13) once more to give

S
S
S
S
S 
RA (ω) = R{U,V } RA (ω) = πU .RA ⊗ πV .RA (ω)


U
V
U
V 
= RA|U (πU .ω) ⊗ RA|V (πV .ω) = RA|U ⊗ RA|V (ω).

Let us note a connection between recombination and sampling that will be important in what
follows.
Lemma 2. Let S = U ∪˙ V for two nonempty subsets U, V ⊆ S. For two partitions A ∈ P(U ),
B ∈ P(V ), the recombinator and the sampling operator satisfy
X
U
V
S
RA ⊗ HB =
HC .
C <A∪B
˙
C|V =B

Proof. Using (17) followed by Fact 2 (C) and Fact 1 we get
 X
X
X
X
U
V
U
V
S
S
µ(B, D) RD∪A =
µ(B, D) RD =
RA ⊗ HB = RA ⊗
µ(B, D)
HE .
D <B

D<B

˙

˙

D<B
˙

E <D∪A
˙

Changing the summation order and applying (2) finally leads to
X
X
X
U
V
S
S
µ(B, D) =
RA ⊗ HB =
HC
HC .
C <A∪B
˙

B4D4C|V
˙

C <A∪B
˙
C|V =B

Remark 5. In a perfectly analogous way, one can show
X
U
V
S
HA ⊗ HB =
HC .
C <A∪B
˙
C|U =A, C|V =B

This illustrates once more that, unlike the RA , the HA do not have a product structure; this
reflects the dependence inherent to drawing without replacement.
♦

- 18 -

Correlations (or linkage disequilibria). Linkage disequilibria (LDE) are used in population
genetics to quantify the deviation from independence of allele frequencies at the various sites in a
sequence. From three sites onwards, many different notions of linkage disequilibria are available
in the literature, see Bürger (2000, Chap. V.4.2) for an overview.
We will use as LDEs the general correlation functions, which are widely used in statistical
physics, see Dyson (1962) or Mehta (1991, Chap. 5.1.1). This results in an explicit formula
for multilocus LDEs for an arbitrary number of sites in terms of sums of products of marginal
frequencies, see also Baake and Baake (2003, Appendix) or Gorelick and Laubichler (2004). As
we will see, common definitions for two and three sites coincide with ours.
For any given subset U ⊆ S and A ∈ P(U ), we first define correlation operators as
X
U
U
LA =
µ(B, A) RB .
(21)
B4A
˙

Note that the summation is now over all refinements of A, in contrast to our sampling functions,
which involve all coarsenings of A. The restriction to subsystems stems from the fact that one
usually considers deviation from independence on small subsets of S.
Q|A| A
U
U
The LA have a product structure, LA = j=1 L1 j , which is obvious from (21) together with the
product structure of the recombinators (Fact 2 (C)) and that of the Möbius function (Eq. (2)).
Eq. (21) has the inverse
|B|
X U
X Y
B
U
L1 j
RA =
LB =
B4A

B4A j=1

˙

˙

due to inversion from below (see Section 2). The latter can be reformulated as
U
LA

=

U
RA

−

|B|
X Y

B

L1 j .

(22)

B≺A j=1
˙

The case A = 1|U , U ⊆ S, now is of special interest. In line with population-genetics
understanding, we define the multilocus linkage disequilibrium with respect to the sites in U
by letting LU1 act on the marginal measure πU .ω, ω ∈ M+ (X) \ 0:
X
LU1 (πU .ω) =
µ(A, 1|U ) RAU (πU .ω),
A∈P(U )

cf. Eq. (21). Note that L1U (πU .ω) is again a measure on πU (X), but no longer positive in general.
With the help of (22), it can be reformulated as
U
L1 (πU .ω)

=

U
R1 (πU .ω) −

|B|
X Y

B

L1 j (πBj .ω),

B≺1|U j=1
˙

which is Eq. (1) in Gorelick and Laubichler (2004). Likewise, this alternative formulation of
multilocus LDEs agrees with previous ones from Geiringer (1944), Bennett (1954), and Hastings
(1984) up to |U | 6 3.
Example 2. For S = {1, 2, 3, 4} the LDE with respect to the sites in U = {2, 4} reads
U

U

U

L1 (π{2,4} .ω)(x) = R1 (π{2,4} .ω)(x) − R{{2},{4}} (π{2,4} .ω)(x)
=

1
1
ω(∗, x2 , ∗, x4 ) −
ω(∗, x2 , ∗, ∗) ω(∗, ∗, ∗, x4 ).
kωk
kωk2
- 19 -

♦
The correlation operators can also be expressed in terms of our sampling operators. Eqns. (21)
and (20), together with a change of the summation order, lead to
U

LA =

X

B4A
˙

µ(B, A)

X

C <B
˙

X
X
N!
N!
U
U
H
=
H
µ(B, A).
C
C
(N − |C|)! N |B|
(N − |C|)! N |B|
C∈P(U )

(23)

B4A∧C
˙

For a counting measure z ∈ E and U ⊆ S with |U | = k 6 3 6 N , Eq. (23) yields a particularly
nice explicit expression for the LDEs:
LU1 (πU .z) =

X
N!
µ(A, 1|U ) HAU (πU .z),
− k)!

N k (N

(24)

A∈P(U )

as is easily verified. For larger k, the explicit formula gets more involved.
U
Let us now consider LA
for A ∈ P(U ) \1|U . Due to its product structure, the collection of all
V
U
L1 (πV .ω), V ⊆ U , determines all LA
(πU .ω), A ∈ P(U ). This is why, for a deterministic ω, the
U
LA (πU .ω), A =
6 1|U , are of no particular interest of their own. This changes, however, when ω is
random (like Zt ). For we typically do not know the law of Zt completely; rather, we have access
to the expectation of certain functions of Zt . More precisely, let ϕ be the law Rof Zt and Eϕ
denote the expectation with respect to ϕ (that is, for a function f of Zt , Eϕ [f ] = f (z) dϕ(z)).
It is important to note that the product structure of the recombined measure does not carry over
to the expectation. That is, for A ∈ P(U ), Eϕ [RAU (πU .Zt )] 6= RAU (Eϕ [πU .Zt ]) in general, see the
Q|A|
U
i
discussion in Baake and Herms (2008). Consequently, Eϕ [LA
(πU .Zt )] 6= i=1 LA
1 (πAi .Eϕ [Zt ])
U

in general. In the stochastic case, therefore, it is interesting to consider the LA for A 6= 1|U
U
as well. The expectations Eϕ [LA (πU .Zt )] contain information on how the mean LDEs in one
part of the sequence depend on the mean LDEs in other parts of the sequence. In the next
S
section, we will obtain an ODE system for the Eϕ [HA (Zt )], A ∈ P(S), and these translate into
S
Eϕ [RAS (Zt )] and thus into Eϕ [LA
(Zt )] via (23). Marginalisation can then be used to calculate
U
the corresponding quantities on U ⊂ S, such as Eϕ [LA
(πU .Zt )] for A ∈ P(U ).

6 Duality
Duality is a powerful tool to obtain information about one process by studying another, the dual
process. The latter may, in an optimal case, have a much smaller state space than the original
one. Duality results are essential in interacting particle systems in physics and in population
genetics. They are often related to time reversal. The most famous example in population
genetics is arguably the moment duality between the Wright-Fisher diffusion forward in time
and the block counting process of Kingman’s coalescent backward in time (Donnelly 1986; Möhle
2001). Mano (2013) extended this result by incorporating recombination into the two-locus,
two-allele case. His results are based on the original version of the ARG and thus on the
diffusion limit.
We will briefly explain the general duality concept and then prove that our processes {Zt }t>0
and {Σt }t>0 are duals of each other. For the general principle, let X = {Xt }t>0 and Y = {Yt }t>0
be two Markov processes with state spaces E and F . Define by M (E ×F )b the set of all bounded
measurable functions on E × F . The following definition of duality with respect to a function
goes back to Liggett (1985); see also the recent review by Jansen and Kurt (2014).

- 20 -

Definition 3 (Duality). The Markov processes X and Y , with laws ϕ and ψ, respectively, are
said to be dual with respect to a function H ∈ M (E × F )b if, for all x ∈ E, y ∈ F and t > 0,
Eϕ [H(Xt , y) | X0 = x] = Eψ [H(x, Yt ) | Y0 = y] .

(25)

If E and F are finite, every function H ∈ M (E × F )b may be represented by a matrix with
bounded entries H(v, w), v ∈ E, w ∈ F . If, further, X and Y are time-homogeneous with
generator matrices Θ and Λ respectively, the expectations in equation (25) may be written in
terms of the corresponding semigroups, i.e.,
X
Eϕ [H(Xt , y) | X0 = x] =
(etΘ )xv H(v, y),
v∈E

Eψ [H(x, Yt ) | Y0 = y] =

X

(etΛ )yw H(x, w).

(26)

w∈F

Since the duality equation (25) is automatically satisfied at t = 0, it is sufficient to check the
identity of the derivatives at t = 0. That is, Eq. (25) holds for all times if and only if
X

d
Eϕ [H(Xt , y) | X0 = x] t=0 =
Λxv H(v, y)
dt
v∈E
X

d
=
H(x, w) Θyw =
Eψ [H(x, Yt ) | Y0 = y] t=0
dt

(27)

w∈F

for all x ∈ E, y ∈ F . As a short-hand of Eq. (27), one can write Λ H = HΘT , where T denotes
transpose.
We will now present a duality result that justifies our construction of a marginalised sample
at present via the partitioning process and sampling from the initial population (cf. Figure 4).
Indeed, it is not coincidence that we have denoted our sampling functions by HA and our
generators by Λ and Θ.
Theorem 1. The population process {Zt }t>0 and the partitioning process {Σt }t>0 with the
generators Λ and Θ and resulting laws ϕ and ψ, respectively, are dual with respect to the sampling
function H defined in Eq. (19). Explicitly,
Eϕ [HA (Zt ) | Z0 = z] = Eψ [HΣt (z) | Σ0 = A]

(28)

for all A ∈ P(S) and z ∈ E.
Before we embark on the proof, let us briefly comment on the meaning of this result.
Remark 6. Eq. (28) is the formal equivalent of the construction in Figure 4. To see this,
et,A from (18). With their help, the left-hand side of (28) may be
recall the random variables X
reformulated as a probability distribution,






et,A = · | Z0 = z ,
et,A = ·] | Zt , Z0 = z = Pϕ X
Eϕ HA (Zt ) | Z0 = z = Eϕ [P X

since the expectation is over all realisations of Zt . The right-hand side is the probability
distribution considered by Bobrowski et al. (2010). Likewise, the right-hand side of (28) is
equal to






e0,Σt = · | Σ0 = A ,
e0,Σt = ·] | Σt , Σ0 = A = Pψ X
Eψ HΣt (z) | Σ0 = A = Eψ P[X

since the expectation is over all realisations of Σt . The right-hand side is the distribution of types
when sampling from the initial population according to the partition Σt , where it is understood
- 21 -

that the initial population consists of the types X01 , . . . , X0N with
et,A , but backwards in Σt .
time runs forward in Zt , Xtk , and X

PN

k=1 δX0k

= z. Recall that
♦

In order to avoid case distinctions in the calculations in the remainder of this section, let us agree
on the following conventions concerning (partitions of) empty sets. Namely, we set A∅ := ∅,
H∅ (π∅ .z) = R∅ (π∅ .z) := π∅ .z = kzk = N , and µ(∅, ∅) := 1. We now collect some auxiliary
results in the following Lemma.
Lemma 3. Consider a counting measure z ∈ E, a partition A ∈ P(S) with |A| = m 6 N
and corresponding index set M = {1, . . . , m}, and a partition B ∈ P(S). Then, the following
statements hold:

X
 X


HAM \j ⊗ RB|A (z).
(A)
RB (z) (x) HA (z + δx ) − HA (z) =
(B)

X

y∈X

j

j∈M

x∈X



z(y) HA (z − δy ) − HA (z) = −m HA (z).

Note that the left-hand side of statement (B) is always well-defined, since z − δy < 0 can only
occur with z(y) = 0, in which case the term vanishes. Note also that, with the above conventions,
the right-hand side of identity (A) evaluates to

X
(z) = N RB (z) if A = 1.
HAM \j ⊗ RB|
Aj

j∈M

Proof. We first observe that
X
X



RB (z) (x) δx = πU . RB (z) = RB|U (πU .z)
RB (z) (x)(πU .δx ) = πU .

(29)

x∈X

x∈X




P
by Fact 2. We next evaluate
x∈X RB (z) (x) RA (z + δx ) − RA (z) by expanding RA to
separate the action on z from that on δx , summing against RB (z) (using (29)), applying Fact 1
and changing summation:
X



RB (z) (x) RA (z + δx ) − RA (z)
x∈X

=

X

x∈X


X 

RB (z) (x)
RAM \J (πAM \J .z) ⊗ πAJ .δx )

X 

=

∅6=J ⊆M
˙

RAM \J ⊗ RB|

∅6=J ⊆M

AJ

˙

=

|D| 
X X

D <A j=1
˙

HD\Dj ⊗ RB|


(z) =

Dj

X

X

∅6=J ⊆M C <AM \J
˙

˙



HC ⊗ RB|

AJ


(z)


(z),

where, in the last step, every AJ reappears as one Dj . Using this together with (17) and (2),

- 22 -

we obtain
X
X




 X

RB (z) (x) HA (z + δx ) − HA (z) =
RB (z) (x) RC (z + δx ) − RC (z)
µ(A, C)
C <A

x∈X

x∈X

˙

=

X

µ(A, C)

C <A

HD\Dj ⊗ RB|D

D <C j=1

˙

=

|D| 
X X

j

˙

|D| 
X X

HD\Dj ⊗ RB|D

D<A j=1

j

˙



X

(z)


(z)
X

µ(A, C) =

A4C 4D

HAM \j ⊗ RB|A

j

j∈M

˙


(z),

which is statement (A).
In an analoguous way, we can prove statement (B):
X

y∈X



z(y) RA (z − δy ) − RA (z) =
X

=



(−1)|J| RAM \J

∅6=J ⊆M
˙

X

=

|J|

(−1)

˙

X

(−1)|J|

∅6=J ⊆M


A
⊗ R1 J (z) =

X

˙

X

y∈X

˙

HB (z) =

B<AM \J ∪AJ

∅6=J ⊆M

=

X

X


 

A
z(y) RAM \J (πAM \J .z) ⊗ R1 J (πAJ .δy )

∅6=J ⊆M
˙

X



(−1)|J| RAM \J ∪AJ (z)

HC (z)

C <A
˙

|C|
X

X

(−1)|K|

j=1 ∅6=K ⊆Cj
˙

|C|

HC (z)

C <A
˙

i
Xh
X
(1 − 1)|Cj | − 1 = −
|C| HC (z),
C <A

j=1

˙

where, in the second-last step, every AJ reappears as a Cj . We therefore get
X
X

 X


z(y) HA (z − δy ) − HA (z) =
µ(A, B)
z(y) RB (z − δy ) − RB (z)
B<A

y∈X

=−

X

˙

µ(A, B)

B<A

X

|C| HC (z) = −

C <B

˙

y∈X

X

C <A

˙

˙

|C| HC (z)

X

µ(A, B)

A4B 4C
˙

= −|A| HA (z),
as claimed.
We can now proceed as follows.
Proof of Theorem 1. We start with the partitioning process. We first note that

X
N − (m − 1) !
= N |J |
(N − |B|)!

(30)

B<AM \j ∪J
˙
B|A
=AM \j
M \j

for j ∈ M and |J | 6 2. This is easily verified by direct calculation; namely, for |J | = 1, the
sum on the left-hand side equals (N − (m − 1)) + (m − 1) = N ; for |J | = 2, it evaluates to
(N − (m − 1)) (N − m) + (N − (m − 1)) (2m − 1) + (m − 1)2 = N 2 .
- 23 -

We now use the formulation of the process via (10) and (11) in the first step, normalisation
and (30) in the second, Lemma 2 in the third, and finally another normalisation step to calculate

X
X
X
X

rJ
N − (m − 1) !
ΘAB HB (z) =
HB − HA (z)
|J |
N
(N − |B|)!
B<AM \j ∪J
˙
B|A
=AM \j

j∈M J ∈O62 (Aj )

B∈P(S)

M \j

=

X

X

j∈M J ∈O62 (Aj )

X

rJ
N |J |

B<AM \j ∪J
˙
=AM \j
B|A

!
!

N − (m − 1) !
HB − N |J | HA (z)
N!

M \j

!


rJ
N − (m − 1) ! 
|J |
=
HAM \j ⊗ RJ − N HA (z)
N |J |
N!
j∈M J ∈O62 (Aj )


X
X
(31)
=
rJ HAM \j ⊗ RJ − HA (z).
X

X

j∈M J ∈O62 (Aj )

We now turn to the type distribution process. Here we first evaluate, with Lemma 3 (B), that
X



z(y) HA z + δx − δy − HA (z)
y∈X

=

X

y∈X

=

X

y∈X

 X
(z + δx )(y) HA (z)
(z + δx )(y) HA (z + δx ) − δy −




y∈X


(z + δx )(y) HA (z + δx ) − δy − HA (z + δx ) + HA (z + δx ) − HA (z)



= (N + 1 − m) HA (z + δx ) − HA (z) − m HA (z).

From this, we obtain via summation against RB (z) and use of Lemma 3 (A) that
XX



RB (z) (x) z(y) HA (z + δx − δy ) − HA (z)
x∈X y∈X

= (N + 1 − m)

X

HAM \j ⊗ RB|

j∈M

Aj



(32)

(z) − m HA (z).

P
We now have to examine z ′ ∈E Λzz ′ HA (z ′ ) for an arbitrary partition A of S. To this end, we
use (7) and normalisation, followed by (32) and a change of summation involving (9) to calculate
X
X
λ(z; y, x) [HA (z + δx − δy ) − HA (z)]
Λzz ′ HA (z ′ ) =
z ′ ∈E

x,y∈X

=

(N − m)!
N!

X

rB

X

x,y∈X

B∈O62 (S)




RB (z) (x) z(y) HA (z + δx − δy ) − HA (z)

 (N − m)!
i
h (N − (m − 1))! X
X
−
HAM \j ⊗ RB|
=
rB
m HA (z)
Aj
N!
N!
j∈M
B∈O62 (S)

X
X
HAM \j ⊗ RB| − HA (z)
=
rB
B∈O62 (S)

=

X

X

X

X

Aj

j∈M

X

j∈M J ∈O62 (Aj ) B∈O62 (S)
B|A =J

=

j∈M J ∈O62 (Aj )



rB HAM \j ⊗ RJ − HA (z)

j


rJ HAM \j ⊗ RJ − HA (z),


- 24 -

which agrees with (31) and proves the claim.
We can now harvest some interesting consequences. First, Eq. (31) contains a meaningful
expression for the derivative:
Corollary 1. For A ∈ P(S), z ∈ E, and the population process {Zt }t>0 , we have
X

d
Eϕ [HA (Zt ) | Z0 = z] t=0 =
dt

X

j∈M J ∈O62 (Aj )



A
A
A
S
rJ j RJ j ⊗ HAMM\j\j − HA (z).

The right-hand side has a plausible explanation. Namely, when block Aj splits into J , the other
blocks in A retain their current type distribution (namely, HAM \j (πAM \j .z)). Independently of
this, the parts of J pick their types from all individuals (with replacement), including those
individuals that already carry other parts of AM \j , which is expressed by the tensor product
with RJ (πAj .z).
Next, via (26) together with the fact that HA (z) = Eϕ [HA (Zt ) | Zt = z], Eqns. (27) and (28)
give rise to a system of differential equations for the expectations, namely:
Corollary 2. For A ∈ P(S) and the population process {Zt }t>0 , one has
X
d
Eϕ [HA (Zt )] =
ΘAB Eϕ [HB (Zt )] .
dt
B∈P(S)

This will be the basis for our concrete calculations in the next section.

7 Applications and examples
Let us now apply our results to the cases of n = 2 and n = 3 sites. Expectations will always be
with respect to ϕ, so we will abbreviate Eϕ by E throughout. We will assume that Z0 = z, i.e.,
that the initial population is deterministic.
Two sites. For U = S = {1, 2}, with the abbreviation r := r{{1},{2}} , the ODE system of
Corollary 2 reads



d 
N −1 
E H{{1,2}} (Zt ) = r
E H{{1},{2}} − H{{1,2}} (Zt )
dt
N



2 
d 
E H{{1},{2}} (Zt ) =
E H{{1,2}} − H{{1},{2}} (Zt ) ,
dt
N

where we have dropped the upper index, which is always U . It follows that







2
N −1
d 
E H{{1,2}} − H{{1},{2}} (Zt ) = −
+r
E H{{1,2}} − H{{1},{2}} (Zt ) .
dt
N
N

(33)

(34)

Since L{{1,2}} = NN−1 (H{{1,2}} − H{{1},{2}} ), it follows that the expected two-point LDE also
decays at rate 2/N + r(N − 1)/N . In the case of two alleles per site, an equivalent formula has
appeared in Bobrowski and Kimmel (2003, Ex. 1). The corresponding result in the diffusion
limit goes back to Ohta and Kimura (1969), see also Durrett (2008, Chap. 8.2). As noted there,
it may seem surprising that the correlations also decay via resampling (even if r = 0); but recall
that our Moran model with recombination is an absorbing Markov chain where a single type
goes to fixation in the long run, that is, Zt will ultimately end up in a point measure.
- 25 -

The expected type distribution is now easily obtained from (33) and (34) via
Z






N −1 t 
E H{{1,2}} (Zt ) = E H{{1,2}} (Z0 ) − r
E H{{1,2}} − H{{1},{2}} (Zτ ) dτ
N
0

 r(N − 1) + 2  


r(N − 1)
Z0
1 − exp −
+
t E H{{1,2}} − H{{1},{2}} (Z0 ) ,
=
N
r(N − 1) + 2
N


where we have used that E H{{1,2}} (Z0 ) = Z0 /N . The asymptotic behaviour is given by
 
Z0
r(N − 1)
Zt
2
+
H
(Z0 ).
(35)
lim E
=
t→∞
N
2 + r(N − 1) N
2 + r(N − 1) {{1}{2}}
Since Zt will ultimately absorb in a point measure, we also know that
  X
Zt
lim E
=
P[Zt absorbs in x] δx ,
t→∞
N
x∈X

and thus P[Zt absorbs in x] = limt→∞ E[Zt /N ](x) for all x ∈ X. We can therefore read off the
2
fixation probabilities from (35). With probability 2+r(N
−1) (the relative intensity of resampling),
r(N −1)
the type that wins is drawn from the initial distribution. With probability 2+r(N
−1) (the relative
intensity of recombination), it is drawn from the distribution that results when the leading and
the trailing segments are sampled from the initial population without replacement.

Three sites. Now, consider U = S = {1, 2, 3}, together with the abbreviations r1 = r{{1}{2,3}}
and r2 = r{{1,2}{3}} . Let us order the partitions of P(U ) as follows:
{{1, 2, 3}}

{{1}, {2, 3}}

{{1, 2}, {3}}

{{1, 3}, {2}}

The generator of the partitioning process then reads
 − N−1 (r +r )
N−1
N−1
r
r
1

N

2

N

1

 2 − N−1 r2 − 2 − (N−1)2 r2
 N N
N
N2

N−1
N−1

2
Θ =  N − N r1
r1
N2

 N2 − N−1
(r1 +r2 ) N−1
2 (r1 +r2 )
N

N−1
r2
N2

2

2
N

2
−N
−

N−1
(r1 +r2 )
N2
2
N

(N−1)2
N2
2
N




(N−1)(N−2)
.
r1

N2

(N−1)(N−2)
(r1 +r2 ) 
2
(N−1)(N−2)
r2
N2

N−1
r1
N2

N



0

N−1
r2
N2

2
− (N−1)
−N
r1
2

N

0

0

2

N

{{1}, {2}, {3}}.

(r1 +r2 )

(36)

N

6
−N

d
E[H(Zt )] = ΘE[H(Zt )], where H(Zt ) := (HAU (Zt ))A∈P(U ) .
Recall that, by Corollary 2, we have dt
We now transform this system into a system in terms of correlation functions. Therefore, let
U
L(Zt ) = (LA (Zt ))A∈P(U ) . From (23), we know that L(Zt ) = T H(Zt ), where the transformation
matrix is given by

1
−1
−1
−1
2 

T =

Consequently,

d
dt

(N −1)(N −2)
N2





1
N−2
1
N−2
1
N−2
1
(N−1)(N−2)

1
− N−2
1
− N−2
1
N−2

E[L(Zt )] = T ΘT −1 E[L(Zt )], where
 6 (N−1)(N−2)
(r1 +r2 )
N2
(N−1)
2
−
(r
+r
1
2)
N
N2
(N−1)
2
(r1 +r2 )
−
N
N2
(N−1)
2
−
(r1 +r2 )
N
N2
1
− 2 (r1 +r2 )
N

−1



=



−1
N−2
1
1+ N−2
1
− N−2
1
N−2

0

−N −

T ΘT

1
1+ N−2

2
− N−1
r2
−N
N

0
0

2
N

1
−N
r2

- 26 -

2
−N

−1
N−2
1
− N−2
1
1+ N−2
1
N−2

−1



−1

−1  .
1



0

0

0

0

0

0

− N−1
r1
N
0

1
2
−N
r1
N

0



0
.

2
− N−1
(r1 +r2 ) 0 
−N
N
1
2
−N
N

(r1 +r2 )

0

(37)

In contrast to (36), the matrix T ΘT −1 has a nice subtriangular structure, from which we can
already read off that the expected three-point LDE E[L{{1,2,3}} (Zt )] (cf. (24)) decays exponentially
according to
!



d 
6N + (N − 1)(N − 2)(r1 + r2 )
E L{{1,2,3}} (Zt ) = −
E L{{1,2,3}} (Zt ) .
2
dt
N
As in the case of two sites, the decay rate contains contributions from resampling as well as
from recombination. To extract more information, we recast T ΘT −1 into the diagonal form
V T ΘT −1 V −1 = D, where the entries of the diagonal matrix D are those on the diagonal of
d
V −1 E[L(Zt )] = DV −1 E[L(Zt )].
T ΘT −1 , i.e., its eigenvalues. Consequently, dt
With the help of the subtriangular structure of T ΘT −1 , the matrix V −1 can be calculated
explicitly. It is again subtriangular, but somewhat unwieldy. To streamline the results, we now
turn to the diffusion limit, with generator Θ′′ of Definition 2. Then T and T −1 converge to
′′ = µ(B, A) δ
′′ −1
matrices T ′′ and (T ′′ )−1 , respectively, with elements TAB
B4A and (T )AB = δB4A ,
A, B ∈ P(U ) (the latter is due to inverison from below). This yields
 −(6+̺1 +̺2 )

T ′′ Θ′′ (T ′′ )−1 = 

2
2
2
0

0
0
0
−(2+̺2 )
0
0
0
−(2+̺1 )
0
0
0
−(2+̺1 +̺2 )
2
2
2

0
0
0,
0
0

where ̺i = limN →∞ N ri , i = 1, 2. Note that the rescaling of time has already been absorbed in
Θ ′′ . In place of V −1 , we now get

1
0
0
0
0
′′ −1

(V )



=


1
2
0
0
(2+̺2 )(4+̺1 )
2+̺2
1
2
0
0
(2+̺1 )(4+̺2 )
2+̺1
1
1
0
0
2(2+̺1 +̺2 )
2+̺1 +̺2
4(̺1 ̺2 +(2+̺1 +̺2 )(6+̺1 +̺2 ))
2
2
2
(2+̺1 )(2+̺2 )(2+̺1 +̺2 )(6+̺1 +̺2 ) 2+̺2 2+̺1 2+̺1 +̺2

0


,
0
0

1

which diagonalises T Θ ′′ T −1 . This shows that, in contrast to |U | = 2, the linear combinations
of E[LA (Zt )]’s that decay exponentially have coefficients depending on the recombination rates
(with exception of E[L{{1,2,3}} (Zt )]). For example (4 + ̺1 ) E[L{{1}{2,3}} (Zt )] + 2 E[L{{1,2,3}} (Zt )]
is one such combination and decays at rate 2 + ̺1 . Solution of the complete system is still
possible due to the triangular structure; however, it is somewhat tedious since it involves the
linear combination given in the last line of (V ′′ )−1 . Further progress may be possible if alternative
scalings are employed, such as the loose linkage approach suggested recently by Jenkins et al.
(2015).

8 Conclusion
Let us summarise our findings. We have described a marginal ancestral recombination process
(ARP) and proved a duality result that relates the ARP with the Moran model forward in
time, via so-called sampling functions. This was achieved by extending the recombinator
formalism, which had previously proved useful in the context of deterministic recombination
equations, to the stochastic setting. The ARP, together with the duality result, reveals the
genealogical structure hidden in the work of Bobrowski et al. (2010), who approached the matter
by functional-analytic means and forward in time. It also leads to an explicit and closed system
of ordinary differential equations for the expected sampling functions, from which the expected
linkage disequilibria of all orders can be calculated. It is quite remarkable that such a closed ODE
system exists: after all, the sampling functions are nonlinear, and the attempt to write down the
- 27 -

differential equation for the expectation of a nonlinear quantity usually results in a hierarchy of
equations that does not close; see Baake and Hustedt (2011) for more on the moment closure
problem in the case of recombination. We would like to emphasise that the favourable structure
is due to the marginalisation, which gives efficient access to correlation functions, but not to
variances, for example.
Unlike Bobrowski et al. (2010), we have not included mutation so far. However, since mutation
acts independently of recombination, it should be straightforward to superimpose it on the
population process as well as the partitioning process. It will be rewarding to study the interplay
of mutation (which increases LDE) with recombination and resampling (which decrease LDE)
within the framework established here.
Acknowledgements
It is our pleasure to thank Noemi Kurt, Cristian Giardina, and Frank Redig for a primer to
duality theory, Fernando Cordero for helpful discussions, and Michael Baake for his help to
improve the manuscript. The authors gratefully acknowledge the support from the Priority
Programme Probabilistic Structures in Evolution (SPP 1590), which is funded by Deutsche
Forschungsgemeinschaft (German Research Foundation, DFG).

References
M. Aigner. Combinatorial Theory. Springer, Berlin, 1979. Reprint 1997.
E. Baake and I. Herms. Single-crossover dynamics: Finite versus infinite populations. Bull. Math. Biol.,
70:603–624, 2008.
E. Baake and T. Hustedt. Moment closure in a Moran model with recombination. Markov Process. Relat.
Fields, 17:429–446, 2011.
E. Baake and U. von Wangenheim. Single-crossover recombination and ancestral recombination trees. J.
Math. Biol., 68:1371–1402, 2014.
E. Baake, M. Baake, and M. Salamat. The general recombination equation in continuous time and its
solution. submitted; arXiv:1409.1378, 2015.
M. Baake. Recombination semigroups on measure spaces. Monatsh. Math., 146:267–278, 2005.
M. Baake and E. Baake. An exactly solved model for mutation, recombination and selection. Canad. J.
Math., 55:3–41, 2003.
J.H. Bennett. On the theory of random mating. Ann. Eugen., 18:311–317, 1954.
C. Berge. Principles of Combinatorics. Academic Press, New York, 1971.
A. Bhaskar and Y.S. Song. Closed-form asymptotic sampling distributions under the coalescent with
recombination for an arbitrary number of loci. Adv. Appl. Prob., 44:391–407, 2012.
A. Bobrowski and M. Kimmel. A random evolution related to a Fisher–Wright–Moran model with
mutation, recombination and drift. Math. Methods Appl. Sci., 26:1587–1599, 2003.
A. Bobrowski, T. Wojdyła, and M. Kimmel. Asymptotic behavior of a Moran model with mutations,
drift and recombination among multiple loci. J. Math. Biol., 61:455–473, 2010.
R. Bürger. The Mathematical Theory of Selection, Recombination, and Mutation. Wiley, New York, 2000.
P. Donnelly. Dual processes in population-genetics. Lecture Notes in Math., 1212:94–105, 1986.
- 28 -

R. Durrett. Probability Models for DNA Sequence Evolution. Springer, New York, 2 edition, 2008.
F.J. Dyson. Statistical theory of energy levels of complex systems III. J. Math. Phys., 3:166–175, 1962.
S.N. Ethier and T.G. Kurtz. Markov Processes: Characterization and Convergence. Wiley, New York,
1985. Reprint 2005.
H. Geiringer. On the probability theory of linkage in Mendelian heredity. Ann. Math. Statist., 15:25–57,
1944.
G.B. Golding. The sampling distribution of linkage disequilibrium. Genetics, 108:257–274, 1984.
R. Gorelick and M.D. Laubichler.
1581–1583, 2004.

Decomposing multilocus linkage disequilibrium.

Genetics, 166:

R.C. Griffiths and R. Marjoram. Ancestral inference from samples of DNA sequences with recombination.
J. Comput. Biol., 3:479–502, 1996.
A. Hastings. Linkage disequilibrium, selection, and recombination at three loci. Genetics, 106:153–14,
1984.
J. Hein, M.H. Schierup, and C. Wiuf. Gene Genealogies, Variation and Evolution: A Primer in Coalescent
Theory. Oxford University Press, Oxford, 2005.
R.R. Hudson. Properties of an neutral allele model with intragenetic recombination. Theor. Popul. Biol.,
23:183–201, 1983.
S. Jansen and N. Kurt. On the notion(s) of duality for Markov processes. Prob. Surveys, 11:59–120, 2014.
P.A. Jenkins and R. Griffiths. Inference from samples of DNA sequences using a two-locus model. J.
Comp. Biol., 18:109–127, 2011.
P.A. Jenkins and Y.S. Song. An asymptotic sampling formula for the coalescent with recombination.
Ann. Appl. Probab., 20:1005–1028, 2010.
P.A. Jenkins, P. Fearnhead, and Y.S. Song. Tractable stochastic models of evolution for loosely linked
loci. submitted; arXiv:1405.6863v1, 2015.
T.M. Liggett. Interacting Particle Systems. Springer, Berlin, 1985. Reprint 2005.
S. Mano. Duality between the two-locus Wright-Fisher diffusion model and the ancestral process with
recombination. J. Appl. Prob., 50:256–271, 2013.
M.L. Mehta. Random Matrices. Academic Press, San Diego, 1991.
M. Möhle. Forward and backward diffusion approximations for haploid exchangeable population models.
Stoch. Proc. Appl., 95:133–149, 2001.
T. Ohta and M. Kimura. Linkage disequilibrium due to random genetic drift. Genet. Res., 13:47–55,
1969.
G.-C. Rota. On the foundations of combinatorial theory I. Theory of Möbius functions.
Wahrscheinlichkeitstheorie, 2:340–368, 1964.

Z.

Y.S. Song and J.S. Song. Analytic computation of the expectation of the linkage disequilibrium coefficient
r2 . Theor. Pop. Biol., 71:49–60, 2007.
R.P. Stanley. Enumerative Combinatorics, volume I. Wadsworth & Brooks/Cole, Monterey, CA, 1986.
U. von Wangenheim, E. Baake, and M. Baake. Single-crossover recombination in discrete time. J. Math.
Biol., 60:727–760, 2010.
J. Wakeley. Coalescent Theory: An Introduction. Roberts and Co., Greenwood Village, CO, 2009.
Y. Wang and B. Rannala. Bayesian inference of fine-scale recombination rates using population genomic
data. Phil. Trans. R. Soc. B, 363:3921–3930, 2008.
- 29 -

